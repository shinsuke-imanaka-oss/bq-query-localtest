# data_quality_ui.py
"""
ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ UIè¡¨ç¤ºæ©Ÿèƒ½
- Streamlitç”¨ã®å“è³ªãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
- å¯è¦–åŒ–ãƒ»ã‚°ãƒ©ãƒ•è¡¨ç¤º
- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªçµæœè¡¨ç¤º
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from typing import Dict, List, Optional, Any
import warnings
warnings.filterwarnings('ignore')

# ã‚³ã‚¢æ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from data_quality_checker import (
        DataQualityChecker, 
        DataProfiler, 
        DataCleaner, 
        StatisticalAnalyzer,
        quick_quality_check,
        generate_quality_report,
        auto_clean_data
    )
except ImportError:
    st.error("data_quality_checker.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# =========================================================================
# ãƒ¡ã‚¤ãƒ³å“è³ªãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
# =========================================================================

def show_data_quality_report(df: pd.DataFrame, analysis_context: str = ""):
    """Streamlitç”¨ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º"""
    if df.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€å“è³ªãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
        return
    
    checker = DataQualityChecker()
    report = checker.comprehensive_quality_check(df, analysis_context)
    
    # ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    show_quality_metrics(report)
    
    # å•é¡Œè©³ç´°ã¨ã‚µãƒãƒªãƒ¼
    show_quality_summary(report)
    
    # è©³ç´°åˆ†æï¼ˆå±•é–‹å¯èƒ½ï¼‰
    show_detailed_quality_analysis(df, report)

def show_quality_metrics(report: Dict[str, Any]):
    """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º"""
    col1, col2, col3 = st.columns(3)
    
    with col1:
        score = report['overall_score']
        delta_color = "normal"
        if score >= 85:
            delta_color = "normal"
        elif score >= 70:
            delta_color = "normal"
        else:
            delta_color = "inverse"
        
        st.metric("å“è³ªã‚¹ã‚³ã‚¢", f"{score}/100", delta=None)
    
    with col2:
        status_icons = {
            'excellent': 'ğŸŸ¢',
            'good': 'ğŸŸ¡', 
            'warning': 'ğŸŸ ',
            'critical': 'ğŸ”´'
        }
        status = report['status']
        st.metric("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", f"{status_icons[status]} {status}")
    
    with col3:
        st.metric("å•é¡Œæ•°", len(report['issues']))

def show_quality_summary(report: Dict[str, Any]):
    """å“è³ªã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º"""
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    if report['status'] == 'excellent':
        st.success(f"âœ… {report['summary']}")
    elif report['status'] == 'good':
        st.success(f"âœ… {report['summary']}")
    elif report['status'] == 'warning':
        st.warning(f"âš ï¸ {report['summary']}")
    else:
        st.error(f"ğŸ”´ {report['summary']}")
    
    # å•é¡Œè©³ç´°è¡¨ç¤º
    if report['issues']:
        st.markdown("### æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ")
        for issue in report['issues']:
            if issue['severity'] == 'critical':
                st.error(f"ğŸ”´ **é‡è¦**: {issue['message']}")
            elif issue['severity'] == 'warning':
                st.warning(f"ğŸŸ¡ **è­¦å‘Š**: {issue['message']}")
            else:
                st.info(f"â„¹ï¸ **æƒ…å ±**: {issue['message']}")
    
    # æ”¹å–„ææ¡ˆè¡¨ç¤º
    if report['suggestions']:
        st.markdown("### ğŸ’¡ æ”¹å–„ææ¡ˆ")
        for suggestion in report['suggestions']:
            st.markdown(f"â€¢ {suggestion}")

def show_detailed_quality_analysis(df: pd.DataFrame, report: Dict[str, Any]):
    """è©³ç´°å“è³ªåˆ†æã®è¡¨ç¤º"""
    with st.expander("ğŸ“Š è©³ç´°å“è³ªåˆ†æ", expanded=False):
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ åŸºæœ¬çµ±è¨ˆ", "ğŸ“ˆ å¯è¦–åŒ–", "ğŸ”§ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°", "ğŸ“„ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«"])
        
        with tab1:
            show_basic_statistics(df)
        
        with tab2:
            show_quality_visualizations(df)
        
        with tab3:
            show_cleaning_interface(df, report)
        
        with tab4:
            show_data_profile(df)

# =========================================================================
# åŸºæœ¬çµ±è¨ˆè¡¨ç¤º
# =========================================================================

def show_basic_statistics(df: pd.DataFrame):
    """åŸºæœ¬çµ±è¨ˆã®è¡¨ç¤º"""
    st.markdown("#### NULLå€¤çµ±è¨ˆ")
    null_stats = []
    for col in df.columns:
        null_count = df[col].isnull().sum()
        null_rate = (null_count / len(df)) * 100
        null_stats.append({
            'åˆ—å': col,
            'NULLæ•°': null_count,
            'NULLç‡': f"{null_rate:.1f}%"
        })
    
    null_df = pd.DataFrame(null_stats)
    st.dataframe(null_df, use_container_width=True)
    
    # æ•°å€¤åˆ—ã®åŸºæœ¬çµ±è¨ˆ
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        st.markdown("#### æ•°å€¤åˆ—ã®åŸºæœ¬çµ±è¨ˆ")
        st.dataframe(df[numeric_cols].describe(), use_container_width=True)
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ—ã®çµ±è¨ˆ
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns
    if len(categorical_cols) > 0:
        st.markdown("#### ã‚«ãƒ†ã‚´ãƒªåˆ—ã®çµ±è¨ˆ")
        for col in categorical_cols[:3]:  # æœ€åˆã®3åˆ—ã®ã¿è¡¨ç¤º
            st.markdown(f"**{col}** ã®ä¸Šä½å€¤:")
            top_values = df[col].value_counts().head(5)
            for value, count in top_values.items():
                st.caption(f"  {value}: {count}å› ({count/len(df)*100:.1f}%)")

# =========================================================================
# å“è³ªå¯è¦–åŒ–æ©Ÿèƒ½
# =========================================================================

def show_quality_visualizations(df: pd.DataFrame):
    """å“è³ªå¯è¦–åŒ–ã®è¡¨ç¤º"""
    st.markdown("#### ãƒ‡ãƒ¼ã‚¿å“è³ªã®å¯è¦–åŒ–")
    
    viz_option = st.selectbox(
        "è¡¨ç¤ºã™ã‚‹å¯è¦–åŒ–ã‚’é¸æŠ",
        ["NULLå€¤åˆ†å¸ƒ", "å¤–ã‚Œå€¤åˆ†æ", "ãƒ‡ãƒ¼ã‚¿å‹åˆ†å¸ƒ", "ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", "åˆ†å¸ƒæ¯”è¼ƒ"]
    )
    
    if viz_option == "NULLå€¤åˆ†å¸ƒ":
        show_null_distribution(df)
    elif viz_option == "å¤–ã‚Œå€¤åˆ†æ":
        show_outlier_analysis(df)
    elif viz_option == "ãƒ‡ãƒ¼ã‚¿å‹åˆ†å¸ƒ":
        show_data_type_distribution(df)
    elif viz_option == "ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—":
        show_correlation_heatmap(df)
    elif viz_option == "åˆ†å¸ƒæ¯”è¼ƒ":
        show_distribution_comparison(df)

def show_null_distribution(df: pd.DataFrame):
    """NULLå€¤åˆ†å¸ƒã®å¯è¦–åŒ–"""
    null_rates = (df.isnull().sum() / len(df)) * 100
    null_rates = null_rates[null_rates > 0].sort_values(ascending=True)
    
    if len(null_rates) > 0:
        fig = px.bar(
            x=null_rates.values,
            y=null_rates.index,
            orientation='h',
            title="åˆ—åˆ¥NULLå€¤ç‡ (%)",
            labels={'x': 'NULLå€¤ç‡ (%)', 'y': 'åˆ—å'}
        )
        
        # è­¦å‘Šç·šã®è¿½åŠ 
        fig.add_vline(x=10, line_dash="dash", line_color="orange", 
                      annotation_text="è­¦å‘Šé–¾å€¤ (10%)")
        fig.add_vline(x=30, line_dash="dash", line_color="red", 
                      annotation_text="é‡è¦è­¦å‘Šé–¾å€¤ (30%)")
        
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.success("âœ… NULLå€¤ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼")

def show_outlier_analysis(df: pd.DataFrame):
    """å¤–ã‚Œå€¤åˆ†æã®å¯è¦–åŒ–"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    
    if len(numeric_cols) > 0:
        selected_col = st.selectbox("å¤–ã‚Œå€¤ãƒã‚§ãƒƒã‚¯å¯¾è±¡åˆ—", numeric_cols)
        
        if selected_col:
            col1, col2 = st.columns(2)
            
            with col1:
                # ç®±ã²ã’å›³
                fig_box = px.box(df, y=selected_col, title=f"{selected_col} ã®åˆ†å¸ƒã¨å¤–ã‚Œå€¤")
                st.plotly_chart(fig_box, use_container_width=True)
            
            with col2:
                # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
                fig_hist = px.histogram(df, x=selected_col, title=f"{selected_col} ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ")
                st.plotly_chart(fig_hist, use_container_width=True)
            
            # å¤–ã‚Œå€¤çµ±è¨ˆ
            Q1 = df[selected_col].quantile(0.25)
            Q3 = df[selected_col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = df[(df[selected_col] < lower_bound) | (df[selected_col] > upper_bound)]
            
            st.info(f"ğŸ“Š å¤–ã‚Œå€¤çµ±è¨ˆ: {len(outliers)}è¡Œ ({len(outliers)/len(df)*100:.1f}%)")
    else:
        st.info("æ•°å€¤åˆ—ãŒãªã„ãŸã‚ã€å¤–ã‚Œå€¤åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")

def show_data_type_distribution(df: pd.DataFrame):
    """ãƒ‡ãƒ¼ã‚¿å‹åˆ†å¸ƒã®å¯è¦–åŒ–"""
    type_counts = df.dtypes.value_counts()
    
    # ãƒ‡ãƒ¼ã‚¿å‹ã®æ—¥æœ¬èªåãƒãƒƒãƒ”ãƒ³ã‚°
    type_mapping = {
        'object': 'ãƒ†ã‚­ã‚¹ãƒˆ',
        'int64': 'æ•´æ•°',
        'float64': 'å°æ•°',
        'datetime64[ns]': 'æ—¥æ™‚',
        'bool': 'çœŸå½å€¤',
        'category': 'ã‚«ãƒ†ã‚´ãƒª'
    }
    
    # ãƒ‡ãƒ¼ã‚¿å‹åã‚’æ—¥æœ¬èªã«å¤‰æ›
    type_counts.index = [type_mapping.get(str(dtype), str(dtype)) for dtype in type_counts.index]
    
    fig = px.pie(
        values=type_counts.values,
        names=type_counts.index,
        title="ãƒ‡ãƒ¼ã‚¿å‹åˆ¥åˆ—æ•°ã®åˆ†å¸ƒ"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«
    st.markdown("#### ãƒ‡ãƒ¼ã‚¿å‹è©³ç´°")
    type_detail = []
    for dtype in df.dtypes.unique():
        cols = df.select_dtypes(include=[dtype]).columns.tolist()
        type_detail.append({
            'ãƒ‡ãƒ¼ã‚¿å‹': type_mapping.get(str(dtype), str(dtype)),
            'åˆ—æ•°': len(cols),
            'åˆ—åä¾‹': ', '.join(cols[:3]) + ('...' if len(cols) > 3 else '')
        })
    
    st.dataframe(pd.DataFrame(type_detail), use_container_width=True)

def show_correlation_heatmap(df: pd.DataFrame):
    """ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®è¡¨ç¤º"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    
    if len(numeric_cols) >= 2:
        corr_matrix = df[numeric_cols].corr()
        
        fig = px.imshow(
            corr_matrix,
            title="æ•°å€¤åˆ—é–“ã®ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
            color_continuous_scale="RdBu",
            aspect="auto",
            text_auto=True
        )
        fig.update_layout(height=600)
        st.plotly_chart(fig, use_container_width=True)
        
        # é«˜ã„ç›¸é–¢ãƒšã‚¢ã®æŠ½å‡º
        high_corr_pairs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_value = corr_matrix.iloc[i, j]
                if abs(corr_value) > 0.7:
                    high_corr_pairs.append({
                        'åˆ—1': corr_matrix.columns[i],
                        'åˆ—2': corr_matrix.columns[j],
                        'ç›¸é–¢ä¿‚æ•°': f"{corr_value:.3f}"
                    })
        
        if high_corr_pairs:
            st.markdown("#### ğŸ”— é«˜ã„ç›¸é–¢ã‚’æŒã¤åˆ—ãƒšã‚¢ (|r| > 0.7)")
            st.dataframe(pd.DataFrame(high_corr_pairs), use_container_width=True)
        else:
            st.info("é«˜ã„ç›¸é–¢ï¼ˆ|r| > 0.7ï¼‰ã‚’æŒã¤åˆ—ãƒšã‚¢ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.info("ç›¸é–¢åˆ†æã«ã¯æ•°å€¤åˆ—ãŒ2åˆ—ä»¥ä¸Šå¿…è¦ã§ã™ã€‚")

def show_distribution_comparison(df: pd.DataFrame):
    """åˆ†å¸ƒæ¯”è¼ƒã®è¡¨ç¤º"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    
    if len(numeric_cols) >= 2:
        col1, col2 = st.columns(2)
        
        with col1:
            x_col = st.selectbox("Xè»¸ï¼ˆåˆ—1ï¼‰", numeric_cols)
        with col2:
            y_col = st.selectbox("Yè»¸ï¼ˆåˆ—2ï¼‰", numeric_cols, index=1)
        
        if x_col != y_col:
            # æ•£å¸ƒå›³
            fig_scatter = px.scatter(
                df, x=x_col, y=y_col,
                title=f"{x_col} vs {y_col}",
                trendline="ols"
            )
            st.plotly_chart(fig_scatter, use_container_width=True)
            
            # çµ±è¨ˆæƒ…å ±
            correlation = df[x_col].corr(df[y_col])
            st.info(f"ğŸ“Š ç›¸é–¢ä¿‚æ•°: {correlation:.3f}")
    else:
        st.info("åˆ†å¸ƒæ¯”è¼ƒã«ã¯æ•°å€¤åˆ—ãŒ2åˆ—ä»¥ä¸Šå¿…è¦ã§ã™ã€‚")

# =========================================================================
# ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
# =========================================================================

def show_cleaning_interface(df: pd.DataFrame, quality_report: Dict[str, Any]):
    """ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®è¡¨ç¤º"""
    st.markdown("#### ğŸ§¹ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°")
    
    if not quality_report.get('issues'):
        st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®é¸æŠ
    cleaning_options = st.multiselect(
        "é©ç”¨ã™ã‚‹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å‡¦ç†ã‚’é¸æŠ:",
        [
            "NULLå€¤ã®å¤šã„åˆ—ã‚’é™¤å» (30%ä»¥ä¸Š)",
            "å®Œå…¨é‡è¤‡è¡Œã‚’é™¤å»",
            "æ•°å€¤åˆ—ã®å¤–ã‚Œå€¤ã‚’é™¤å» (IQRåŸºæº–)",
            "å®šæ•°åˆ—ã‚’é™¤å»"
        ]
    )
    
    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½
    if cleaning_options:
        show_cleaning_preview(df, cleaning_options)
    
    # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
    if st.button("ğŸš€ é¸æŠã—ãŸã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ", disabled=len(cleaning_options) == 0):
        execute_data_cleaning(df, cleaning_options)

def show_cleaning_preview(df: pd.DataFrame, cleaning_options: List[str]):
    """ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è¡¨ç¤º"""
    st.markdown("#### ğŸ‘ï¸ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å‰å¾Œã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    
    # ä»®æƒ³ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã¯å¤‰æ›´ã—ãªã„ï¼‰
    try:
        cleaner = DataCleaner()
        preview_df = cleaner.clean_data(df.copy(), cleaning_options)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("è¡Œæ•°", f"{len(df):,}", delta=f"{len(preview_df) - len(df):,}")
        
        with col2:
            st.metric("åˆ—æ•°", len(df.columns), delta=len(preview_df.columns) - len(df.columns))
        
        with col3:
            memory_before = df.memory_usage(deep=True).sum() / 1024 / 1024
            memory_after = preview_df.memory_usage(deep=True).sum() / 1024 / 1024
            st.metric("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡(MB)", f"{memory_before:.1f}", delta=f"{memory_after - memory_before:.1f}")
        
        # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹æœã®è©³ç´°
        show_cleaning_effects(df, preview_df)
        
    except Exception as e:
        st.error(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

def show_cleaning_effects(original_df: pd.DataFrame, cleaned_df: pd.DataFrame):
    """ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹æœã®è©³ç´°è¡¨ç¤º"""
    st.markdown("#### ğŸ“ˆ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹æœ")
    
    effects = []
    
    # è¡Œæ•°ã®å¤‰åŒ–
    row_change = len(cleaned_df) - len(original_df)
    if row_change != 0:
        effects.append(f"è¡Œæ•°: {row_change:+,}è¡Œ ({row_change/len(original_df)*100:+.1f}%)")
    
    # åˆ—æ•°ã®å¤‰åŒ–
    col_change = len(cleaned_df.columns) - len(original_df.columns)
    if col_change != 0:
        effects.append(f"åˆ—æ•°: {col_change:+}åˆ—")
    
    # NULLå€¤ã®å¤‰åŒ–
    null_before = original_df.isnull().sum().sum()
    null_after = cleaned_df.isnull().sum().sum()
    null_change = null_after - null_before
    if null_change != 0:
        effects.append(f"NULLå€¤: {null_change:+,}å€‹")
    
    # é‡è¤‡è¡Œã®å¤‰åŒ–
    dup_before = original_df.duplicated().sum()
    dup_after = cleaned_df.duplicated().sum()
    dup_change = dup_after - dup_before
    if dup_change != 0:
        effects.append(f"é‡è¤‡è¡Œ: {dup_change:+,}è¡Œ")
    
    # åŠ¹æœã®è¡¨ç¤º
    for effect in effects:
        st.info(f"â€¢ {effect}")
    
    if not effects:
        st.info("å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

def execute_data_cleaning(df: pd.DataFrame, cleaning_options: List[str]):
    """ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œ"""
    try:
        cleaner = DataCleaner()
        cleaned_df = cleaner.clean_data(df, cleaning_options)
        
        # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
        st.session_state.cleaned_df = cleaned_df
        
        # çµæœã®è¡¨ç¤º
        st.success(f"ğŸ‰ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼ {len(df):,}è¡Œ â†’ {len(cleaned_df):,}è¡Œ")
        
        # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®å“è³ªãƒã‚§ãƒƒã‚¯
        show_post_cleaning_quality_check(cleaned_df)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        csv = cleaned_df.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name=f"cleaned_data_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
        
    except Exception as e:
        st.error(f"ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

def show_post_cleaning_quality_check(cleaned_df: pd.DataFrame):
    """ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®å“è³ªãƒã‚§ãƒƒã‚¯"""
    with st.expander("ğŸ“Š ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®å“è³ªãƒã‚§ãƒƒã‚¯", expanded=False):
        post_report = quick_quality_check(cleaned_df)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å“è³ªã‚¹ã‚³ã‚¢", f"{post_report['overall_score']}/100")
        with col2:
            status_icons = {"excellent": "ğŸŸ¢", "good": "ğŸŸ¡", "warning": "ğŸŸ ", "critical": "ğŸ”´"}
            status = post_report['status']
            st.write(f"**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: {status_icons[status]} {status}")
        with col3:
            st.metric("æ®‹å­˜å•é¡Œ", len(post_report['issues']))
        
        if post_report['issues']:
            st.markdown("**æ®‹å­˜ã™ã‚‹å•é¡Œ:**")
            for issue in post_report['issues']:
                st.caption(f"â€¢ {issue['message']}")

# =========================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º
# =========================================================================

def show_data_profile(df: pd.DataFrame):
    """ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤º"""
    st.markdown("#### ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")
    
    profiler = DataProfiler()
    profile = profiler.generate_profile_report(df)
    
    # åŸºæœ¬æƒ…å ±
    basic = profile['basic_info']
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç·è¡Œæ•°", f"{basic['row_count']:,}")
    with col2:
        st.metric("ç·åˆ—æ•°", basic['column_count'])
    with col3:
        st.metric("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡", f"{basic['memory_usage_mb']:.1f} MB")
    with col4:
        st.metric("æ•°å€¤åˆ—æ•°", basic['numeric_columns'])
    
    # åˆ—ã®è©³ç´°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
    show_column_profiles(profile['column_profiles'])
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºçµæœ
    show_data_patterns(profile['data_patterns'])

def show_column_profiles(column_profiles: Dict[str, Any]):
    """åˆ—ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤º"""
    with st.expander("ğŸ“Š åˆ—åˆ¥è©³ç´°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«", expanded=False):
        profile_data = []
        
        for col_name, col_profile in column_profiles.items():
            profile_data.append({
                'åˆ—å': col_name,
                'ãƒ‡ãƒ¼ã‚¿å‹': col_profile['dtype'],
                'NULLç‡': f"{col_profile['null_rate']:.1f}%",
                'ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°': col_profile['unique_count'],
                'ãƒ¦ãƒ‹ãƒ¼ã‚¯ç‡': f"{col_profile['unique_rate']:.1f}%"
            })
        
        profile_df = pd.DataFrame(profile_data)
        st.dataframe(profile_df, use_container_width=True)
        
        # è©³ç´°è¡¨ç¤ºç”¨ã®åˆ—é¸æŠ
        selected_column = st.selectbox("è©³ç´°è¡¨ç¤ºã™ã‚‹åˆ—", list(column_profiles.keys()))
        
        if selected_column:
            show_individual_column_profile(selected_column, column_profiles[selected_column])

def show_individual_column_profile(col_name: str, col_profile: Dict[str, Any]):
    """å€‹åˆ¥åˆ—ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤º"""
    st.markdown(f"#### {col_name} ã®è©³ç´°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("NULLç‡", f"{col_profile['null_rate']:.1f}%")
    with col2:
        st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°", col_profile['unique_count'])
    with col3:
        st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ç‡", f"{col_profile['unique_rate']:.1f}%")
    
    # æ•°å€¤åˆ—ã®å ´åˆã®çµ±è¨ˆæƒ…å ±
    if 'mean' in col_profile:
        st.markdown("**çµ±è¨ˆæƒ…å ±**")
        stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
        with stat_col1:
            st.metric("æœ€å°å€¤", f"{col_profile['min']:,.2f}")
        with stat_col2:
            st.metric("æœ€å¤§å€¤", f"{col_profile['max']:,.2f}")
        with stat_col3:
            st.metric("å¹³å‡å€¤", f"{col_profile['mean']:,.2f}")
        with stat_col4:
            st.metric("æ¨™æº–åå·®", f"{col_profile['std']:,.2f}")
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ—ã®å ´åˆã®ä¸Šä½å€¤
    if 'top_values' in col_profile:
        st.markdown("**ä¸Šä½å€¤**")
        for value, count in list(col_profile['top_values'].items())[:5]:
            percentage = (count / col_profile.get('total_count', count)) * 100
            st.caption(f"{value}: {count}å› ({percentage:.1f}%)")

def show_data_patterns(patterns: Dict[str, Any]):
    """ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¡¨ç¤º"""
    with st.expander("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º", expanded=False):
        # å®šæ•°åˆ—
        if patterns['constant_columns']:
            st.warning(f"âš ï¸ **å®šæ•°åˆ—ã‚’æ¤œå‡º**: {', '.join(patterns['constant_columns'])}")
            st.caption("ã“ã‚Œã‚‰ã®åˆ—ã¯å¸¸ã«åŒã˜å€¤ã‚’æŒã£ã¦ã„ã‚‹ãŸã‚ã€åˆ†æã«ã¯æœ‰ç”¨ã§ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
        # é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£åˆ—
        if patterns['high_cardinality_columns']:
            st.warning(f"âš ï¸ **é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£åˆ—ã‚’æ¤œå‡º**: {', '.join(patterns['high_cardinality_columns'])}")
            st.caption("ã“ã‚Œã‚‰ã®åˆ—ã¯ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ãŒå¤šã™ãã‚‹ãŸã‚ã€ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã¨ã—ã¦æ‰±ã†ã®ã«é©ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
        # ç–‘ã‚ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³
        if patterns['suspicious_columns']:
            st.warning("âš ï¸ **ç–‘ã‚ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º**:")
            for suspicious in patterns['suspicious_columns']:
                st.caption(f"â€¢ {suspicious['column']}: {suspicious['pattern']}")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
        if not any([patterns['constant_columns'], patterns['high_cardinality_columns'], patterns['suspicious_columns']]):
            st.success("âœ… ç‰¹åˆ¥ãªæ³¨æ„ãŒå¿…è¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

# =========================================================================
# å“è³ªæ”¹å–„ææ¡ˆè¡¨ç¤º
# =========================================================================

def show_quality_improvement_suggestions(df: pd.DataFrame, quality_report: Dict[str, Any]):
    """å“è³ªæ”¹å–„ææ¡ˆã®è¡¨ç¤º"""
    st.markdown("#### ğŸ’¡ å“è³ªæ”¹å–„ææ¡ˆ")
    
    suggestions = quality_report.get('suggestions', [])
    
    if not suggestions:
        st.success("âœ… ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿å“è³ªã«ç‰¹åˆ¥ãªæ”¹å–„ææ¡ˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ææ¡ˆã®åˆ†é¡
    immediate_actions = []
    optional_improvements = []
    
    for suggestion in suggestions:
        if any(keyword in suggestion for keyword in ['é™¤å¤–', 'NULLå€¤', 'é‡è¤‡', 'ç¢ºèª']):
            immediate_actions.append(suggestion)
        else:
            optional_improvements.append(suggestion)
    
    # ç·Šæ€¥åº¦ã®é«˜ã„ææ¡ˆ
    if immediate_actions:
        st.markdown("**ğŸš¨ å„ªå…ˆåº¦é«˜ï¼šå³åº§ã«å¯¾å¿œã‚’æ¨å¥¨**")
        for action in immediate_actions:
            st.error(f"ğŸ”´ {action}")
    
    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³çš„ãªæ”¹å–„ææ¡ˆ
    if optional_improvements:
        st.markdown("**ğŸ’¡ æ”¹å–„ææ¡ˆï¼šä½™è£•ãŒã‚ã‚‹ã¨ãã«æ¤œè¨**")
        for improvement in optional_improvements:
            st.info(f"â„¹ï¸ {improvement}")

# =========================================================================
# æ¯”è¼ƒè¡¨ç¤ºæ©Ÿèƒ½
# =========================================================================

def show_data_comparison(df1: pd.DataFrame, df2: pd.DataFrame, label1: str = "ãƒ‡ãƒ¼ã‚¿1", label2: str = "ãƒ‡ãƒ¼ã‚¿2"):
    """2ã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ¯”è¼ƒè¡¨ç¤º"""
    st.markdown(f"#### ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒ: {label1} vs {label2}")
    
    # åŸºæœ¬çµ±è¨ˆã®æ¯”è¼ƒ
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"**{label1}**")
        report1 = quick_quality_check(df1)
        st.metric("å“è³ªã‚¹ã‚³ã‚¢", f"{report1['overall_score']}/100")
        st.metric("è¡Œæ•°", len(df1))
        st.metric("åˆ—æ•°", len(df1.columns))
        st.metric("å•é¡Œæ•°", len(report1['issues']))
    
    with col2:
        st.markdown(f"**{label2}**")
        report2 = quick_quality_check(df2)
        st.metric("å“è³ªã‚¹ã‚³ã‚¢", f"{report2['overall_score']}/100", 
                 delta=report2['overall_score'] - report1['overall_score'])
        st.metric("è¡Œæ•°", len(df2), delta=len(df2) - len(df1))
        st.metric("åˆ—æ•°", len(df2.columns), delta=len(df2.columns) - len(df1.columns))
        st.metric("å•é¡Œæ•°", len(report2['issues']), delta=len(report2['issues']) - len(report1['issues']))
    
    # æ”¹å–„åŠ¹æœã®å¯è¦–åŒ–
    if report2['overall_score'] != report1['overall_score']:
        show_improvement_visualization(report1, report2, label1, label2)

def show_improvement_visualization(report1: Dict, report2: Dict, label1: str, label2: str):
    """æ”¹å–„åŠ¹æœã®å¯è¦–åŒ–"""
    scores = [report1['overall_score'], report2['overall_score']]
    labels = [label1, label2]
    
    fig = px.bar(
        x=labels,
        y=scores,
        title="ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢æ¯”è¼ƒ",
        color=scores,
        color_continuous_scale="RdYlGn"
    )
    fig.update_layout(showlegend=False)
    st.plotly_chart(fig, use_container_width=True)

# =========================================================================
# å¤–éƒ¨å‘¼ã³å‡ºã—ç”¨ã®çµ±åˆé–¢æ•°
# =========================================================================

def show_comprehensive_quality_analysis(df: pd.DataFrame, context: str = ""):
    """åŒ…æ‹¬çš„ãªå“è³ªåˆ†æã®è¡¨ç¤ºï¼ˆå¤–éƒ¨ã‹ã‚‰å‘¼ã³å‡ºã—ç”¨ï¼‰"""
    if df.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€å“è³ªåˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ¡ã‚¤ãƒ³å“è³ªãƒ¬ãƒãƒ¼ãƒˆ
    show_data_quality_report(df, context)
    
    # å“è³ªæ”¹å–„ææ¡ˆ
    quality_report = quick_quality_check(df)
    show_quality_improvement_suggestions(df, quality_report)

def show_quality_dashboard(df: pd.DataFrame):
    """å“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è¡¨ç¤º"""
    st.markdown("## ğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    
    if df.empty:
        st.error("ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")
        return
    
    # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    quality_report = quick_quality_check(df)
    
    # 4åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("å“è³ªã‚¹ã‚³ã‚¢", f"{quality_report['overall_score']}/100")
    
    with col2:
        st.metric("ãƒ‡ãƒ¼ã‚¿è¡Œæ•°", f"{len(df):,}")
    
    with col3:
        null_rate = (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
        st.metric("NULLå€¤ç‡", f"{null_rate:.1f}%")
    
    with col4:
        duplicate_rate = (df.duplicated().sum() / len(df)) * 100
        st.metric("é‡è¤‡ç‡", f"{duplicate_rate:.1f}%")
    
    # è©³ç´°åˆ†æ
    show_detailed_quality_analysis(df, quality_report)