# enhanced_prompts.py - è¨­å®šå¯¾å¿œç‰ˆï¼ˆå®Œå…¨ç‰ˆï¼‰
"""
å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ  - è¨­å®šä¸€å…ƒç®¡ç†å¯¾å¿œ
æ¥­ç•Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ»æˆ¦ç•¥åˆ†æãƒ»ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’æ©Ÿèƒ½
"""

import json
from datetime import datetime
from typing import Dict, Any, List, Optional
import streamlit as st
from context_glossary import get_glossary_for_prompt, extract_relevant_glossary

# è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®èª­ã¿è¾¼ã¿
try:
    from bq_tool_config import settings
    SETTINGS_AVAILABLE = settings is not None
except ImportError:
    SETTINGS_AVAILABLE = False
    settings = None

# åˆ†æå¯¾è±¡ã¨ã—ãŸã„ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’ãƒªã‚¹ãƒˆã§å®šç¾©ï¼ˆä»Šå¾Œã“ã“ã‚’ç·¨é›†ã™ã‚‹ã ã‘ã§å¯¾è±¡ã‚’å¢—æ¸›ã§ãã‚‹ï¼‰
TARGET_TABLES = [
    "LookerStudio_report_campaign",
    "LookerStudio_report_campaign_device",
    "LookerStudio_report_ad_group",
    "LookerStudio_report_ad",
    "LookerStudio_report_keyword",
    "LookerStudio_report_device",
    "LookerStudio_report_gender",
    "LookerStudio_report_age_group",
    "LookerStudio_report_budget",
    "LookerStudio_report_final_url",
    "LookerStudio_report_hourly",
    "LookerStudio_report_interest",
    "LookerStudio_report_placement",
    "LookerStudio_report_search_query",
    "LookerStudio_report_area"
]

@st.cache_data(ttl=3600)
def get_table_schema_for_prompt() -> str:
    """ã€æ–°ãƒ»æ”¹ã€‘è¤‡æ•°ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—ã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã«æ•´å½¢ã™ã‚‹"""
    bq_client = st.session_state.get("bq_client")
    if not bq_client:
        return "ï¼ˆã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
    
    try:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆIDã‚’å–å¾—
        dataset_id = settings.bigquery.dataset
        project_id = settings.bigquery.project_id

        # TARGET_TABLESãƒªã‚¹ãƒˆã®ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’ç›´æ¥INå¥ã§ä½¿ç”¨ã™ã‚‹
        table_list_str = "', '".join(TARGET_TABLES)

        # INFORMATION_SCHEMAã‚’ä¸€åº¦ã«ã‚¯ã‚¨ãƒªã—ã¦ã€è¤‡æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆ—æƒ…å ±ã‚’ã¾ã¨ã‚ã¦å–å¾—
        query = f"""
        SELECT table_name, column_name, data_type
        FROM `{project_id}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`
        WHERE table_name IN ('{table_list_str}')
        ORDER BY table_name, ordinal_position
        """
        df = bq_client.query(query).to_dataframe()
        
        if df.empty:
            st.warning(f"ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {', '.join(TARGET_TABLES)}")
            return "ï¼ˆã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"

        # ãƒ†ãƒ¼ãƒ–ãƒ«ã”ã¨ã«è¦‹ã‚„ã™ãæ•´å½¢
        schema_str = ""
        current_table = ""
        for _, row in df.iterrows():
            if row.table_name != current_table:
                current_table = row.table_name
                # settingsã‹ã‚‰å–å¾—ã—ãŸæƒ…å ±ã§å®Œå…¨ãªãƒ†ãƒ¼ãƒ–ãƒ«åã‚’å†æ§‹ç¯‰ã—ã¦è¡¨ç¤º
                full_table_path = f"`{project_id}.{dataset_id}.{current_table}`"
                schema_str += f"\n### ãƒ†ãƒ¼ãƒ–ãƒ«å: {full_table_path}\n"
            schema_str += f"- {row.column_name} ({row.data_type})\n"

        return schema_str

    except Exception as e:
        st.warning(f"è¤‡æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒã®å–å¾—ã«å¤±æ•—: {e}")
        return "ï¼ˆã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"


# =========================================================================
# æ¥­ç•Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ»å®šæ•°å®šç¾©ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

def get_industry_benchmarks() -> Dict[str, Dict[str, float]]:
    """æ¥­ç•Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ•°å€¤ï¼ˆè¨­å®šã‹ã‚‰æ‹¡å¼µå¯èƒ½ï¼‰"""
    base_benchmarks = {
        "æ¤œç´¢åºƒå‘Š": {
            "å¹³å‡CTR": 0.035,    # 3.5%
            "å¹³å‡CPC": 150,      # 150å††
            "å¹³å‡CVR": 0.025,    # 2.5%
            "å¹³å‡CPA": 6000,     # 6,000å††
            "å¹³å‡ROAS": 4.2      # 420%
        },
        "ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤åºƒå‘Š": {
            "å¹³å‡CTR": 0.008,    # 0.8%
            "å¹³å‡CPC": 80,       # 80å††
            "å¹³å‡CVR": 0.012,    # 1.2%
            "å¹³å‡CPA": 8000,     # 8,000å††
            "å¹³å‡ROAS": 3.1      # 310%
        },
        "SNSåºƒå‘Š": {
            "å¹³å‡CTR": 0.015,    # 1.5%
            "å¹³å‡CPC": 120,      # 120å††
            "å¹³å‡CVR": 0.018,    # 1.8%
            "å¹³å‡CPA": 7200,     # 7,200å††
            "å¹³å‡ROAS": 3.8      # 380%
        }
    }
    
    # è¨­å®šã‹ã‚‰æ¥­ç•Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ä¸Šæ›¸ããŒå¯èƒ½
    if SETTINGS_AVAILABLE and hasattr(settings, 'industry_benchmarks'):
        base_benchmarks.update(settings.industry_benchmarks)
    
    return base_benchmarks

def get_llm_config() -> Dict[str, Any]:
    """LLMè¨­å®šã®å–å¾—"""
    if SETTINGS_AVAILABLE:
        return {
            "gemini_model": settings.ai.gemini_model,
            "claude_model": settings.ai.claude_model,
            "temperature": settings.ai.temperature,
            "max_tokens": settings.ai.max_tokens,
            "timeout": settings.ai.timeout
        }
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
        return {
            "gemini_model": "gemini-2.0-flash-001",
            "claude_model": "claude-3-sonnet-20240229", 
            "temperature": 0.3,
            "max_tokens": 4000,
            "timeout": 60
        }

# =========================================================================
# å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

class EnhancedPrompts:
    """å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆè¨­å®šç®¡ç†å¯¾å¿œï¼‰"""
    
    def __init__(self):
        self.config = get_llm_config()
        self.industry_knowledge = get_industry_benchmarks()
        self.analysis_history = []
        
        # è¨­å®šã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®èª­ã¿è¾¼ã¿
        if SETTINGS_AVAILABLE and hasattr(settings, 'prompt_templates'):
            self.prompt_templates = settings.prompt_templates
        else:
            self.prompt_templates = self._get_default_templates()
    
    def _get_default_templates(self) -> Dict[str, str]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"""
        return {
            "sql_planning": """

            # BigQuery SQLã‚¯ã‚¨ãƒªè¨­è¨ˆæ›¸ ä½œæˆæŒ‡ç¤º
            
            ## ã‚ãªãŸã®å½¹å‰²
            ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªç„¶è¨€èªã«ã‚ˆã‚‹è¦æ±‚ã‚’åˆ†æã—ã€ãã‚Œã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®SQLã‚¯ã‚¨ãƒªã®æ§‹æˆè¦ç´ ã‚’**JSONå½¢å¼ã§å‡ºåŠ›ã™ã‚‹**ã€ŒSQLãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€ã§ã™ã€‚
            **é‡è¦: ã‚ãªãŸã¯SQLã‚’ç›´æ¥æ›¸ã„ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚**SQLã‚’çµ„ã¿ç«‹ã¦ã‚‹ãŸã‚ã®ã€Œè¨­è¨ˆæ›¸ã€ã¨ãªã‚‹JSONã‚’ä½œã‚‹ã“ã¨ãŒã€ã‚ãªãŸã®å”¯ä¸€ã®ä»•äº‹ã§ã™ã€‚

            ## ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚
            {user_input}

            ## åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒ
            {table_schema}

            ## ãƒ“ã‚¸ãƒã‚¹ç”¨èªé›†
            {context}

            # â–¼â–¼â–¼ã€é‡è¦ã€‘ã“ã“ã‹ã‚‰ãŒä»Šå›ã®ä¿®æ­£ç®‡æ‰€â–¼â–¼â–¼
            ## è¡Œå‹•åŸå‰‡
            1.  **ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠ:** ã¾ãšã€ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã¨åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒã‚’åˆ†æã—ã€**æœ€ã‚‚è¦æ±‚ã«é©ã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã‚’1ã¤ã ã‘é¸æŠ**ã—ã€ãã®åå‰ã‚’JSONã®`table_to_use`ã‚­ãƒ¼ã«è¨­å®šã™ã‚‹ã“ã¨ã€‚
            2.  **åˆ†æè»¸ã¨æŒ‡æ¨™ã®åˆ†é›¢:** ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’ã€Œä½•ã§ï¼ˆ`dimensions`ï¼‰ã€ã¨ã€Œä½•ã‚’ï¼ˆ`metrics`ï¼‰ã€ã«åˆ†è§£ã—ã¦è€ƒãˆã‚‹ã“ã¨ã€‚
            3.  **ã‚¹ã‚­ãƒ¼ãƒã®å³å®ˆ:** ä¸Šè¨˜ã§é¸æŠã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒã«ãƒªã‚¹ãƒˆã•ã‚Œã¦ã„ãªã„åˆ—åã¯ã€**ã„ã‹ãªã‚‹å ´åˆã‚‚çµ¶å¯¾ã«ä½¿ç”¨ã—ã¦ã¯ãªã‚‰ãªã„ã€‚**

            ## JSONè¨­è¨ˆæ›¸ã®å‡ºåŠ›å½¢å¼ã¨ãƒ«ãƒ¼ãƒ«
            - `table_to_use`: ã‚¯ã‚¨ãƒªã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«åï¼ˆæ–‡å­—åˆ—ï¼‰ã€‚
            - `dimensions`: åˆ†æã®è»¸ã¨ãªã‚‹åˆ—åï¼ˆGROUP BYå¥ã§ä½¿ã†åˆ—ï¼‰ã‚’**æ–‡å­—åˆ—ã®ãƒ•ãƒ©ãƒƒãƒˆãªãƒªã‚¹ãƒˆ**ã§è¨˜è¿°ã€‚ä¾‹: `["CampaignName", "DeviceCategory"]`
            - `metrics`: è¨ˆç®—ã—ãŸã„æŒ‡æ¨™ã‚’è¨˜è¿°ã€‚`alias`ã«ã¯å¿…ãšåˆ†ã‹ã‚Šã‚„ã™ã„åˆ¥åã‚’ä»˜ã‘ã€`expression`ã«ã¯é›†è¨ˆé–¢æ•°ã‚’ä½¿ã£ãŸè¨ˆç®—å¼ã‚’è¨˜è¿°ã€‚
            - `filters`: WHEREå¥ã®æ¡ä»¶ã‚’è¨˜è¿°ã€‚
            - `order_by`: `alias`ã§ä»˜ã‘ãŸåå‰ã‚’ä½¿ã†ã€‚
            - `limit`: çµæœã®è¡Œæ•°ã€‚
            - **å¿…ãšJSONå½¢å¼ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ```json ... ```ï¼‰ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚è§£èª¬ã¯ä¸€åˆ‡ä¸è¦ã§ã™ã€‚**

            ## JSONè¨­è¨ˆæ›¸ã®ä¾‹
            ```json
            {{
            "table_to_use": "LookerStudio_report_keyword",
            "dimensions": ["Keyword"],
            "metrics": [
                {{"alias": "åˆè¨ˆã‚¯ãƒªãƒƒã‚¯æ•°", "expression": "SUM(Clicks)"}},
                {{"alias": "CTR", "expression": "SAFE_DIVIDE(SUM(Clicks), SUM(Impressions))"}}
            ],
            "filters": [],
            "order_by": {{"column": "CTR", "direction": "DESC"}},
            "limit": 10
            }}            
            """,
                        
            "claude_analysis": """
            # ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°åˆ†æå°‚é–€å®¶ã¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„

            ## åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿
            {data_summary}

            ## åˆ†æè¦æ±‚
            {user_input}

            ## æ¥­ç•Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
            {industry_benchmarks}

            ## å‡ºåŠ›è¦æ±‚
            1. **ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼**: é‡è¦ãªæ•°å€¤ã¨ãƒˆãƒ¬ãƒ³ãƒ‰
            2. **ğŸ” ã‚¤ãƒ³ã‚µã‚¤ãƒˆ**: ç™ºè¦‹ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ç‰¹å¾´
            3. **ğŸ’¡ æˆ¦ç•¥ææ¡ˆ**: å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³
            4. **ğŸ“ˆ æ”¹å–„æ–½ç­–**: å„ªå…ˆåº¦é †ã®æ¨å¥¨äº‹é …

            {context}
            """
        }
    
    def generate_sql_plan_prompt(self, user_input: str, context: Dict[str, Any] = None) -> str:
        """ã€æ–°ã€‘SQLã®ã€Œè¨­è¨ˆæ›¸ã€ã‚’AIã«ç”Ÿæˆã•ã›ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
        if context is None:
            context = {}
        
        # BigQueryè¨­å®šã®å–å¾—
        if SETTINGS_AVAILABLE:
            table_schema = get_table_schema_for_prompt()
        else:
            table_schema = "ï¼ˆã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ãªã—ï¼‰"

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®æ§‹ç¯‰
        sql_context = self._build_sql_context(user_input, context)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é©ç”¨
        plan_prompt = self.prompt_templates["sql_planning"].format(
            user_input=user_input,
            table_schema=table_schema,
            context=sql_context
        )
        
        return plan_prompt
    
    def generate_enhanced_claude_prompt(self, user_input: str, data_summary: str, context: Dict[str, Any] = None) -> str:
        """å¼·åŒ–Claudeåˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰"""
        if context is None:
            context = {}
        
        # æ¥­ç•Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æƒ…å ±ã®æº–å‚™
        industry_benchmark_text = self._format_industry_benchmarks()
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®æ§‹ç¯‰  
        claude_context = self._build_claude_context(user_input, context)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é©ç”¨
        enhanced_prompt = self.prompt_templates["claude_analysis"].format(
            user_input=user_input,
            data_summary=data_summary,
            industry_benchmarks=industry_benchmark_text,
            context=claude_context
        )
        
        # Claude ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®èª¿æ•´
        if self.config["claude_model"] == "claude-3-sonnet-20240229":
            enhanced_prompt += "\n\n## åˆ†æå“è³ªè¦æ±‚\n- çµ±è¨ˆçš„ãªæ ¹æ‹ ã‚’æ˜ç¤º\n- å®Ÿè·µçš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’æä¾›\n- ROIãƒ»åŠ¹æœæ¸¬å®šã®è¦³ç‚¹ã‚’å«ã‚ã‚‹"
        
        return enhanced_prompt
    
    def _format_industry_benchmarks(self) -> str:
        """æ¥­ç•Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        benchmark_text = "## ğŸ­ æ¥­ç•Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆæ—¥æœ¬å¸‚å ´ï¼‰\n\n"
        
        for media_type, metrics in self.industry_knowledge.items():
            benchmark_text += f"### {media_type}\n"
            for metric_name, value in metrics.items():
                if "CTR" in metric_name or "CVR" in metric_name:
                    benchmark_text += f"- **{metric_name}**: {value:.1%}\n"
                elif "CPC" in metric_name or "CPA" in metric_name:
                    benchmark_text += f"- **{metric_name}**: Â¥{value:,.0f}\n"
                elif "ROAS" in metric_name:
                    benchmark_text += f"- **{metric_name}**: {value:.1f}å€\n"
                else:
                    benchmark_text += f"- **{metric_name}**: {value}\n"
            benchmark_text += "\n"
        
        return benchmark_text
    
    def _build_sql_context(self, user_input: str, context: Dict[str, Any]) -> str:
        """SQLç”Ÿæˆç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±æ§‹ç¯‰"""
        context_parts = []

        # é–¢é€£ç”¨èªã ã‘ã‚’æŠ½å‡ºã—ã¦è¿½åŠ  â–¼â–¼â–¼
        glossary = extract_relevant_glossary(user_input)
        context_parts.append(glossary)

        # éå»ã®åˆ†æãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å­¦ç¿’
        if self.analysis_history:
            recent_patterns = self._analyze_recent_patterns()
            if recent_patterns:
                context_parts.append(f"## ğŸ“š æœ€è¿‘ã®åˆ†æãƒ‘ã‚¿ãƒ¼ãƒ³\n{recent_patterns}")
        
        # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®è€ƒæ…®
        if context.get("data_period"):
            context_parts.append(f"## ğŸ“… åˆ†ææœŸé–“\n{context['data_period']}")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æ„å›³ã®åˆ†æ
        intent = self._analyze_user_intent(user_input)
        if intent:
            context_parts.append(f"## ğŸ¯ åˆ†ææ„å›³\n{intent}")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®ãƒ’ãƒ³ãƒˆ
        optimization_tips = self._get_optimization_tips(user_input)
        if optimization_tips:
            context_parts.append(f"## âš¡ æœ€é©åŒ–ã®ãƒã‚¤ãƒ³ãƒˆ\n{optimization_tips}")
        
        return "\n\n".join(context_parts) if context_parts else ""
    
    def _build_claude_context(self, user_input: str, context: Dict[str, Any]) -> str:
        """Claudeåˆ†æç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±æ§‹ç¯‰"""
        user_input = context.get("user_input", "") 
        context_parts = []

        # ç”¨èªé›†ã‚’è¿½åŠ 
        glossary = extract_relevant_glossary(user_input)
        context_parts.append(glossary)

        # åˆ†æã®èƒŒæ™¯ãƒ»ç›®çš„
        if context.get("analysis_goal"):
            context_parts.append(f"### ğŸ¯ åˆ†æç›®çš„\n{context['analysis_goal']}")
        
        # éå»ã®åˆ†æçµæœã¨ã®é–¢é€£
        if self.analysis_history:
            previous_insights = self._extract_previous_insights()
            if previous_insights:
                context_parts.append(f"### ğŸ“Š éå»ã®åˆ†æçµæœ\n{previous_insights}")
        
        # ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´ãƒ»åˆ¶ç´„
        data_constraints = self._identify_data_constraints(context)
        if data_constraints:
            context_parts.append(f"### âš ï¸ ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´ãƒ»åˆ¶ç´„\n{data_constraints}")
        
        # ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        business_context = self._get_business_context(context)
        if business_context:
            context_parts.append(f"### ğŸ¢ ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n{business_context}")
        
        return "\n\n".join(context_parts) if context_parts else ""
    
    def _analyze_user_intent(self, user_input: str) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‹ã‚‰åˆ†ææ„å›³ã‚’æ¨å®š"""
        user_lower = user_input.lower()
        
        # æ¯”è¼ƒåˆ†æã®æ„å›³
        if any(word in user_lower for word in ["æ¯”è¼ƒ", "å¯¾æ¯”", "é•ã„", "å·®", "vs"]):
            return "æ¯”è¼ƒåˆ†æ: è¤‡æ•°ã®è¦ç´ ã‚’æ¯”è¼ƒã—ã¦ç›¸å¯¾çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡"
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã®æ„å›³
        elif any(word in user_lower for word in ["ãƒˆãƒ¬ãƒ³ãƒ‰", "æ¨ç§»", "å¤‰åŒ–", "æ™‚ç³»åˆ—"]):
            return "ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ: æ™‚é–“è»¸ã§ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å°†æ¥äºˆæ¸¬"
        
        # æœ€é©åŒ–ã®æ„å›³
        elif any(word in user_lower for word in ["æœ€é©åŒ–", "æ”¹å–„", "åŠ¹ç‡", "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹"]):
            return "æœ€é©åŒ–åˆ†æ: æˆæœæ”¹å–„ã®ãŸã‚ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®šã¨æ”¹å–„ææ¡ˆ"
        
        # è©³ç´°åˆ†æã®æ„å›³
        elif any(word in user_lower for word in ["è©³ç´°", "æ·±å €ã‚Š", "åˆ†æ", "èª¿æŸ»"]):
            return "è©³ç´°åˆ†æ: ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ãªç‰¹å¾´åˆ†æã¨æ´å¯ŸæŠ½å‡º"
        
        return ""
    
    def _get_optimization_tips(self, user_input: str) -> str:
        """SQLæœ€é©åŒ–ã®ãƒ’ãƒ³ãƒˆ"""
        tips = []
        user_lower = user_input.lower()
        
        if any(word in user_lower for word in ["å¤§é‡", "å…¨ãƒ‡ãƒ¼ã‚¿", "å…¨æœŸé–“"]):
            tips.append("ğŸ’¡ å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†: LIMITå¥ã‚„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆTABLESAMPLEï¼‰ã®æ´»ç”¨ã‚’æ¤œè¨")
        
        if any(word in user_lower for word in ["ã‚°ãƒ«ãƒ¼ãƒ—", "é›†è¨ˆ", "åˆè¨ˆ"]):
            tips.append("ğŸ’¡ é›†è¨ˆå‡¦ç†: é©åˆ‡ãªINDEXã¨PARTITION BYå¥ã§é«˜é€ŸåŒ–")
        
        if any(word in user_lower for word in ["çµåˆ", "JOIN", "ãƒãƒ¼ã‚¸"]):
            tips.append("ğŸ’¡ çµåˆå‡¦ç†: å°ã•ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å·¦å´ã«é…ç½®ã—ã€é©åˆ‡ãªçµåˆã‚­ãƒ¼ã‚’ä½¿ç”¨")
        
        return " | ".join(tips) if tips else ""
    
    def _analyze_recent_patterns(self) -> str:
        """æœ€è¿‘ã®åˆ†æãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        if not self.analysis_history:
            return ""
        
        recent_analyses = self.analysis_history[-5:]  # ç›´è¿‘5ä»¶
        patterns = []
        
        # ã‚ˆãä½¿ã‚ã‚Œã‚‹æŒ‡æ¨™
        common_metrics = {}
        for analysis in recent_analyses:
            for metric in analysis.get("metrics_used", []):
                common_metrics[metric] = common_metrics.get(metric, 0) + 1
        
        if common_metrics:
            top_metrics = sorted(common_metrics.items(), key=lambda x: x[1], reverse=True)[:3]
            patterns.append(f"é »ç”¨æŒ‡æ¨™: {', '.join([m[0] for m in top_metrics])}")
        
        return " | ".join(patterns) if patterns else ""
    
    def _extract_previous_insights(self) -> str:
        """éå»ã®åˆ†æçµæœã‹ã‚‰é‡è¦ãªæ´å¯Ÿã‚’æŠ½å‡º"""
        # å®Ÿè£…ï¼šéå»ã®åˆ†æçµæœã‹ã‚‰é‡è¦ãªã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’æŠ½å‡º
        if not self.analysis_history:
            return ""
        
        return "å‰å›åˆ†æã§åŠ¹æœçš„ãªã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç‰¹å®šæ¸ˆã¿"
    
    def _identify_data_constraints(self, context: Dict[str, Any]) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´ãƒ»åˆ¶ç´„ã®è­˜åˆ¥"""
        constraints = []
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®åˆ¶ç´„
        if context.get("row_count"):
            row_count = context["row_count"]
            if row_count > 100000:
                constraints.append("å¤§é‡ãƒ‡ãƒ¼ã‚¿: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¾ãŸã¯æœŸé–“é™å®šã‚’æ¨å¥¨")
            elif row_count < 1000:
                constraints.append("å°‘é‡ãƒ‡ãƒ¼ã‚¿: çµ±è¨ˆçš„æœ‰æ„æ€§ã«æ³¨æ„")
        
        # NULLå€¤ãƒ»å“è³ªã®å•é¡Œ  
        if context.get("data_quality_issues"):
            constraints.append("ãƒ‡ãƒ¼ã‚¿å“è³ª: ä¸€éƒ¨ã®æŒ‡æ¨™ã§NULLå€¤ã‚„ç•°å¸¸å€¤ã‚’æ¤œå‡º")
        
        return " | ".join(constraints) if constraints else ""
    
    def _get_business_context(self, context: Dict[str, Any]) -> str:
        """ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ¨å®š"""
        business_info = []
        
        # æ¥­ç•Œãƒ»äº‹æ¥­ã‚¿ã‚¤ãƒ—ã®æ¨å®š
        if context.get("campaign_types"):
            campaign_types = context["campaign_types"]
            if any("EC" in ct or "é€šè²©" in ct for ct in campaign_types):
                business_info.append("äº‹æ¥­ã‚¿ã‚¤ãƒ—: Eã‚³ãƒãƒ¼ã‚¹ãƒ»é€šè²©ç³»")
            elif any("BtoB" in ct or "æ³•äºº" in ct for ct in campaign_types):
                business_info.append("äº‹æ¥­ã‚¿ã‚¤ãƒ—: BtoBã‚µãƒ¼ãƒ“ã‚¹ç³»")
        
        # äº‹æ¥­è¦æ¨¡ã®æ¨å®š
        if context.get("monthly_spend"):
            monthly_spend = context["monthly_spend"]
            if monthly_spend > 10000000:  # 1000ä¸‡å††ä»¥ä¸Š
                business_info.append("äº‹æ¥­è¦æ¨¡: å¤§è¦æ¨¡ï¼ˆæœˆé¡1000ä¸‡å††ä»¥ä¸Šï¼‰")
            elif monthly_spend > 1000000:  # 100ä¸‡å††ä»¥ä¸Š
                business_info.append("äº‹æ¥­è¦æ¨¡: ä¸­è¦æ¨¡ï¼ˆæœˆé¡100-1000ä¸‡å††ï¼‰")
            else:
                business_info.append("äº‹æ¥­è¦æ¨¡: å°è¦æ¨¡ï¼ˆæœˆé¡100ä¸‡å††æœªæº€ï¼‰")
        
        return " | ".join(business_info) if business_info else ""
    
    def add_analysis_to_history(self, analysis_data: Dict[str, Any]):
        """åˆ†æå±¥æ­´ã¸ã®è¿½åŠ """
        self.analysis_history.append({
            "timestamp": datetime.now(),
            "user_input": analysis_data.get("user_input", ""),
            "sql": analysis_data.get("sql", ""),
            "row_count": analysis_data.get("row_count", 0),
            "metrics_used": analysis_data.get("metrics_used", [])
        })
        
        # å±¥æ­´ã®ä¸Šé™ç®¡ç†ï¼ˆè¨­å®šã‹ã‚‰å–å¾—ï¼‰
        max_history = getattr(settings.app, 'max_analysis_history', 20) if SETTINGS_AVAILABLE else 20
        if len(self.analysis_history) > max_history:
            self.analysis_history = self.analysis_history[-max_history:]

# =========================================================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ« ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒ»é–¢æ•°ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

# å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
try:
    enhanced_prompts = EnhancedPrompts()
    print("âœ… å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
except Exception as e:
    print(f"âš ï¸ å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    enhanced_prompts = None

def generate_sql_plan_prompt(user_input: str, context: Dict[str, Any] = None) -> str:
    """ã€æ–°ã€‘å¼·åŒ–SQLã€Œè¨­è¨ˆæ›¸ã€ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼‰"""
    if enhanced_prompts:
        return enhanced_prompts.generate_sql_plan_prompt(user_input, context)
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        return json.dumps({"error": "Enhanced prompts not available."})

def generate_enhanced_claude_prompt(user_input: str, data_summary: str, context: Dict[str, Any] = None) -> str:
    """å¼·åŒ–Claudeåˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼‰"""
    if enhanced_prompts:
        return enhanced_prompts.generate_enhanced_claude_prompt(user_input, data_summary, context)
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        basic_template = """
ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°åˆ†æå°‚é–€å®¶ã¨ã—ã¦ã€ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ãã ã•ã„:

## ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
{data_summary}

## åˆ†æè¦æ±‚
{user_input}
"""
        return basic_template.format(user_input=user_input, data_summary=data_summary)

def select_enhanced_prompt(user_input: str, context: Dict[str, Any] = None) -> Dict[str, str]:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‹ã‚‰æœ€é©ãªå¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠ"""
    # ... (ã“ã®é–¢æ•°ã®ä¸­èº«ã¯å¤‰æ›´ãªã—) ...
    user_lower = user_input.lower()
    context = context or {}
    
    # æ™‚ç³»åˆ—åˆ†æã®åˆ¤å®š
    if any(keyword in user_lower for keyword in ["æ™‚ç³»åˆ—", "æ¨ç§»", "ãƒˆãƒ¬ãƒ³ãƒ‰", "å¤‰åŒ–", "æœˆåˆ¥", "æ—¥åˆ¥"]):
        return {
            "type": "time_series",
            "description": "æ™‚ç³»åˆ—ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ",
            "template": "æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«ç‰¹åŒ–ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"
        }
    
    # æ¯”è¼ƒåˆ†æã®åˆ¤å®š
    elif any(keyword in user_lower for keyword in ["æ¯”è¼ƒ", "å¯¾æ¯”", "å·®", "é•ã„", "vs", "ãƒ©ãƒ³ã‚­ãƒ³ã‚°"]):
        return {
            "type": "comparison", 
            "description": "æ¯”è¼ƒãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ",
            "template": "è¤‡æ•°è¦ç´ ã®æ¯”è¼ƒã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æã«ç‰¹åŒ–ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"
        }
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã®åˆ¤å®š
    elif any(keyword in user_lower for keyword in ["åŠ¹æœ", "æˆæœ", "roi", "roas", "cpa", "cpc"]):
        return {
            "type": "performance",
            "description": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»åŠ¹æœæ¸¬å®šåˆ†æ", 
            "template": "åºƒå‘ŠåŠ¹æœã¨ROIåˆ†æã«ç‰¹åŒ–ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"
        }
    
    # è©³ç´°åˆ†æã®åˆ¤å®š
    elif any(keyword in user_lower for keyword in ["è©³ç´°", "æ·±å €ã‚Š", "èª¿æŸ»", "åˆ†æ"]):
        return {
            "type": "detailed",
            "description": "è©³ç´°ãƒ»æ·±å €ã‚Šåˆ†æ",
            "template": "ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ç‰¹å¾´ã¨æ·±å±¤æ´å¯Ÿã«ç‰¹åŒ–ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"
        }
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆç·åˆåˆ†æï¼‰
    else:
        return {
            "type": "comprehensive",
            "description": "ç·åˆãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°åˆ†æ",
            "template": "åŒ…æ‹¬çš„ãªãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"
        }

# =========================================================================
# è¨­å®šé€£æºãƒ»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =========================================================================

def get_prompt_settings() -> Dict[str, Any]:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé–¢é€£è¨­å®šã®å–å¾—"""
    if SETTINGS_AVAILABLE:
        return {
            "use_enhanced_prompts": getattr(settings.app, 'use_enhanced_prompts', True),
            "include_benchmarks": getattr(settings.app, 'include_benchmarks', True),
            "context_learning": getattr(settings.app, 'context_learning', True),
            "max_context_length": getattr(settings.ai, 'max_tokens', 4000)
        }
    else:
        return {
            "use_enhanced_prompts": True,
            "include_benchmarks": True,
            "context_learning": True,
            "max_context_length": 4000
        }

def update_industry_benchmarks(new_benchmarks: Dict[str, Dict[str, float]]):
    """æ¥­ç•Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å‹•çš„æ›´æ–°"""
    if enhanced_prompts:
        enhanced_prompts.industry_knowledge.update(new_benchmarks)
        print(f"âœ… æ¥­ç•Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ›´æ–°: {list(new_benchmarks.keys())}")

def get_analysis_history_summary() -> Dict[str, Any]:
    """åˆ†æå±¥æ­´ã®ã‚µãƒãƒªãƒ¼å–å¾—"""
    if not enhanced_prompts or not enhanced_prompts.analysis_history:
        return {"total_analyses": 0, "recent_patterns": []}
    
    history = enhanced_prompts.analysis_history
    return {
        "total_analyses": len(history),
        "recent_patterns": [h.get("user_input", "")[:50] + "..." for h in history[-5:]],
        "last_analysis": history[-1]["timestamp"] if history else None
    }

def reset_analysis_history():
    """åˆ†æå±¥æ­´ã®ãƒªã‚»ãƒƒãƒˆ"""
    if enhanced_prompts:
        enhanced_prompts.analysis_history = []
        print("ğŸ”„ åˆ†æå±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")

# =========================================================================
# ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
# =========================================================================

def test_enhanced_prompts():
    """å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    test_cases = [
        "éå»30æ—¥ã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åˆ¥ã®CTRã¨CVRã‚’æ¯”è¼ƒã—ã¦",
        "ã‚³ã‚¹ãƒˆåŠ¹ç‡ãŒæœ€ã‚‚é«˜ã„åºƒå‘Šã‚°ãƒ«ãƒ¼ãƒ—ã‚’ç‰¹å®šã—ã¦",
        "æœˆåˆ¥ã®å£²ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æã—ã¦",
        "ãƒ‡ãƒã‚¤ã‚¹åˆ¥ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©³ç´°ã«èª¿æŸ»ã—ã¦"
    ]
    
    results = []
    for test_input in test_cases:
        selected = select_enhanced_prompt(test_input)
        results.append({
            "input": test_input,
            "type": selected["type"],
            "description": selected["description"]
        })
    
    return results

def get_system_info() -> Dict[str, Any]:
    """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã®å–å¾—"""
    return {
        "settings_available": SETTINGS_AVAILABLE,
        "enhanced_prompts_active": enhanced_prompts is not None,
        "config": get_llm_config(),
        "prompt_settings": get_prompt_settings(),
        "analysis_history_count": len(enhanced_prompts.analysis_history) if enhanced_prompts else 0
    }

# =========================================================================
# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨å®šæ•°ãƒ»è¨­å®š
# =========================================================================

# å¤–éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªè¨­å®šæƒ…å ±
ENHANCED_PROMPT_CONFIG = {
    "version": "2.0.0-config",
    "settings_available": SETTINGS_AVAILABLE,
    "default_model": get_llm_config()["gemini_model"],
    "supported_analysis_types": ["time_series", "comparison", "performance", "detailed", "comprehensive"]
}

# åˆ©ç”¨å¯èƒ½ãªæ¥­ç•Œã‚¿ã‚¤ãƒ—
SUPPORTED_INDUSTRIES = list(get_industry_benchmarks().keys())

# ã‚ˆãä½¿ç”¨ã•ã‚Œã‚‹åˆ†æãƒ‘ã‚¿ãƒ¼ãƒ³
COMMON_ANALYSIS_PATTERNS = {
    "åŠ¹æœæ¸¬å®š": ["CTR", "CVR", "CPA", "ROASåˆ†æ"],
    "æ¯”è¼ƒåˆ†æ": ["ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³æ¯”è¼ƒ", "ãƒ¡ãƒ‡ã‚£ã‚¢æ¯”è¼ƒ", "æœŸé–“æ¯”è¼ƒ"],
    "ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ": ["æ™‚ç³»åˆ—æ¨ç§»", "å­£ç¯€æ€§åˆ†æ", "æˆé•·ç‡åˆ†æ"],
    "æœ€é©åŒ–": ["äºˆç®—é…åˆ†", "å…¥æœ­æˆ¦ç•¥", "ã‚¿ãƒ¼ã‚²ãƒ†ã‚£ãƒ³ã‚°æœ€é©åŒ–"]
}

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("ğŸ§ª å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    test_results = test_enhanced_prompts()
    for result in test_results:
        print(f"âœ… {result['input'][:30]}... â†’ {result['type']} ({result['description']})")
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º
    system_info = get_system_info()
    print(f"\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±: {system_info}")
    
    print("âœ… å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆå®Œäº†")