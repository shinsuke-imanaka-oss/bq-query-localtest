# main.py - è¨­å®šç®¡ç†å¯¾å¿œç‰ˆ
"""
ãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ - ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«
è¨­å®šä¸€å…ƒç®¡ç†ã‚·ã‚¹ãƒ†ãƒ å¯¾å¿œ
BigQuery + AI(Gemini/Claude) ã«ã‚ˆã‚‹åºƒå‘Šãƒ‡ãƒ¼ã‚¿åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
"""

import sys
import streamlit as st
from dotenv import load_dotenv  # <-- 1. ã“ã®è¡Œã‚’è¿½åŠ 
load_dotenv()  # <-- 2. ã“ã®è¡Œã‚’è¿½åŠ 
st.warning(f"ğŸ StreamlitãŒä½¿ç”¨ä¸­ã®Python: {sys.executable}")
import pandas as pd
import os
import traceback
from datetime import datetime as dt, date
from typing import Dict, List, Optional, Any
import diagnostics
from error_handler import handle_error_with_ai
# from troubleshooter import display_troubleshooting_guide


# =========================================================================
# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆæœ€åˆã«å®Ÿè¡Œï¼‰
# =========================================================================

st.set_page_config(
    page_title="ğŸš€ AIãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =========================================================================
# è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
# =========================================================================

try:
    from bq_tool_config import settings, show_config_panel
    SETTINGS_AVAILABLE = settings is not None
    CONFIG_UI_AVAILABLE = True
    if SETTINGS_AVAILABLE:
        st.success("âœ… è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        
        # è¨­å®šã®æ¤œè¨¼
        validation_result = settings.get_validation_status()
        if not validation_result["valid"]:
            st.error("âŒ è¨­å®šã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:")
            for error in validation_result["errors"]:
                st.error(f"- {error}")
            st.stop()
        if validation_result["warnings"]:
            st.warning("âš ï¸ è¨­å®šã«é–¢ã™ã‚‹è­¦å‘Š:")
            for warning in validation_result["warnings"]:
                st.warning(f"- {warning}")
    else:
        st.error("âŒ è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
        SETTINGS_AVAILABLE = False
        
except ImportError as e:
    st.error(f"è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    SETTINGS_AVAILABLE = False
    CONFIG_UI_AVAILABLE = False
    settings = None

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    def show_config_panel():
        st.error("è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

# =========================================================================
# ã‚¤ãƒ³ãƒãƒ¼ãƒˆçŠ¶æ³ç®¡ç†
# =========================================================================

IMPORT_STATUS = {
    "config.settings": SETTINGS_AVAILABLE,
    "google.cloud.bigquery": False,
    "google.oauth2.service_account": False,
    "google.generativeai": False,
    "anthropic": False,
    "prompts": False,
    "enhanced_prompts": False,
    "ui_main": False,
    "ui_features": False,
    "analysis_controller": False,
    "error_handler": False,
    "data_quality_checker": False,
    "looker_handler": False
}

# =========================================================================
# å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

# Google Cloud & AI
try:
    from google.cloud import bigquery
    from google.oauth2 import service_account
    IMPORT_STATUS["google.cloud.bigquery"] = True
    IMPORT_STATUS["google.oauth2.service_account"] = True
    print("âœ… Google Cloud ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âŒ Google Cloud ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.error("âŒ Google Cloud ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`pip install google-cloud-bigquery` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

try:
    import google.generativeai as genai
    IMPORT_STATUS["google.generativeai"] = True
    print("âœ… Gemini ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âŒ Gemini ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.error("âŒ Gemini ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`pip install google-generativeai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

try:
    import anthropic
    IMPORT_STATUS["anthropic"] = True
    print("âœ… Claude ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âŒ Claude ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.error("âŒ Claude ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`pip install anthropic` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

# =========================================================================
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

# åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ 
try:
    from prompts import (
        select_best_prompt, get_optimized_bigquery_template,
        ANALYSIS_RECIPES, PROMPT_DEFINITIONS
    )
    IMPORT_STATUS["prompts"] = True
    print("âœ… prompts.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ prompts.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    ANALYSIS_RECIPES = {"è‡ªç”±å…¥åŠ›": "è‡ªç”±ã«SQLã‚¯ã‚¨ãƒªã‚„åˆ†æå†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"}
    PROMPT_DEFINITIONS = {}

# å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ 
try:
    from enhanced_prompts import generate_sql_plan_prompt, generate_enhanced_claude_prompt
    IMPORT_STATUS["enhanced_prompts"] = True
    print("âœ… enhanced_prompts.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ enhanced_prompts.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


# =========================================================================
# UIãƒ»åˆ†æåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ 
# =========================================================================

# UI ã‚·ã‚¹ãƒ†ãƒ 
try:
    from ui_main import show_analysis_workbench, show_manual_sql_interface
    IMPORT_STATUS["ui_main"] = True
    print("âœ… ui_main.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ ui_main.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
# UIæ©Ÿèƒ½æ‹¡å¼µ
try:
    from ui_features import (
        show_analysis_summary_panel,
        show_data_quality_panel, 
        show_error_history,
        show_usage_statistics,
        show_quick_reanalysis
    )
    IMPORT_STATUS["ui_features"] = True
    print("âœ… ui_features.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ ui_features.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    IMPORT_STATUS["ui_features"] = False

# åˆ†æåˆ¶å¾¡
try:
    from analysis_controller import run_analysis_flow, execute_sql_query
    IMPORT_STATUS["analysis_controller"] = True
    print("âœ… analysis_controller.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ analysis_controller.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
try:
    from error_handler import handle_error_with_ai
    IMPORT_STATUS["error_handler"] = True
    print("âœ… error_handler.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ error_handler.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    def handle_error_with_ai(*args, **kwargs):
        st.info("ğŸ“Š ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ©Ÿèƒ½ã¯ä¸€æ™‚çš„ã«åˆ©ç”¨ã§ãã¾ã›ã‚“")

# ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
try:
    from data_quality_checker import check_data_quality
    IMPORT_STATUS["data_quality_checker"] = True
    print("âœ… data_quality_checker.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ data_quality_checker.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    def check_data_quality(*args, **kwargs):
        st.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã¯ä¸€æ™‚çš„ã«åˆ©ç”¨ã§ãã¾ã›ã‚“")

# Lookeré€£æº
try:
    from looker_handler import show_looker_studio_integration, show_filter_ui
    from dashboard_analyzer import SHEET_ANALYSIS_QUERIES 
    IMPORT_STATUS["looker_handler"] = True
    print("âœ… looker_handler.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ looker_handler.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    IMPORT_STATUS["looker_handler"] = False

# =========================================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

def ensure_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ç¢ºå®ŸãªåˆæœŸåŒ–ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰"""
    if not SETTINGS_AVAILABLE:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
        defaults = {
            "usage_stats": {"total_analyses": 0, "error_count": 0, "enhanced_usage": 0, "avg_execution_time": 0.0},
            "error_history": [],
            "analysis_history": [],
            "filter_settings": {"start_date": dt.now().date(), "end_date": dt.now().date(), "media": [], "campaigns": []},
            "last_analysis_result": None,
            "last_sql": "",
            "last_user_input": "",
            "auto_claude_analysis": True,
            "view_mode": "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º",
            "accessibility_settings": {"high_contrast": False, "large_text": False, "reduced_motion": False}
        }
    else:
        # è¨­å®šã‹ã‚‰åˆæœŸå€¤ã‚’å–å¾—
        defaults = {
            "usage_stats": {"total_analyses": 0, "error_count": 0, "enhanced_usage": 0, "avg_execution_time": 0.0},
            "error_history": [],
            "analysis_history": [],
            "filter_settings": {"start_date": dt.now().date(), "end_date": dt.now().date(), "media": [], "campaigns": []},
            "last_analysis_result": None,
            "last_sql": "",
            "last_user_input": "",
            "debug_mode": settings.app.debug_mode,
            "auto_claude_analysis": settings.app.auto_claude_analysis,
            "view_mode": "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º",
            "accessibility_settings": {"high_contrast": False, "large_text": False, "reduced_motion": False}
        }

    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# =========================================================================
# APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šãƒ»èªè¨¼ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

def setup_bigquery_client():
    """BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    try:
            # è¨­å®šã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’å–å¾—
        if SETTINGS_AVAILABLE and settings.bigquery.project_id:
            project_id = settings.bigquery.project_id
            location = settings.bigquery.location
        else:
            project_id = None
            location = "US"
        
        # Streamlit Secretsã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
        if "gcp_service_account" in st.secrets:
            credentials_info = st.secrets["gcp_service_account"]
            credentials = service_account.Credentials.from_service_account_info(credentials_info)
            if not project_id:
                project_id = credentials_info.get("project_id")
            client = bigquery.Client(credentials=credentials, project=project_id, location=location)
                
            # âœ… é‡è¦: ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state.bq_client = client
            st.success(f"âœ… BigQueryæ¥ç¶šæˆåŠŸ (Secrets) - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_id}")
            return client
            
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼
        elif "GOOGLE_APPLICATION_CREDENTIALS" in os.environ:
            client = bigquery.Client(project=project_id, location=location)
        
            # âœ… é‡è¦: ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state.bq_client = client
            st.success(f"âœ… BigQueryæ¥ç¶šæˆåŠŸ (ç’°å¢ƒå¤‰æ•°) - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {client.project}")
            return client
            
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆèªè¨¼
        else:
            client = bigquery.Client(project=project_id, location=location)
            
            # âœ… é‡è¦: ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state.bq_client = client
            st.success(f"âœ… BigQueryæ¥ç¶šæˆåŠŸ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ) - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {client.project}")
            return client
    except Exception as e:
        #handle_error_with_ai(e, st.session_state.get("gemini_model"), {"operation": "BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"})
        #if 'bq_client' in st.session_state:
        #    st.session_state.bq_client = None
        #return None            
        raise e


def setup_gemini_client():
    """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰"""
    try:
        if SETTINGS_AVAILABLE:
            api_key = settings.get_api_key("gemini")
            model_name = settings.ai.gemini_model
        else:
            api_key = st.secrets.get("GEMINI_API_KEY") or st.secrets.get("GOOGLE_API_KEY") or os.environ.get("GEMINI_API_KEY") or os.environ.get("GOOGLE_API_KEY")
            model_name = "gemini-1.5-pro"
            
        # â–¼â–¼â–¼ã€é‡è¦ã€‘APIã‚­ãƒ¼ãŒãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚’ä¿®æ­£ â–¼â–¼â–¼
        if not api_key:
            st.error("âŒ Gemini API ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            st.markdown("ğŸ’¡ `secrets.toml` ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã« `GOOGLE_API_KEY` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚è¨­å®šå¾Œã€ã“ã®ãƒœã‚¿ãƒ³ã‚’å†åº¦ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
            return None # ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ãšã«Noneã‚’è¿”ã™
            
        genai.configure(api_key=api_key)
            
        if SETTINGS_AVAILABLE:
            generation_config = {"temperature": settings.ai.temperature, "max_output_tokens": settings.ai.max_tokens}
        else:
            generation_config = {"temperature": 0.3, "max_output_tokens": 4000}
            
        model = genai.GenerativeModel(model_name, generation_config=generation_config)
        st.success(f"âœ… Gemini API æ¥ç¶šæˆåŠŸ - ãƒ¢ãƒ‡ãƒ«: {model_name}")
        return model
    except Exception as e:
        # äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã¯AIã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ã§å‡¦ç†
        handle_error_with_ai(e, None, {"operation": "Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"})
        return None
        

def setup_claude_client():
    """Claude APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰"""
    try:
        # è¨­å®šã‹ã‚‰APIã‚­ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        if SETTINGS_AVAILABLE:
            api_key = settings.get_api_key("claude")
            model_name = settings.ai.claude_model
        else:
            api_key = st.secrets.get("CLAUDE_API_KEY") or st.secrets.get("ANTHROPIC_API_KEY") or os.environ.get("CLAUDE_API_KEY") or os.environ.get("ANTHROPIC_API_KEY")
            model_name = "claude-3-sonnet-20240229"
        
        if not api_key:
            st.error("âŒ Claude API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            st.markdown("ğŸ’¡ `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯Streamlit Secretsã§ `ANTHROPIC_API_KEY` ã‚’è¨­å®šã—ã¦ãã ã•ã„")
            return None, None
            
        client = anthropic.Anthropic(api_key=api_key)
        st.success(f"âœ… Claude API æ¥ç¶šæˆåŠŸ - ãƒ¢ãƒ‡ãƒ«: {model_name}")
        return client, model_name
    except Exception as e:
        #handle_error_with_ai(e, st.session_state.get("gemini_model"), {"operation": "Claudeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"})
        #return None, None
        raise e


# =========================================================================
# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹è¡¨ç¤ºï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

def show_system_status():
    """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®è¡¨ç¤ºï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰"""
    with st.expander("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹", expanded=False):
        st.markdown("### ğŸ“¦ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿çŠ¶æ³")
        for module_name, status in IMPORT_STATUS.items():
            st.markdown(f"{'âœ…' if status else 'âŒ'} **{module_name}**")
        
        st.markdown("---")
        st.markdown("### ğŸ”‘ APIæ¥ç¶šçŠ¶æ³")
        st.markdown(f"**BigQuery**: {'âœ… æ¥ç¶šæ¸ˆã¿' if st.session_state.get('bq_client') else 'âŒ æœªæ¥ç¶š'}")
        st.markdown(f"**Gemini**: {'âœ… æ¥ç¶šæ¸ˆã¿' if st.session_state.get('gemini_model') else 'âŒ æœªæ¥ç¶š'}")
        st.markdown(f"**Claude**: {'âœ… æ¥ç¶šæ¸ˆã¿' if st.session_state.get('claude_client') else 'âŒ æœªæ¥ç¶š'}")
        
        if SETTINGS_AVAILABLE:
            st.markdown("---")
            st.markdown("### âš™ï¸ è¨­å®šæƒ…å ±")
            st.markdown(f"**Geminiãƒ¢ãƒ‡ãƒ«**: {settings.ai.gemini_model}")
            st.markdown(f"**Claudeãƒ¢ãƒ‡ãƒ«**: {settings.ai.claude_model}")
            st.markdown(f"**Temperature**: {settings.ai.temperature}")
            st.markdown(f"**BigQueryãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: {settings.bigquery.project_id or 'æœªè¨­å®š'}")
            st.markdown(f"**ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰**: {'âœ… æœ‰åŠ¹' if settings.app.debug_mode else 'âŒ ç„¡åŠ¹'}")

def show_settings_panel():
    """è¨­å®šãƒ‘ãƒãƒ«è¡¨ç¤º"""
    if not SETTINGS_AVAILABLE:
        st.warning("âš ï¸ è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return
    
    with st.expander("âš™ï¸ è¨­å®šç®¡ç†", expanded=False):
        st.markdown("### ğŸ“‹ ç¾åœ¨ã®è¨­å®š")
        
        # LLMè¨­å®š
        st.markdown("**ğŸ¤– LLMè¨­å®š**")
        st.code(f"""
Geminiãƒ¢ãƒ‡ãƒ«: {settings.ai.gemini_model}
Claudeãƒ¢ãƒ‡ãƒ«: {settings.ai.claude_model}
Temperature: {settings.ai.temperature}
æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {settings.ai.max_tokens}
        """)
        
        # BigQueryè¨­å®š
        st.markdown("**ğŸ“Š BigQueryè¨­å®š**")
        st.code(f"""
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID: {settings.bigquery.project_id or 'æœªè¨­å®š'}
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {settings.bigquery.dataset}
ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹: {settings.bigquery.table_prefix}
ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³: {settings.bigquery.location}
        """)
        
        # è¨­å®šå†èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ è¨­å®šã‚’å†èª­ã¿è¾¼ã¿", help="ç’°å¢ƒå¤‰æ•°ã‚„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›´ã‚’åæ˜ ã—ã¾ã™"):
            try:
                settings.reload_settings()
                st.success("âœ… è¨­å®šã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ")
                st.rerun()
            except Exception as e:
                st.error(f"âŒ è¨­å®šå†èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# =========================================================================
# ãƒ¡ã‚¤ãƒ³è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

# main.py ã®show_dashboard_modeé–¢æ•°ã‚’ä»¥ä¸‹ã«ç½®ãæ›ãˆ

def show_dashboard_mode():
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ï¼ˆLooker Studioæ©Ÿèƒ½å¾©æ´»ç‰ˆï¼‰"""
    st.header("ğŸ“Š Looker Studio ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    
    # BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ç¢ºèª
    bq_client = st.session_state.get("bq_client")
    if not bq_client:
        st.warning("âš ï¸ BigQueryæ¥ç¶šãŒå¿…è¦ã§ã™")
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€ŒğŸ”„ BigQueryæ¥ç¶šã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
        return
    
    # Lookeré€£æºæ©Ÿèƒ½ã®ç¢ºèª
    if IMPORT_STATUS.get("looker_handler", False):
        try:
            from looker_handler import show_looker_studio_integration, show_filter_ui
            
            # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼UIè¡¨ç¤º
            with st.sidebar:
                st.markdown("### ğŸ“Š Looker Studio ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
                show_filter_ui(bq_client)
            
            # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã§Looker Studioè¡¨ç¤º
            show_looker_studio_integration(
                bq_client=bq_client,
                model=st.session_state.get("gemini_model"),
                key_prefix="dashboard",
                sheet_analysis_queries=SHEET_ANALYSIS_QUERIES
            )
            
        except ImportError as e:
            st.error(f"âŒ Lookeræ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            show_fallback_dashboard()
        except Exception as e:
            st.error(f"âŒ Lookeræ©Ÿèƒ½ã®ã‚¨ãƒ©ãƒ¼: {e}")
            show_fallback_dashboard()
    else:
        show_fallback_dashboard()

def show_fallback_dashboard():
    """Lookeræ©Ÿèƒ½ãŒä½¿ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    st.info("ğŸ“Š Looker Studioé€£æºæ©Ÿèƒ½ã¯æº–å‚™ä¸­ã§ã™")
    
    # åŸºæœ¬çš„ãªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä»£æ›¿æ©Ÿèƒ½
    st.markdown("### ğŸ“ˆ åŸºæœ¬åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    
    # åˆ†æçµ±è¨ˆè¡¨ç¤º
    if "usage_stats" in st.session_state:
        stats = st.session_state.usage_stats
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ç·åˆ†ææ•°", stats.get("total_analyses", 0))
        with col2:
            st.metric("æˆåŠŸåˆ†æ", stats.get("total_analyses", 0) - stats.get("error_count", 0))
        with col3:
            st.metric("é«˜å“è³ªåˆ†æ", stats.get("enhanced_usage", 0))
    
    # æœ€æ–°åˆ†æçµæœè¡¨ç¤º
    if st.session_state.get("last_analysis_result") is not None:
        st.markdown("### ğŸ“Š æœ€æ–°ã®åˆ†æçµæœ")
        df = st.session_state.last_analysis_result
        st.dataframe(df.head(10), width='stretch')
        
        # åŸºæœ¬çµ±è¨ˆ
        if len(df.select_dtypes(include=['number']).columns) > 0:
            st.markdown("### ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ")
            st.write(df.describe())
    
    st.info("ğŸ’¡ å®Œå…¨ãªLooker Studioæ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ã€looker_handler.pyã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„")

def show_semantic_search_ui():
    """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æã®UIã‚’è¡¨ç¤ºã™ã‚‹"""
    st.markdown("---")
    st.subheader("ğŸ§  é¡ä¼¼ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³æ¤œç´¢")
    
    # BigQueryã‹ã‚‰å…¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´»ç”¨ï¼‰
    @st.cache_data(ttl=3600)
    def get_all_campaign_names(_bq_client): # bq_client -> _bq_client ã«å¤‰æ›´
        if not _bq_client: # bq_client -> _bq_client ã«å¤‰æ›´
            return []
        try:
            query = "SELECT DISTINCT CampaignName FROM `vorn-digi-mktg-poc-635a.toki_air.LookerStudio_report_campaign` WHERE CampaignName IS NOT NULL"
            df = _bq_client.query(query).to_dataframe() # bq_client -> _bq_client ã«å¤‰æ›´
            return df["CampaignName"].tolist()
        except Exception as e:
            st.warning(f"ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åã®å–å¾—ã«å¤±æ•—: {e}")
            return []

    bq_client = st.session_state.get("bq_client")
    all_campaigns = get_all_campaign_names(bq_client)

    if not all_campaigns:
        st.warning("åˆ†æå¯¾è±¡ã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚BigQueryã«æ¥ç¶šã—ã¦ãã ã•ã„ã€‚")
        return

    # æ¤œç´¢UI
    target_campaign = st.selectbox("åŸºæº–ã¨ãªã‚‹ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„", options=all_campaigns)

    if st.button("é¡ä¼¼ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’æ¤œç´¢ã™ã‚‹", width='stretch'):
        if target_campaign:
            from semantic_analyzer import generate_embeddings, find_similar_texts
            
            # å…¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒåŠ¹ãï¼‰
            all_embeddings = generate_embeddings(all_campaigns)
            
            if all_embeddings:
                # é¡ä¼¼ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’æ¤œç´¢
                similar_campaigns_df = find_similar_texts(target_campaign, all_embeddings, top_n=5)
                
            if similar_campaigns_df is not None:
                st.success("é¡ä¼¼ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
                # st.dataframe ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«å¤‰æ›´
                st.dataframe(
                    similar_campaigns_df,
                    column_config={
                        "text": st.column_config.TextColumn("ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å", width="large"),
                        "similarity": st.column_config.ProgressColumn(
                            "é–¢é€£æ€§ã‚¹ã‚³ã‚¢",
                            help="åŸºæº–ãƒ†ã‚­ã‚¹ãƒˆã¨ã®æ„å‘³çš„ãªè¿‘ã•ï¼ˆ1ã«è¿‘ã„ã»ã©é–¢é€£æ€§ãŒé«˜ã„ï¼‰",
                            format="%.3f",
                            min_value=0,
                            max_value=1,
                        ),
                    },
                    use_container_width=True,
                    hide_index=True
                )
        else:
            st.error("åŸºæº–ã¨ãªã‚‹ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

def show_auto_grouping_ui():
    """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æã«ã‚ˆã‚‹è‡ªå‹•ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°UI (çµæœä¿æŒæ©Ÿèƒ½ä»˜ã)"""
    st.markdown("---")
    st.subheader("ğŸ§  åºƒå‘Šã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–è‡ªå‹•ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°")
    st.markdown("AIãŒãƒ‡ãƒ¼ã‚¿ã®å¯†åº¦ã«åŸºã¥ãã€æ„å‘³çš„ã«è‡ªç„¶ãªã‚°ãƒ«ãƒ¼ãƒ—ã‚’è‡ªå‹•ã§ç™ºè¦‹ã—ã¾ã™ã€‚")

    # --- 1. éå»ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå‚ç…§ï¼‰æ©Ÿèƒ½ ---
    with st.expander("ğŸ“‚ éå»ã®ã‚¿ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å‚ç…§ã™ã‚‹"):
        uploaded_file = st.file_uploader(
            "ä¿å­˜ã—ãŸã‚¿ã‚°æƒ…å ±CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            type="csv",
            key="grouping_csv_uploader", # keyã‚’è¿½åŠ ã—ã¦ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’åŒºåˆ¥
            help="ä»¥å‰ã«ã“ã®ã‚¢ãƒ—ãƒªã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸ `semantic_tags_...csv` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"
        )
        if uploaded_file is not None:
            try:
                past_tags_df = pd.read_csv(uploaded_file)
                if 'ad_text' in past_tags_df.columns:
                    past_tags_df.rename(columns={'ad_text': 'analyzed_text'}, inplace=True)
                required_columns = ['analyzed_text', 'cluster_id', 'tag']
                if not all(col in past_tags_df.columns for col in required_columns):
                     st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚{', '.join(required_columns)} ãŒå«ã¾ã‚Œã‚‹CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                else:
                    st.success(f"âœ… {len(past_tags_df)}ä»¶ã®éå»ã®ã‚¿ã‚°æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
                    st.dataframe(past_tags_df, use_container_width=True)
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    st.markdown("---")

    bq_client = st.session_state.get("bq_client")
    if not bq_client:
        st.warning("BigQueryã«æ¥ç¶šã—ã¦ãã ã•ã„ã€‚")
        return

    # --- åˆ†æå¯¾è±¡ã®å®šç¾© ---
    ANALYSIS_TARGETS = {
        "åºƒå‘Šæ–‡ (Headline)": ("LookerStudio_report_ad", "Headline"),
        "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ("LookerStudio_report_keyword", "Keyword"),
        "åºƒå‘Šã‚°ãƒ«ãƒ¼ãƒ—å": ("LookerStudio_report_ad_group", "AdGroupName_unified"),
        "ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å": ("LookerStudio_report_campaign", "CampaignName"),
    }

    selected_target_label = st.selectbox(
        "åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
        options=list(ANALYSIS_TARGETS.keys()),
        index=0
    )
    table_name, selected_column = ANALYSIS_TARGETS[selected_target_label]

    @st.cache_data(ttl=3600)
    def get_text_data(_bq_client, table_name, column_name):
        query = f"""
        SELECT DISTINCT {column_name} AS text_data
        FROM `vorn-digi-mktg-poc-635a.toki_air.{table_name}`
        WHERE {column_name} IS NOT NULL AND LENGTH({column_name}) > 5
        LIMIT 500
        """
        try:
            df = _bq_client.query(query).to_dataframe()
            return df["text_data"].tolist()
        except Exception as e:
            st.error(f"ã€Œ{column_name}ã€åˆ—ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—: {e}")
            return []

    ad_texts = get_text_data(bq_client, table_name, selected_column)
    if not ad_texts:
        st.info(f"åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ{selected_column}ï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    min_cluster_size = st.slider(
        "ã‚°ãƒ«ãƒ¼ãƒ—ã®æœ€å°ã‚µã‚¤ã‚º",
        min_value=2, max_value=10, value=3,
        help="ä½•å€‹ä»¥ä¸Šã®åºƒå‘Šæ–‡ãŒé›†ã¾ã£ãŸã‚‰ä¸€ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã¨è¦‹ãªã™ã‹ã‚’è¨­å®šã—ã¾ã™ã€‚"
    )

    # â–¼â–¼â–¼ã€ã“ã“ã‹ã‚‰ãŒä»Šå›ã®ä¿®æ­£ç®‡æ‰€ã§ã™ã€‘â–¼â–¼â–¼

    # --- å®Ÿè¡Œãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç† ---
    if st.button("ğŸš€ ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°å®Ÿè¡Œ", type="primary"):
        with st.spinner("AIã«ã‚ˆã‚‹ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œä¸­ã§ã™..."):
            from semantic_analyzer import group_texts_by_meaning, extract_tags_for_cluster, reduce_dimensions_for_visualization, generate_embeddings
            import pandas as pd

            grouped_df = group_texts_by_meaning(ad_texts, min_cluster_size=min_cluster_size)

            if grouped_df is not None:
                grouped_df_for_tags = grouped_df[grouped_df['cluster'] != -1].copy()
                gemini_model = st.session_state.get("gemini_model")
                cluster_tags = extract_tags_for_cluster(grouped_df_for_tags, gemini_model)
                cluster_themes = {cluster_id: ", ".join(tags) for cluster_id, tags in cluster_tags.items()}
                cluster_themes[-1] = "ãƒã‚¤ã‚º / åˆ†é¡å¤–"

                embeddings_dict = generate_embeddings(grouped_df['text'].tolist())
                vis_df = None
                if embeddings_dict:
                    vis_df_raw = reduce_dimensions_for_visualization(embeddings_dict)
                    if vis_df_raw is not None:
                        vis_df = pd.merge(vis_df_raw, grouped_df, on='text')
                        vis_df['theme'] = vis_df['cluster'].map(cluster_themes)

                # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                st.session_state.grouping_results = {
                    "grouped_df": grouped_df,
                    "cluster_themes": cluster_themes,
                    "vis_df": vis_df,
                    "cluster_tags": cluster_tags,
                    "selected_column": selected_column # åˆ†æå¯¾è±¡åˆ—ã‚‚ä¿å­˜
                }
            else:
                st.session_state.grouping_results = None
                st.error("ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ã•ã‚ŒãŸçµæœãŒã‚ã‚Œã°è¡¨ç¤ºã™ã‚‹ ---
    if "grouping_results" in st.session_state and st.session_state.grouping_results:
        import plotly.express as px
        import pandas as pd

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰çµæœã‚’èª­ã¿è¾¼ã‚€
        results = st.session_state.grouping_results
        grouped_df = results["grouped_df"]
        cluster_themes = results["cluster_themes"]
        vis_df = results["vis_df"]
        cluster_tags = results["cluster_tags"]
        selected_column = results["selected_column"]

        st.subheader("ğŸ“Š ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°çµæœ")

        # å¯è¦–åŒ–
        if vis_df is not None:
            fig = px.scatter(
                vis_df, x='x', y='y', color='theme', hover_name='text',
                title='åºƒå‘Šã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã®æ¦‚å¿µãƒãƒƒãƒ—', labels={'color': 'ã‚°ãƒ«ãƒ¼ãƒ—ãƒ†ãƒ¼ãƒ'},
                color_discrete_map={"ãƒã‚¤ã‚º / åˆ†é¡å¤–": "lightgrey"}
            )
            fig.update_layout(legend_title_text='<b>æ¦‚å¿µã‚°ãƒ«ãƒ¼ãƒ—</b>')
            st.plotly_chart(fig, use_container_width=True)

        # å„ã‚¯ãƒ©ã‚¹ã‚¿ã®è©³ç´°
        for cluster_id in sorted(grouped_df['cluster'].unique()):
            if cluster_id == -1: continue
            theme_name = cluster_themes.get(cluster_id, f"ã‚°ãƒ«ãƒ¼ãƒ— {cluster_id + 1}")
            with st.expander(f"**{theme_name}** ({len(grouped_df[grouped_df['cluster'] == cluster_id])}ä»¶)"):
                st.dataframe(grouped_df[grouped_df['cluster'] == cluster_id][['text']], use_container_width=True)

        noise_df = grouped_df[grouped_df['cluster'] == -1]
        if not noise_df.empty:
            with st.expander(f"**ãƒã‚¤ã‚º / åˆ†é¡å¤–** ({len(noise_df)}ä»¶)"):
                st.dataframe(noise_df[['text']], use_container_width=True)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
        st.markdown("---")
        st.subheader("ğŸ’¾ ä»Šå›ã®åˆ†æçµæœã‚’ä¿å­˜")
        
        tags_to_save = []
        for cluster_id, tags in cluster_tags.items():
            texts_in_cluster = grouped_df[grouped_df['cluster'] == cluster_id]['text']
            for text in texts_in_cluster:
                for tag in tags:
                    tags_to_save.append({
                        "analyzed_text": text,
                        "cluster_id": cluster_id,
                        "tag": tag,
                        "analysis_timestamp": pd.Timestamp.now(tz="Asia/Tokyo").isoformat()
                    })
        save_df = pd.DataFrame(tags_to_save)

        if not save_df.empty:
            save_df['analysis_target_column'] = selected_column
            new_column_order = ['analysis_target_column', 'analyzed_text', 'cluster_id', 'tag', 'analysis_timestamp']
            save_df = save_df[new_column_order]

        st.download_button(
            label="ğŸ“¥ ã“ã®ã‚¿ã‚°ä»˜ã‘çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=save_df.to_csv(index=False, encoding='utf-8-sig'),
            file_name=f"semantic_tags_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.csv",
            mime='text/csv',
        )

def show_ai_mode():
    """AIåˆ†æãƒ¢ãƒ¼ãƒ‰"""
    if IMPORT_STATUS["ui_main"]:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰å¿…è¦ãªæƒ…å ±ã‚’å–å¾—
        gemini_model = st.session_state.get("gemini_model")
        claude_client = st.session_state.get("claude_client")
        claude_model_name = st.session_state.get("claude_model_name")
        
        # SHEET_ANALYSIS_QUERIESã®å–å¾—
        sheet_analysis_queries = globals().get("SHEET_ANALYSIS_QUERIES", {})
        
        show_analysis_workbench(gemini_model, claude_client, claude_model_name, sheet_analysis_queries)

        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æãŒæœ‰åŠ¹ãªå ´åˆã®ã¿ã€æ¤œç´¢UIã‚’è¡¨ç¤º
        if st.session_state.get("use_semantic_analysis", False):
            show_semantic_search_ui() # æ—¢å­˜ã®é¡ä¼¼æ¤œç´¢UI
            show_auto_grouping_ui()   # æ–°ã—ãè¿½åŠ ã™ã‚‹ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°UI
    else:
        st.error("âŒ AIåˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

def show_manual_mode():
    """æ‰‹å‹•SQLå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰"""
    if IMPORT_STATUS["ui_main"]:
        show_manual_sql_interface()
    else:
        st.error("âŒ æ‰‹å‹•SQLæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

def show_monitoring_dashboard():
    """ä½¿ç”¨çŠ¶æ³ã‚„ã‚¨ãƒ©ãƒ¼å±¥æ­´ã‚’è¡¨ç¤ºã™ã‚‹ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    st.header("ğŸ“ˆ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

    if st.button("ğŸ”„ æœ€æ–°ã®æƒ…å ±ã«æ›´æ–°"):
        st.rerun()

    st.subheader("ğŸ“Š ä½¿ç”¨çŠ¶æ³ã‚µãƒãƒªãƒ¼")
    
    # st.session_stateã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
    stats = st.session_state.get("usage_stats", {})
    total_analyses = stats.get("total_analyses", 0)
    error_count = stats.get("error_count", 0)
    enhanced_usage = stats.get("enhanced_usage", 0)
    
    success_rate = ((total_analyses - error_count) / total_analyses * 100) if total_analyses > 0 else 0

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç·åˆ†æå›æ•°", f"{total_analyses} å›")
    with col2:
        st.metric("ã‚¨ãƒ©ãƒ¼å›æ•°", f"{error_count} å›")
    with col3:
        st.metric("æˆåŠŸç‡", f"{success_rate:.1f} %")
    with col4:
        st.metric("é«˜å“è³ªåˆ†æ", f"{enhanced_usage} å›")

    st.subheader("âš ï¸ ã‚¨ãƒ©ãƒ¼å±¥æ­´")
    
    error_history = st.session_state.get("error_history", [])
    if not error_history:
        st.success("âœ… ã“ã‚Œã¾ã§ã«è¨˜éŒ²ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        # ç›´è¿‘5ä»¶ã®ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤º
        with st.expander(f"ç›´è¿‘ã®ã‚¨ãƒ©ãƒ¼å±¥æ­´ ({len(error_history)}ä»¶)"):
            for i, error_info in enumerate(reversed(error_history[-5:])):
                st.error(f"**ã‚¨ãƒ©ãƒ¼ #{len(error_history)-i}:** {error_info.get('timestamp')}")
                st.code(error_info.get('error_message', 'è©³ç´°ä¸æ˜'), language='text')

def show_environment_debug_page():
    """
    ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œç’°å¢ƒã‚’å¾¹åº•çš„ã«è‡ªå·±è¨ºæ–­ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒãƒƒã‚°ãƒšãƒ¼ã‚¸
    """
    st.header("ğŸ”¬ ç’°å¢ƒè‡ªå·±è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ")

    st.subheader("1. Pythonå®Ÿè¡Œç’°å¢ƒ")
    st.markdown("ç¾åœ¨ã“ã®Streamlitã‚¢ãƒ—ãƒªã‚’å‹•ã‹ã—ã¦ã„ã‚‹Pythonã®å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚")
    st.code(sys.executable, language="text")

    st.subheader("2. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ¤œç´¢ãƒ‘ã‚¹")
    st.markdown("PythonãŒãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ¢ã—ã«è¡Œããƒ•ã‚©ãƒ«ãƒ€ã®ä¸€è¦§ã§ã™ã€‚ã“ã®ä¸­ã«`venv\\Lib\\site-packages`ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.json(sys.path)

    st.subheader("3. å®Ÿéš›ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª")
    st.markdown("ä¸Šè¨˜ã®Pythonç’°å¢ƒã«ã€ç¾åœ¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä¸€è¦§ã§ã™ã€‚")
    st.info("ã€Œ`pip freeze`ã®çµæœã‚’ã“ã“ã«å‡ºåŠ›ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

    if st.button("`pip freeze`ã®çµæœã‚’ã“ã“ã«å‡ºåŠ›"):
        import subprocess
        try:
            with st.spinner("ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸€è¦§ã‚’å–å¾—ä¸­..."):
                # sys.executable ã‚’ä½¿ã£ã¦ã€ç¾åœ¨å®Ÿè¡Œä¸­ã®Pythonã§pipã‚’å®Ÿè¡Œã™ã‚‹
                result = subprocess.run(
                    [sys.executable, "-m", "pip", "freeze"],
                    capture_output=True,
                    text=True,
                    check=True
                )
                st.code(result.stdout, language="text")
        except Exception as e:
            st.error(f"pip freezeã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.code(traceback.format_exc())

    st.subheader("4. `google-cloud-aiplatform` ã®ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ")
    st.markdown("ã“ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€ã“ã®ã‚¢ãƒ—ãƒªãŒ `google-cloud-aiplatform` ã‚’ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã‚‹ã‹è©¦ã—ã¾ã™ã€‚")
    if st.button("ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"):
        try:
            with st.spinner("ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦ã¿ã¦ã„ã¾ã™..."):
                from google.cloud import aiplatform
                st.success("âœ… `from google.cloud import aiplatform` ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«æˆåŠŸã—ã¾ã—ãŸï¼")
                st.write(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å ´æ‰€: `{aiplatform.__file__}`")
        except Exception as e:
            st.error("âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.code(traceback.format_exc())

def show_glossary_ui():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ç”¨èªé›†ã‚’è¡¨ç¤ºã™ã‚‹UI"""
    with st.sidebar.expander("ğŸ“– ãƒ“ã‚¸ãƒã‚¹ç”¨èªé›†"):
        try:
            # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã“ã“ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            import pandas as pd
            from pathlib import Path

            glossary_path = Path("glossary.csv")
            if glossary_path.exists():
                df = pd.read_csv(glossary_path)
                # hide_index=True ã§DataFrameã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0, 1, 2...ï¼‰ã‚’éè¡¨ç¤ºã«ã™ã‚‹
                st.dataframe(df, hide_index=True)
                st.caption("ã“ã®ç”¨èªé›†ã¯ `glossary.csv` ã‚’ç·¨é›†ã™ã‚‹ã“ã¨ã§æ›´æ–°ã§ãã¾ã™ã€‚")
            else:
                st.info("`glossary.csv` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        except Exception as e:
            st.error(f"ç”¨èªé›†ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")

# =========================================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =========================================================================

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•°ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰"""
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
    st.title("ğŸš€ AIãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ")
    
    if SETTINGS_AVAILABLE:
        st.success("âœ… è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒä¸­")
    else:
        st.warning("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œä¸­ï¼ˆè¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ æœªä½¿ç”¨ï¼‰")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
    ensure_session_state()
    
    # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ãƒ»è¨­å®šãƒ‘ãƒãƒ«
    col1, col2 = st.columns([3, 1])
    with col2:
        show_system_status()
        show_settings_panel()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
    with st.sidebar:
        st.header("ğŸ›ï¸ ã‚·ã‚¹ãƒ†ãƒ åˆ¶å¾¡")
        
        # è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰é¸æŠ
        view_options = ["ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º", "ğŸ¤– AIåˆ†æ", "âš™ï¸ æ‰‹å‹•SQLå®Ÿè¡Œ", "ğŸ©º ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­", "ğŸ“ˆ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", "ğŸ”¬ ç’°å¢ƒãƒ‡ãƒãƒƒã‚°"]
        st.session_state.view_mode = st.selectbox(
            "è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰é¸æŠ",
            view_options,
            index=view_options.index(st.session_state.get("view_mode", "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º"))
        )
        
        st.markdown("---")
        
        # APIæ¥ç¶šè¨­å®š
        st.markdown("### ğŸ”Œ APIæ¥ç¶š")
        
        # BigQueryæ¥ç¶š
        if st.button("ğŸ”„ BigQueryæ¥ç¶š", width='stretch'):
            try: # â† try ã‚’è¿½åŠ 
                with st.spinner("BigQueryæ¥ç¶šä¸­..."):
                    bq_client = setup_bigquery_client()
                    if bq_client:
                        st.session_state.bq_client = bq_client
            except Exception as e: # â† except ã‚’è¿½åŠ 
                handle_error_with_ai(e, st.session_state.get("gemini_model"), {"operation": "BigQueryæ¥ç¶šãƒœã‚¿ãƒ³"})
        
        # Geminiæ¥ç¶š
        if st.button("ğŸ”„ Geminiæ¥ç¶š", width='stretch'):
            try: # â† try ã‚’è¿½åŠ 
                with st.spinner("Gemini APIæ¥ç¶šä¸­..."):
                    gemini_model = setup_gemini_client()
                    if gemini_model:
                        st.session_state.gemini_model = gemini_model
            except Exception as e: # â† except ã‚’è¿½åŠ 
                handle_error_with_ai(e, None, {"operation": "Geminiæ¥ç¶šãƒœã‚¿ãƒ³"})

        # Claudeæ¥ç¶š
        if st.button("ğŸ”„ Claudeæ¥ç¶š", width='stretch'):
            try: # â† try ã‚’è¿½åŠ 
                with st.spinner("Claude APIæ¥ç¶šä¸­..."):
                    claude_client, claude_model_name = setup_claude_client()
                    if claude_client and claude_model_name:
                        st.session_state.claude_client = claude_client
                        st.session_state.claude_model_name = claude_model_name
            except Exception as e: # â† except ã‚’è¿½åŠ 
                handle_error_with_ai(e, st.session_state.get("gemini_model"), {"operation": "Claudeæ¥ç¶šãƒœã‚¿ãƒ³"})

        st.markdown("---")

        if st.button("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š", width='stretch'):
            st.session_state.show_config_panel = True
            st.rerun()
        
        # ç”¨èªé›†è¡¨ç¤ºUIã‚’å‘¼ã³å‡ºã™
        show_glossary_ui()

        # --- â†“â†“â†“ ã“ã“ã‹ã‚‰ãŒè¿½åŠ ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã§ã™ â†“â†“â†“ ---
        st.markdown("---")
        st.markdown("### ğŸ§  AIæ‹¡å¼µæ©Ÿèƒ½")

        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æã®ã‚ªãƒ³/ã‚ªãƒ•ãƒˆã‚°ãƒ«
        st.session_state.use_semantic_analysis = st.toggle(
            "ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æã‚’æœ‰åŠ¹ã«ã™ã‚‹",
            value=st.session_state.get("use_semantic_analysis", False), # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚ªãƒ•
            help="ã‚ªãƒ³ã«ã™ã‚‹ã¨ã€ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åã‚„åºƒå‘Šæ–‡ã®æ„å‘³çš„ãªé¡ä¼¼æ€§åˆ†æãªã©ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ãŒã€å‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"
        )
        
        # ãƒ‡ãƒãƒƒã‚°è¨­å®š
        # Streamlitã®keyã‚’ä½¿ã£ã¦ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ç›´æ¥ç´ä»˜ã‘ã‚‹
        st.checkbox(
            "ğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰",
            key="debug_mode",
            help="ã‚ªãƒ³ã«ã™ã‚‹ã¨ã€ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«AIã®å†…éƒ¨çš„ãªå¿œç­”ã‚„ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ãªã©ã®è©³ç´°æƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
        )

        if st.session_state.debug_mode:
            st.markdown("**ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±**")
            
            # ç°¡æ˜“ã‚µãƒãƒªãƒ¼è¡¨ç¤º
            st.json({
                "ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚­ãƒ¼æ•°": len(st.session_state.keys()),
                "è¨­å®šã‚·ã‚¹ãƒ†ãƒ ": "âœ… åˆ©ç”¨å¯èƒ½" if SETTINGS_AVAILABLE else "âŒ åˆ©ç”¨ä¸å¯",
                "æœ€å¾Œã®åˆ†æ": st.session_state.get("last_user_input", "ãªã—")[:50] + "..."
            })
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®å…¨å†…å®¹è¡¨ç¤ºæ©Ÿèƒ½ã‚’è¿½åŠ 
            with st.expander("ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ï¼ˆst.session_stateï¼‰ã®å…¨å†…å®¹ã‚’è¡¨ç¤º"):
                st.json(st.session_state.to_dict(), expanded=False)


    # ğŸ”§ è¨­å®šãƒ‘ãƒãƒ«è¡¨ç¤ºå‡¦ç†ã‚’è¿½åŠ 
    if st.session_state.get("show_config_panel", False):
        if CONFIG_UI_AVAILABLE:
            show_config_panel()
        else:
            st.error("è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
        if st.button("âŒ è¨­å®šãƒ‘ãƒãƒ«ã‚’é–‰ã˜ã‚‹"):
            st.session_state.show_config_panel = False
            st.rerun()
        return

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¡¨ç¤º
    with col1:
        try:
            # â–¼â–¼â–¼ã€é‡è¦ã€‘ã“ã“ã‹ã‚‰ãŒä¿®æ­£ç®‡æ‰€ â–¼â–¼â–¼
            # ã©ã®ãƒ¢ãƒ¼ãƒ‰ã‚ˆã‚Šã‚‚å…ˆã«ã€ä¿®æ­£æ¡ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»é¢ã‚’è¡¨ç¤ºã™ã‚‹ã‹ã‚’æœ€å„ªå…ˆã§ãƒã‚§ãƒƒã‚¯
            if st.session_state.get("show_fix_review"):
                from ui_main import show_sql_fix_review_ui
                show_sql_fix_review_ui()
            
            # ä¿®æ­£æ¡ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»é¢ã‚’è¡¨ç¤ºã—ãªã„å ´åˆã«ã€é€šå¸¸ã®ãƒ¢ãƒ¼ãƒ‰åˆ¥ç”»é¢ã‚’è¡¨ç¤º
            elif st.session_state.view_mode == "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º":
                show_dashboard_mode()
            elif st.session_state.view_mode in ["ğŸ¤– AIåˆ†æ", "âš™ï¸ æ‰‹å‹•SQLå®Ÿè¡Œ"]:
                show_ai_mode()
            elif st.session_state.view_mode == "ğŸ©º ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­":
                diagnostics.run_all_checks(
                    settings=settings,
                    bq_client=st.session_state.get("bq_client"),
                    gemini_model=st.session_state.get("gemini_model"),
                    claude_client=st.session_state.get("claude_client")
                )      
            elif st.session_state.view_mode == "ğŸ“ˆ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰":
                show_monitoring_dashboard()
            elif st.session_state.view_mode == "ğŸ”¬ ç’°å¢ƒãƒ‡ãƒãƒƒã‚°":
                show_environment_debug_page()
            # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

        except Exception as e:
            st.error(f"âŒ è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
            if st.session_state.debug_mode:
                st.code(traceback.format_exc())
    
    # ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±
    st.markdown("---")
    footer_col1, footer_col2, footer_col3 = st.columns(3)
    with footer_col1:
        st.markdown("**ğŸš€ Version**: 2.0.0-config")
    with footer_col2:
        if SETTINGS_AVAILABLE:
            st.markdown(f"**ğŸ¤– Models**: {settings.ai.gemini_model}, {settings.ai.claude_model}")
        else:
            st.markdown("**ğŸ¤– Models**: Default")
    with footer_col3:
        st.markdown(f"**â° Last Update**: {dt.now().strftime('%Y-%m-%d %H:%M')}")

# =========================================================================
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
# =========================================================================

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"âŒ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
        st.markdown("### ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°")
        st.markdown("""
        1. **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª**: `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã¨ `config/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒæ­£ã—ãé…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹
        2. **API ã‚­ãƒ¼è¨­å®š**: ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯Streamlit Secretsã§ API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹  
        3. **ä¾å­˜é–¢ä¿‚**: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹
        4. **æ¨©é™ç¢ºèª**: BigQueryç­‰ã®ã‚µãƒ¼ãƒ“ã‚¹ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚‹ã‹
        """)
        
        if st.checkbox("ğŸ› è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º"):
            st.code(traceback.format_exc())

def show_glossary_ui():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ç”¨èªé›†ã‚’è¡¨ç¤ºã™ã‚‹UI"""
    with st.sidebar.expander("ğŸ“– ãƒ“ã‚¸ãƒã‚¹ç”¨èªé›†"):
        try:
            # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã“ã“ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            import pandas as pd
            from pathlib import Path

            glossary_path = Path("glossary.csv")
            if glossary_path.exists():
                df = pd.read_csv(glossary_path)
                # hide_index=True ã§DataFrameã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0, 1, 2...ï¼‰ã‚’éè¡¨ç¤ºã«ã™ã‚‹
                st.dataframe(df, hide_index=True)
                st.caption("ã“ã®ç”¨èªé›†ã¯ `glossary.csv` ã‚’ç·¨é›†ã™ã‚‹ã“ã¨ã§æ›´æ–°ã§ãã¾ã™ã€‚")
            else:
                st.info("`glossary.csv` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        except Exception as e:
            st.error(f"ç”¨èªé›†ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")