# main.py - è¨­å®šç®¡ç†å¯¾å¿œç‰ˆ
"""
ãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ - ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«
è¨­å®šä¸€å…ƒç®¡ç†ã‚·ã‚¹ãƒ†ãƒ å¯¾å¿œ
BigQuery + AI(Gemini/Claude) ã«ã‚ˆã‚‹åºƒå‘Šãƒ‡ãƒ¼ã‚¿åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
"""

import sys
import streamlit as st
from dotenv import load_dotenv  # <-- 1. ã“ã®è¡Œã‚’è¿½åŠ 
load_dotenv()  # <-- 2. ã“ã®è¡Œã‚’è¿½åŠ 
st.warning(f"ğŸ StreamlitãŒä½¿ç”¨ä¸­ã®Python: {sys.executable}")
import pandas as pd
import os
import traceback
from datetime import datetime as dt, date, timedelta
from typing import Dict, List, Optional, Any
import diagnostics
from error_handler import handle_error_with_ai
# from troubleshooter import display_troubleshooting_guide
from display_functions import display_comparative_analysis, display_action_recommendations


# =========================================================================
# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆæœ€åˆã«å®Ÿè¡Œï¼‰
# =========================================================================

st.set_page_config(
    page_title="ğŸš€ AIãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =========================================================================
# è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
# =========================================================================

try:
    from bq_tool_config import settings, show_config_panel
    SETTINGS_AVAILABLE = settings is not None
    CONFIG_UI_AVAILABLE = True
    if SETTINGS_AVAILABLE:
        st.success("âœ… è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        
        # è¨­å®šã®æ¤œè¨¼
        validation_result = settings.get_validation_status()
        if not validation_result["valid"]:
            st.error("âŒ è¨­å®šã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:")
            for error in validation_result["errors"]:
                st.error(f"- {error}")
            st.stop()
        if validation_result["warnings"]:
            st.warning("âš ï¸ è¨­å®šã«é–¢ã™ã‚‹è­¦å‘Š:")
            for warning in validation_result["warnings"]:
                st.warning(f"- {warning}")
    else:
        st.error("âŒ è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
        SETTINGS_AVAILABLE = False
        
except ImportError as e:
    st.error(f"è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    SETTINGS_AVAILABLE = False
    CONFIG_UI_AVAILABLE = False
    settings = None

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    def show_config_panel():
        st.error("è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

# =========================================================================
# ã‚¤ãƒ³ãƒãƒ¼ãƒˆçŠ¶æ³ç®¡ç†
# =========================================================================

IMPORT_STATUS = {
    "config.settings": SETTINGS_AVAILABLE,
    "google.cloud.bigquery": False,
    "google.oauth2.service_account": False,
    "google.generativeai": False,
    "anthropic": False,
    "prompts": False,
    "enhanced_prompts": False,
    "ui_main": False,
    "ui_features": False,
    "analysis_controller": False,
    "error_handler": False,
    "data_quality_checker": False,
    "looker_handler": False,
    "master_analyzer": False
}

# =========================================================================
# å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

# Google Cloud & AI
try:
    from google.cloud import bigquery
    from google.oauth2 import service_account
    IMPORT_STATUS["google.cloud.bigquery"] = True
    IMPORT_STATUS["google.oauth2.service_account"] = True
    print("âœ… Google Cloud ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âŒ Google Cloud ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.error("âŒ Google Cloud ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`pip install google-cloud-bigquery` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

try:
    import google.generativeai as genai
    IMPORT_STATUS["google.generativeai"] = True
    print("âœ… Gemini ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âŒ Gemini ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.error("âŒ Gemini ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`pip install google-generativeai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

try:
    import anthropic
    IMPORT_STATUS["anthropic"] = True
    print("âœ… Claude ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âŒ Claude ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.error("âŒ Claude ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`pip install anthropic` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

# =========================================================================
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

# åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ 
try:
    from prompts import (
        select_best_prompt, get_optimized_bigquery_template,
        ANALYSIS_RECIPES, PROMPT_DEFINITIONS
    )
    IMPORT_STATUS["prompts"] = True
    print("âœ… prompts.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ prompts.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    ANALYSIS_RECIPES = {"è‡ªç”±å…¥åŠ›": "è‡ªç”±ã«SQLã‚¯ã‚¨ãƒªã‚„åˆ†æå†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"}
    PROMPT_DEFINITIONS = {}

# å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ 
try:
    from enhanced_prompts import generate_sql_plan_prompt, generate_enhanced_claude_prompt
    IMPORT_STATUS["enhanced_prompts"] = True
    print("âœ… enhanced_prompts.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ enhanced_prompts.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


# =========================================================================
# UIãƒ»åˆ†æåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ 
# =========================================================================

# UI ã‚·ã‚¹ãƒ†ãƒ 
try:
    from ui_main import show_analysis_workbench, show_manual_sql_interface
    IMPORT_STATUS["ui_main"] = True
    print("âœ… ui_main.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ ui_main.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
# UIæ©Ÿèƒ½æ‹¡å¼µ
try:
    from ui_features import (
        show_analysis_summary_panel,
        show_data_quality_panel, 
        show_error_history,
        show_usage_statistics,
        show_quick_reanalysis
    )
    IMPORT_STATUS["ui_features"] = True
    print("âœ… ui_features.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ ui_features.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    IMPORT_STATUS["ui_features"] = False

# åˆ†æåˆ¶å¾¡
try:
    from analysis_controller import run_analysis_flow, execute_sql_query
    IMPORT_STATUS["analysis_controller"] = True
    print("âœ… analysis_controller.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ analysis_controller.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
try:
    from error_handler import handle_error_with_ai
    IMPORT_STATUS["error_handler"] = True
    print("âœ… error_handler.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ error_handler.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    def handle_error_with_ai(*args, **kwargs):
        st.info("ğŸ“Š ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ©Ÿèƒ½ã¯ä¸€æ™‚çš„ã«åˆ©ç”¨ã§ãã¾ã›ã‚“")

# ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
try:
    from data_quality_checker import check_data_quality
    IMPORT_STATUS["data_quality_checker"] = True
    print("âœ… data_quality_checker.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ data_quality_checker.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    def check_data_quality(*args, **kwargs):
        st.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã¯ä¸€æ™‚çš„ã«åˆ©ç”¨ã§ãã¾ã›ã‚“")

# Lookeré€£æº
try:
    from looker_handler import show_looker_studio_integration, show_filter_ui
    from dashboard_analyzer import SHEET_ANALYSIS_QUERIES 
    IMPORT_STATUS["looker_handler"] = True
    print("âœ… looker_handler.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ looker_handler.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    IMPORT_STATUS["looker_handler"] = False

#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ºæ–­æ©Ÿèƒ½
try:
    from performance_analyzer import run_performance_diagnosis
    IMPORT_STATUS["performance_analyzer"] = True
    print("âœ… performance_analyzer.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ performance_analyzer.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    IMPORT_STATUS["performance_analyzer"] = False

#æ™‚ç³»åˆ—è¨ºæ–­æ©Ÿèƒ½
try:
    from forecast_analyzer import run_forecast_analysis
    IMPORT_STATUS["forecast_analyzer"] = True
    print("âœ… forecast_analyzer.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ forecast_analyzer.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    IMPORT_STATUS["forecast_analyzer"] = False

#ã‚¤ãƒ³ã‚µã‚¤ãƒˆåˆ†ææ©Ÿèƒ½
try:
    from insight_miner import run_insight_analysis
    IMPORT_STATUS["insight_miner"] = True
    print("âœ… insight_miner.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ insight_miner.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    IMPORT_STATUS["insight_miner"] = False

#æˆ¦ç•¥ç«‹æ¡ˆæ©Ÿèƒ½
try:
    from strategy_simulator import run_strategy_simulation
    IMPORT_STATUS["strategy_simulator"] = True
    print("âœ… strategy_simulator.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ strategy_simulator.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    IMPORT_STATUS["strategy_simulator"] = False

#çµ±åˆåˆ†ææ©Ÿèƒ½
try:
    from master_analyzer import show_comprehensive_report_mode
    IMPORT_STATUS["master_analyzer"] = True
    print("âœ… master_analyzer.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ master_analyzer.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    IMPORT_STATUS["master_analyzer"] = False

# =========================================================================
# ã€è¿½åŠ ã€‘é€±æ¬¡ãƒ»æœˆæ¬¡ã‚µãƒãƒªãƒ¼æ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# =========================================================================

# æ—¢å­˜ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ä»¥ä¸‹ã‚’è¿½åŠ 
try:
    from targets_manager import TargetsManager
    from achievement_analyzer import AchievementAnalyzer
    from summary_report_generator import SummaryReportGenerator
    from ui_summary import SummaryUI
    from datetime import datetime, date
    SUMMARY_AVAILABLE = True
except ImportError as e:
    SUMMARY_AVAILABLE = False
    print(f"âš ï¸ ã‚µãƒãƒªãƒ¼æ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—: {e}")

# IMPORT_STATUSè¾æ›¸ã«è¿½åŠ 
IMPORT_STATUS["summary_system"] = SUMMARY_AVAILABLE

# =========================================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

def ensure_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ç¢ºå®ŸãªåˆæœŸåŒ–ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰"""
    if not SETTINGS_AVAILABLE:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
        defaults = {
            "usage_stats": {"total_analyses": 0, "error_count": 0, "enhanced_usage": 0, "avg_execution_time": 0.0},
            "error_history": [],
            "analysis_history": [],
            "filter_settings": {"start_date": dt.now().date(), "end_date": dt.now().date(), "media": [], "campaigns": []},
            "last_analysis_result": None,
            "last_sql": "",
            "last_user_input": "",
            "auto_claude_analysis": True,
            "view_mode": "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º",
            "accessibility_settings": {"high_contrast": False, "large_text": False, "reduced_motion": False}
        }
    else:
        # è¨­å®šã‹ã‚‰åˆæœŸå€¤ã‚’å–å¾—
        defaults = {
            "usage_stats": {"total_analyses": 0, "error_count": 0, "enhanced_usage": 0, "avg_execution_time": 0.0},
            "error_history": [],
            "analysis_history": [],
            "filter_settings": {"start_date": dt.now().date(), "end_date": dt.now().date(), "media": [], "campaigns": []},
            "last_analysis_result": None,
            "last_sql": "",
            "last_user_input": "",
            "debug_mode": settings.app.debug_mode,
            "auto_claude_analysis": settings.app.auto_claude_analysis,
            "view_mode": "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º",
            "accessibility_settings": {"high_contrast": False, "large_text": False, "reduced_motion": False}
        }

    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# =========================================================================
# APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šãƒ»èªè¨¼ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

def setup_bigquery_client():
    """BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    try:
            # è¨­å®šã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’å–å¾—
        if SETTINGS_AVAILABLE and settings.bigquery.project_id:
            project_id = settings.bigquery.project_id
            location = settings.bigquery.location
        else:
            project_id = None
            location = "US"
        
        # Streamlit Secretsã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
        if "gcp_service_account" in st.secrets:
            credentials_info = st.secrets["gcp_service_account"]
            credentials = service_account.Credentials.from_service_account_info(credentials_info)
            if not project_id:
                project_id = credentials_info.get("project_id")
            client = bigquery.Client(credentials=credentials, project=project_id, location=location)
                
            # âœ… é‡è¦: ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state.bq_client = client
            st.success(f"âœ… BigQueryæ¥ç¶šæˆåŠŸ (Secrets) - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_id}")
            return client
            
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼
        elif "GOOGLE_APPLICATION_CREDENTIALS" in os.environ:
            client = bigquery.Client(project=project_id, location=location)
        
            # âœ… é‡è¦: ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state.bq_client = client
            st.success(f"âœ… BigQueryæ¥ç¶šæˆåŠŸ (ç’°å¢ƒå¤‰æ•°) - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {client.project}")
            return client
            
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆèªè¨¼
        else:
            client = bigquery.Client(project=project_id, location=location)
            
            # âœ… é‡è¦: ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state.bq_client = client
            st.success(f"âœ… BigQueryæ¥ç¶šæˆåŠŸ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ) - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {client.project}")
            return client
    except Exception as e:
        #handle_error_with_ai(e, st.session_state.get("gemini_model"), {"operation": "BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"})
        #if 'bq_client' in st.session_state:
        #    st.session_state.bq_client = None
        #return None            
        raise e


def setup_gemini_client():
    """Gemini APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰"""
    try:
        if SETTINGS_AVAILABLE:
            api_key = settings.get_api_key("gemini")
            model_name = settings.ai.gemini_model
        else:
            api_key = st.secrets.get("GEMINI_API_KEY") or st.secrets.get("GOOGLE_API_KEY") or os.environ.get("GEMINI_API_KEY") or os.environ.get("GOOGLE_API_KEY")
            model_name = "gemini-1.5-pro"
            
        # â–¼â–¼â–¼ã€é‡è¦ã€‘APIã‚­ãƒ¼ãŒãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚’ä¿®æ­£ â–¼â–¼â–¼
        if not api_key:
            st.error("âŒ Gemini API ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            st.markdown("ğŸ’¡ `secrets.toml` ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã« `GOOGLE_API_KEY` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚è¨­å®šå¾Œã€ã“ã®ãƒœã‚¿ãƒ³ã‚’å†åº¦ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
            return None # ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ãšã«Noneã‚’è¿”ã™
            
        genai.configure(api_key=api_key)
            
        if SETTINGS_AVAILABLE:
            generation_config = {"temperature": settings.ai.temperature, "max_output_tokens": settings.ai.max_tokens}
        else:
            generation_config = {"temperature": 0.3, "max_output_tokens": 4000}
            
        model = genai.GenerativeModel(model_name, generation_config=generation_config)
        st.success(f"âœ… Gemini API æ¥ç¶šæˆåŠŸ - ãƒ¢ãƒ‡ãƒ«: {model_name}")
        return model
    except Exception as e:
        # äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã¯AIã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ã§å‡¦ç†
        handle_error_with_ai(e, None, {"operation": "Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"})
        return None
        

def setup_claude_client():
    """Claude APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰"""
    try:
        # è¨­å®šã‹ã‚‰APIã‚­ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        if SETTINGS_AVAILABLE:
            api_key = settings.get_api_key("claude")
            model_name = settings.ai.claude_model
        else:
            api_key = st.secrets.get("CLAUDE_API_KEY") or st.secrets.get("ANTHROPIC_API_KEY") or os.environ.get("CLAUDE_API_KEY") or os.environ.get("ANTHROPIC_API_KEY")
            model_name = "claude-sonnet-4-20250514"
        
        if not api_key:
            st.error("âŒ Claude API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            st.markdown("ğŸ’¡ `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯Streamlit Secretsã§ `ANTHROPIC_API_KEY` ã‚’è¨­å®šã—ã¦ãã ã•ã„")
            return None, None
            
        client = anthropic.Anthropic(api_key=api_key)
        st.success(f"âœ… Claude API æ¥ç¶šæˆåŠŸ - ãƒ¢ãƒ‡ãƒ«: {model_name}")
        return client, model_name
    except Exception as e:
        #handle_error_with_ai(e, st.session_state.get("gemini_model"), {"operation": "Claudeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"})
        #return None, None
        raise e


# =========================================================================
# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹è¡¨ç¤ºï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

def show_system_status():
    """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®è¡¨ç¤ºï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰"""
    with st.expander("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹", expanded=False):
        st.markdown("### ğŸ“¦ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿çŠ¶æ³")
        for module_name, status in IMPORT_STATUS.items():
            st.markdown(f"{'âœ…' if status else 'âŒ'} **{module_name}**")
        
        st.markdown("---")
        st.markdown("### ğŸ”‘ APIæ¥ç¶šçŠ¶æ³")
        st.markdown(f"**BigQuery**: {'âœ… æ¥ç¶šæ¸ˆã¿' if st.session_state.get('bq_client') else 'âŒ æœªæ¥ç¶š'}")
        st.markdown(f"**Gemini**: {'âœ… æ¥ç¶šæ¸ˆã¿' if st.session_state.get('gemini_model') else 'âŒ æœªæ¥ç¶š'}")
        st.markdown(f"**Claude**: {'âœ… æ¥ç¶šæ¸ˆã¿' if st.session_state.get('claude_client') else 'âŒ æœªæ¥ç¶š'}")
        
        if SETTINGS_AVAILABLE:
            st.markdown("---")
            st.markdown("### âš™ï¸ è¨­å®šæƒ…å ±")
            st.markdown(f"**Geminiãƒ¢ãƒ‡ãƒ«**: {settings.ai.gemini_model}")
            st.markdown(f"**Claudeãƒ¢ãƒ‡ãƒ«**: {settings.ai.claude_model}")
            st.markdown(f"**Temperature**: {settings.ai.temperature}")
            st.markdown(f"**BigQueryãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: {settings.bigquery.project_id or 'æœªè¨­å®š'}")
            st.markdown(f"**ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰**: {'âœ… æœ‰åŠ¹' if settings.app.debug_mode else 'âŒ ç„¡åŠ¹'}")

def show_settings_panel():
    """è¨­å®šãƒ‘ãƒãƒ«è¡¨ç¤º"""
    if not SETTINGS_AVAILABLE:
        st.warning("âš ï¸ è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return
    
    with st.expander("âš™ï¸ è¨­å®šç®¡ç†", expanded=False):
        st.markdown("### ğŸ“‹ ç¾åœ¨ã®è¨­å®š")
        
        # LLMè¨­å®š
        st.markdown("**ğŸ¤– LLMè¨­å®š**")
        st.code(f"""
Geminiãƒ¢ãƒ‡ãƒ«: {settings.ai.gemini_model}
Claudeãƒ¢ãƒ‡ãƒ«: {settings.ai.claude_model}
Temperature: {settings.ai.temperature}
æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {settings.ai.max_tokens}
        """)
        
        # BigQueryè¨­å®š
        st.markdown("**ğŸ“Š BigQueryè¨­å®š**")
        st.code(f"""
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID: {settings.bigquery.project_id or 'æœªè¨­å®š'}
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {settings.bigquery.dataset}
ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹: {settings.bigquery.table_prefix}
ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³: {settings.bigquery.location}
        """)
        
        # è¨­å®šå†èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ è¨­å®šã‚’å†èª­ã¿è¾¼ã¿", help="ç’°å¢ƒå¤‰æ•°ã‚„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›´ã‚’åæ˜ ã—ã¾ã™"):
            try:
                settings.reload_settings()
                st.success("âœ… è¨­å®šã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ")
                st.rerun()
            except Exception as e:
                st.error(f"âŒ è¨­å®šå†èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# =========================================================================
# ã€è¿½åŠ ã€‘é€±æ¬¡ãƒ»æœˆæ¬¡ã‚µãƒãƒªãƒ¼è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
# =========================================================================

def show_summary_mode():
    """é€±æ¬¡ãƒ»æœˆæ¬¡ã‚µãƒãƒªãƒ¼è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰"""
    st.header("ğŸ“… é€±æ¬¡ãƒ»æœˆæ¬¡ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ")
    
    # æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
    if not SUMMARY_AVAILABLE:
        st.error("âŒ ã‚µãƒãƒªãƒ¼æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        st.info("ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãé…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„:")
        st.code("""
- targets_manager.py
- achievement_analyzer.py
- summary_report_generator.py
- ui_summary.py
        """)
        return
    
    # BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ç¢ºèª
    bq_client = st.session_state.get('bq_client')
    if not bq_client:
        st.warning("âš ï¸ BigQueryã«æ¥ç¶šã—ã¦ãã ã•ã„")
        if st.button("ğŸ”„ BigQueryæ¥ç¶š", type="primary"):
            try:
                with st.spinner("BigQueryæ¥ç¶šä¸­..."):
                    from main import setup_bigquery_client
                    bq_client = setup_bigquery_client()
                    if bq_client:
                        st.session_state.bq_client = bq_client
                        st.rerun()
            except Exception as e:
                st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # UIã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
    ui = SummaryUI()
    targets_manager = TargetsManager()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã®è¨­å®š
    config = ui.render_sidebar()

    # Phase 3: æœ€ä½ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³æ•°ã®è¨­å®šã‚’è¿½åŠ 
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ”§ Phase 3è¨­å®š")
    min_campaigns = st.sidebar.number_input(
        "æ¯”è¼ƒåˆ†æã®æœ€ä½ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³æ•°",
        min_value=1,
        max_value=10,
        value=3,
        help="é«˜/ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ãã‚Œãã‚Œã«å¿…è¦ãªæœ€ä½ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³æ•°"
    )    
    
    # å¯¾è±¡å¹´æœˆã®å–å¾—
    year_month = config["period"]["start_date"].strftime("%Y-%m")
    
    # ç›®æ¨™è¨­å®šçŠ¶æ…‹ã®è¡¨ç¤º
    targets = targets_manager.get_targets(year_month)
    ui.display_targets_summary(targets, year_month)
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    st.markdown("---")
    
    # ç›®æ¨™è¨­å®šãƒ¢ãƒ¼ãƒ€ãƒ«
    if config["targets"] == "open_targets_modal":
        st.subheader("âš™ï¸ ç›®æ¨™ãƒ»äºˆç®—è¨­å®š")
        
        saved = ui.render_targets_modal(targets_manager)
        
        if saved:
            st.success("âœ… ç›®æ¨™ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            # 3ç§’å¾Œã«è‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰
            import time
            time.sleep(2)
            st.rerun()
        
        st.markdown("---")
        st.info("ğŸ‘† ç›®æ¨™è¨­å®šå¾Œã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ŒğŸš€ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„")
        return
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆ
    if config["generate"]:
        try:
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            with st.spinner("ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­..."):
                # AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—
                gemini_client = st.session_state.get('gemini_model')
                claude_client = st.session_state.get('claude_client')
                
                # ãƒ†ãƒ¼ãƒ–ãƒ«IDã®æ§‹ç¯‰
                if SETTINGS_AVAILABLE and settings:
                    table_id = f"{settings.bigquery.project_id}.{settings.bigquery.dataset}.LookerStudio_report_campaign"
                else:
                    table_id = "vorn-digi-mktg-poc-635a.toki_air.LookerStudio_report_campaign"
                
                # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ä½œæˆ
                generator = SummaryReportGenerator(
                    bq_client=bq_client,
                    gemini_client=gemini_client,
                    claude_client=claude_client
                )
                
                # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                report = generator.generate_report(
                    start_date=config["period"]["start_date"],
                    end_date=config["period"]["end_date"],
                    comparison_mode=config["comparison"]["mode"],
                    table_id=table_id,
                    min_campaigns_for_comparison=min_campaigns
                )
                
                if not report:
                    st.error("âŒ ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return
                
                # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
                display_summary_report(report, config)
                
        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
            if SETTINGS_AVAILABLE and settings and settings.app.debug_mode:
                st.exception(e)
    
    else:
        # åˆæœŸè¡¨ç¤º
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æœŸé–“ã‚’é¸æŠã—ã€ã€ŒğŸš€ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„")
        
        # èª¬æ˜
        with st.expander("ğŸ“– é€±æ¬¡ãƒ»æœˆæ¬¡ã‚µãƒãƒªãƒ¼æ©Ÿèƒ½ã«ã¤ã„ã¦", expanded=True):
            st.markdown("""
            ### æ©Ÿèƒ½æ¦‚è¦
            
            å®šæœŸãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚’è‡ªå‹•åŒ–ã—ã€æŒ‡å®šã—ãŸæœŸé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼ã‚’ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ç”Ÿæˆã§ãã¾ã™ã€‚
            
            ### ç”Ÿæˆã•ã‚Œã‚‹ãƒ¬ãƒãƒ¼ãƒˆ
            
            1. **ğŸ“ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼** - AIç”Ÿæˆã®è¦ç´„
            2. **ğŸ¯ ç›®æ¨™é”æˆçŠ¶æ³** - äºˆç®—æ¶ˆåŒ–ç‡ã€KPIé”æˆç‡
            3. **ğŸ“Š ä¸»è¦KPI** - Cost, CPA, CVR, CTRç­‰
            4. **ğŸ“ˆ æœŸé–“ãƒˆãƒ¬ãƒ³ãƒ‰** - æ—¥æ¬¡æ¨ç§»ã‚°ãƒ©ãƒ•
            5. **â­ ãƒã‚¤ãƒ©ã‚¤ãƒˆ** - æœ€é«˜/æœ€ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
            
            ### ä½¿ã„æ–¹
            
            1. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§**æœŸé–“ã‚’é¸æŠ**ï¼ˆä»Šé€±/å…ˆé€±/ä»Šæœˆ/å…ˆæœˆç­‰ï¼‰
            2. å¿…è¦ã«å¿œã˜ã¦**ç›®æ¨™ãƒ»äºˆç®—ã‚’è¨­å®š**
            3. **æ¯”è¼ƒè¨­å®š**ã§å‰æœŸé–“ã¨ã®æ¯”è¼ƒã‚’æœ‰åŠ¹åŒ–
            4. ã€ŒğŸš€ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            
            ### ç›®æ¨™è¨­å®šã«ã¤ã„ã¦
            
            ç›®æ¨™ã‚’è¨­å®šã—ãªãã¦ã‚‚ãƒ¬ãƒãƒ¼ãƒˆã¯ç”Ÿæˆã§ãã¾ã™ãŒã€è¨­å®šã™ã‚‹ã¨ä»¥ä¸‹ã®æƒ…å ±ãŒè¿½åŠ ã•ã‚Œã¾ã™ï¼š
            - äºˆç®—æ¶ˆåŒ–ãƒšãƒ¼ã‚¹ï¼ˆã‚¢ãƒ³ãƒ€ãƒ¼/ã‚ªãƒ³/ã‚ªãƒ¼ãƒãƒ¼ï¼‰
            - KPIé”æˆç‡
            - ç›®æ¨™ã¨ã®å·®ç•°åˆ†æ
            """)


def display_summary_report(report: Dict[str, Any], config: Dict[str, Any]):
    """
    ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤ºï¼ˆPhase 2å¯¾å¿œç‰ˆï¼‰
    
    Args:
        report: ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
        config: UIè¨­å®š
    """
    from datetime import datetime
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    import pandas as pd
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.success("âœ… ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    
    period_info = report["period"]
    st.markdown(f"""
    **æœŸé–“**: {period_info['start_date'].strftime('%Y/%m/%d')} - {period_info['end_date'].strftime('%Y/%m/%d')}  
    **ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y/%m/%d %H:%M')}
    """)
    
    st.markdown("---")
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
    st.subheader("ğŸ¤– ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼")
    
    if report.get("section_1_executive_summary"):
        st.markdown(report["section_1_executive_summary"])
    else:
        st.info("ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
    
    st.markdown("---")
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: ç›®æ¨™é”æˆçŠ¶æ³
    st.subheader("ğŸ¯ ç›®æ¨™é”æˆçŠ¶æ³")
    
    achievement = report["section_2_achievement"]
    
    # äºˆç®—æ¶ˆåŒ–ãƒšãƒ¼ã‚¹
    st.markdown("#### ğŸ’° äºˆç®—æ¶ˆåŒ–ãƒšãƒ¼ã‚¹")
    
    budget_pacing = achievement["budget_pacing"]
    
    if budget_pacing["has_target"]:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "å®Ÿã‚³ã‚¹ãƒˆ",
                f"Â¥{budget_pacing['actual_cost']:,.0f}",
                f"ç›®æ¨™: Â¥{budget_pacing['target_budget']:,.0f}"
            )
        
        with col2:
            st.metric(
                "æ¶ˆåŒ–ç‡",
                f"{budget_pacing['progress_rate']:.1%}",
                f"æœŸå¾…: {budget_pacing['expected_progress_rate']:.1%}"
            )
        
        with col3:
            status_icon = {
                "under": "ğŸŸ¢",
                "on_track": "ğŸŸ¡",
                "over": "ğŸ”´"
            }.get(budget_pacing["pace_status"], "âšª")
            
            st.metric(
                "ãƒšãƒ¼ã‚¹åˆ¤å®š",
                f"{status_icon} {budget_pacing['pace_status_text']}"
            )
        
        # è©³ç´°æƒ…å ±
        with st.expander("ğŸ“Š è©³ç´°æƒ…å ±"):
            st.write(f"æ—¥æ¬¡å¹³å‡ã‚³ã‚¹ãƒˆ: Â¥{budget_pacing['daily_average']:,.0f}")
            st.write(f"æœˆæœ«äºˆæ¸¬: Â¥{budget_pacing['projected_month_end']:,.0f}")
            st.write(f"æ®‹äºˆç®—: Â¥{budget_pacing['remaining_budget']:,.0f}")
            st.write(f"æ®‹æ—¥æ•°: {budget_pacing['days_remaining']}æ—¥")
    
    else:
        st.info("âš ï¸ ç›®æ¨™ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        st.write(f"å®Ÿã‚³ã‚¹ãƒˆ: Â¥{budget_pacing['actual_cost']:,.0f}")
        st.write(f"æ—¥æ¬¡å¹³å‡: Â¥{budget_pacing['daily_average']:,.0f}")
        st.write(f"æœˆæœ«äºˆæ¸¬: Â¥{budget_pacing['projected_month_end']:,.0f}")
    
    # KPIé”æˆç‡
    st.markdown("#### ğŸ“Š KPIé”æˆçŠ¶æ³")
    
    kpi_achievement = achievement["kpi_achievement"]
    
    if kpi_achievement["has_target"]:
        kpi_cols = st.columns(len(kpi_achievement["kpis"]))
        
        for idx, (kpi_name, kpi_data) in enumerate(kpi_achievement["kpis"].items()):
            with kpi_cols[idx]:
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åã®æ•´å½¢
                display_name = {
                    "conversions": "CVæ•°",
                    "cpa": "CPA",
                    "cvr": "CVR",
                    "ctr": "CTR"
                }.get(kpi_name, kpi_name.upper())
                
                # å€¤ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                if kpi_name in ["cvr", "ctr"]:
                    actual_display = f"{kpi_data['actual']:.2%}"
                    target_display = f"{kpi_data['target']:.2%}"
                elif kpi_name in ["cpa", "conversions"]:
                    actual_display = f"{kpi_data['actual']:,.0f}"
                    target_display = f"{kpi_data['target']:,.0f}"
                else:
                    actual_display = f"{kpi_data['actual']}"
                    target_display = f"{kpi_data['target']}"
                
                st.metric(
                    display_name,
                    actual_display,
                    f"ç›®æ¨™: {target_display}"
                )
                st.write(f"é”æˆç‡: {kpi_data['status_text']}")
    
    else:
        st.info("âš ï¸ KPIç›®æ¨™ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    st.markdown("---")
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³3: ä¸»è¦KPI
    st.subheader("ğŸ“Š ä¸»è¦KPI")
    
    metrics = report["section_3_kpis"]["metrics"]
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ã‚³ã‚¹ãƒˆ", f"Â¥{metrics['cost']:,.0f}")
    
    with col2:
        st.metric("CVæ•°", f"{metrics['conversions']:,.0f}ä»¶")
    
    with col3:
        st.metric("CPA", f"Â¥{metrics['cpa']:,.0f}")
    
    with col4:
        st.metric("CVR", f"{metrics['cvr']:.2%}")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Imp", f"{metrics['impressions']:,.0f}")
    
    with col2:
        st.metric("Clicks", f"{metrics['clicks']:,.0f}")
    
    with col3:
        st.metric("CTR", f"{metrics['ctr']:.2%}")
    
    with col4:
        st.metric("CPC", f"Â¥{metrics['cpc']:,.0f}")
    
    # KPIæ´å¯Ÿã‚’è¡¨ç¤ºï¼ˆPhase 2ï¼‰
    if report.get("kpi_insights"):
        with st.expander("ğŸ’¡ KPIåˆ†æ", expanded=True):
            st.markdown(report["kpi_insights"])
    
    # å‰æœŸé–“æ¯”è¼ƒï¼ˆã‚ã‚‹å ´åˆï¼‰
    if "comparison" in report:
        st.markdown("#### ğŸ“ˆ å‰æœŸé–“æ¯”è¼ƒ")
        
        comparison = report["comparison"]
        
        if comparison["has_comparison"]:
            comp_data = comparison["comparisons"]
            
            comp_cols = st.columns(5)
            
            for idx, metric in enumerate(["cost", "conversions", "cpa", "cvr", "ctr"]):
                if metric in comp_data:
                    data = comp_data[metric]
                    
                    with comp_cols[idx]:
                        display_name = {
                            "cost": "ã‚³ã‚¹ãƒˆ",
                            "conversions": "CVæ•°",
                            "cpa": "CPA",
                            "cvr": "CVR",
                            "ctr": "CTR"
                        }.get(metric, metric)
                        
                        if data["change_rate"] is not None:
                            st.write(f"**{display_name}**")
                            st.write(data["trend_text"])
                        else:
                            st.write(f"**{display_name}**")
                            st.write("æ¯”è¼ƒä¸å¯")
    
    st.markdown("---")
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³4: æœŸé–“ãƒˆãƒ¬ãƒ³ãƒ‰
    st.subheader("ğŸ“ˆ æœŸé–“ãƒˆãƒ¬ãƒ³ãƒ‰")
    
    trend_data = report["section_4_trends"]["daily_data"]
    
    if trend_data:
        df_trend = pd.DataFrame(trend_data)
        df_trend['date'] = pd.to_datetime(df_trend['date'])
        
        # 2è¡Œã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=("ã‚³ã‚¹ãƒˆæ¨ç§»", "CVæ•°æ¨ç§»", "CPAæ¨ç§»", "CVRæ¨ç§»")
        )
        
        # ã‚³ã‚¹ãƒˆ
        fig.add_trace(
            go.Scatter(x=df_trend['date'], y=df_trend['cost'], name="ã‚³ã‚¹ãƒˆ", line=dict(color='blue')),
            row=1, col=1
        )
        
        # CVæ•°
        fig.add_trace(
            go.Scatter(x=df_trend['date'], y=df_trend['conversions'], name="CVæ•°", line=dict(color='green')),
            row=1, col=2
        )
        
        # CPA
        fig.add_trace(
            go.Scatter(x=df_trend['date'], y=df_trend['cpa'], name="CPA", line=dict(color='red')),
            row=2, col=1
        )
        
        # CVR
        fig.add_trace(
            go.Scatter(x=df_trend['date'], y=df_trend['cvr'], name="CVR", line=dict(color='purple')),
            row=2, col=2
        )
        
        fig.update_layout(height=600, showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
    
    else:
        st.info("ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    st.markdown("---")
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³5: ãƒã‚¤ãƒ©ã‚¤ãƒˆ
    st.subheader("â­ ãƒã‚¤ãƒ©ã‚¤ãƒˆ")
    
    highlights = report["section_5_highlights"]
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ† æœ€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
        
        if highlights["best_campaign"]:
            best = highlights["best_campaign"]
            st.success(f"**{best['campaign_name']}**")
            st.write(f"CPA: Â¥{best['cpa']:,.0f}")
            st.write(f"CVæ•°: {best['conversions']:,.0f}ä»¶")
            st.write(f"ã‚³ã‚¹ãƒˆ: Â¥{best['cost']:,.0f}")
        else:
            st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")
    
    with col2:
        st.markdown("#### ğŸ“‰ è¦æ”¹å–„")
        
        if highlights["worst_campaign"]:
            worst = highlights["worst_campaign"]
            st.warning(f"**{worst['campaign_name']}**")
            st.write(f"CPA: Â¥{worst['cpa']:,.0f}")
            st.write(f"CVæ•°: {worst['conversions']:,.0f}ä»¶")
            st.write(f"ã‚³ã‚¹ãƒˆ: Â¥{worst['cost']:,.0f}")
        else:
            st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")
    
    # Phase 3: ã‚»ã‚¯ã‚·ãƒ§ãƒ³6ã¨7
    st.header("ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³6: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒåˆ†æ")
    if "section_6_comparative_analysis" in report:
        display_comparative_analysis(report["section_6_comparative_analysis"])

    st.header("ğŸ¯ ã‚»ã‚¯ã‚·ãƒ§ãƒ³7: æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    if "section_7_action_recommendations" in report:
        display_action_recommendations(report["section_7_action_recommendations"])

        # ãƒã‚¤ãƒ©ã‚¤ãƒˆæ´å¯Ÿã‚’è¡¨ç¤ºï¼ˆPhase 2ï¼‰
        if report.get("highlights_insights"):
            st.markdown("---")
            with st.expander("ğŸ’¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å·®ã®åˆ†æ", expanded=True):
                st.markdown(report["highlights_insights"])
    
    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
    st.markdown("---")
    st.subheader("ğŸ’¾ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
            # ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
            report_text = generate_text_report(report)
            st.download_button(
                label="ğŸ’¾ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=report_text,
                file_name=f"summary_report_{period_info['year_month']}.txt",
                mime="text/plain"
            )
    
    with col2:
        if st.button("ğŸ“Š CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
            # CSVå½¢å¼ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å‡ºåŠ›
            csv_data = generate_csv_report(report)
            st.download_button(
                label="ğŸ’¾ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_data,
                file_name=f"summary_metrics_{period_info['year_month']}.csv",
                mime="text/csv"
            )


def generate_text_report(report: Dict[str, Any]) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    period = report["period"]
    text = f"""
é€±æ¬¡ãƒ»æœˆæ¬¡ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
{'='*60}

æœŸé–“: {period['start_date'].strftime('%Y/%m/%d')} - {period['end_date'].strftime('%Y/%m/%d')}
ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y/%m/%d %H:%M')}

{'='*60}
ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
{'='*60}

{report.get('section_1_executive_summary', 'ã‚µãƒãƒªãƒ¼ãªã—')}

{'='*60}
ä¸»è¦KPI
{'='*60}

"""
    
    metrics = report["section_3_kpis"]["metrics"]
    text += f"""
ã‚³ã‚¹ãƒˆ: Â¥{metrics['cost']:,.0f}
CVæ•°: {metrics['conversions']:,.0f}ä»¶
CPA: Â¥{metrics['cpa']:,.0f}
CVR: {metrics['cvr']:.2%}
CTR: {metrics['ctr']:.2%}
"""
    
    return text


def generate_csv_report(report: Dict[str, Any]) -> str:
    """CSVå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    import io
    import pandas as pd
    
    metrics = report["section_3_kpis"]["metrics"]
    
    data = {
        "æŒ‡æ¨™": ["ã‚³ã‚¹ãƒˆ", "CVæ•°", "CPA", "CVR", "CTR", "Impressions", "Clicks", "CPC"],
        "å€¤": [
            metrics['cost'],
            metrics['conversions'],
            metrics['cpa'],
            metrics['cvr'],
            metrics['ctr'],
            metrics['impressions'],
            metrics['clicks'],
            metrics['cpc']
        ]
    }
    
    df = pd.DataFrame(data)
    
    return df.to_csv(index=False, encoding='utf-8-sig')


# =========================================================================
# ãƒ¡ã‚¤ãƒ³è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰
# =========================================================================

# main.py ã®show_dashboard_modeé–¢æ•°ã‚’ä»¥ä¸‹ã«ç½®ãæ›ãˆ

def show_dashboard_mode():
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ï¼ˆLooker Studioæ©Ÿèƒ½å¾©æ´»ç‰ˆï¼‰"""
    st.header("ğŸ“Š Looker Studio ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    
    # BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ç¢ºèª
    bq_client = st.session_state.get("bq_client")
    if not bq_client:
        st.warning("âš ï¸ BigQueryæ¥ç¶šãŒå¿…è¦ã§ã™")
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€ŒğŸ”„ BigQueryæ¥ç¶šã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
        return
    
    # Lookeré€£æºæ©Ÿèƒ½ã®ç¢ºèª
    if IMPORT_STATUS.get("looker_handler", False):
        try:
            from looker_handler import show_looker_studio_integration, show_filter_ui
            
            # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼UIè¡¨ç¤º
            with st.sidebar:
                st.markdown("### ğŸ“Š Looker Studio ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
                show_filter_ui(bq_client)
            
            # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã§Looker Studioè¡¨ç¤º
            show_looker_studio_integration(
                bq_client=bq_client,
                model=st.session_state.get("gemini_model"),
                key_prefix="dashboard",
                sheet_analysis_queries=SHEET_ANALYSIS_QUERIES
            )
            
        except ImportError as e:
            st.error(f"âŒ Lookeræ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            show_fallback_dashboard()
        except Exception as e:
            st.error(f"âŒ Lookeræ©Ÿèƒ½ã®ã‚¨ãƒ©ãƒ¼: {e}")
            show_fallback_dashboard()
    else:
        show_fallback_dashboard()

def show_fallback_dashboard():
    """Lookeræ©Ÿèƒ½ãŒä½¿ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    st.info("ğŸ“Š Looker Studioé€£æºæ©Ÿèƒ½ã¯æº–å‚™ä¸­ã§ã™")
    
    # åŸºæœ¬çš„ãªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä»£æ›¿æ©Ÿèƒ½
    st.markdown("### ğŸ“ˆ åŸºæœ¬åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    
    # åˆ†æçµ±è¨ˆè¡¨ç¤º
    if "usage_stats" in st.session_state:
        stats = st.session_state.usage_stats
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ç·åˆ†ææ•°", stats.get("total_analyses", 0))
        with col2:
            st.metric("æˆåŠŸåˆ†æ", stats.get("total_analyses", 0) - stats.get("error_count", 0))
        with col3:
            st.metric("é«˜å“è³ªåˆ†æ", stats.get("enhanced_usage", 0))
    
    # æœ€æ–°åˆ†æçµæœè¡¨ç¤º
    if st.session_state.get("last_analysis_result") is not None:
        st.markdown("### ğŸ“Š æœ€æ–°ã®åˆ†æçµæœ")
        df = st.session_state.last_analysis_result
        st.dataframe(df.head(10), width='stretch')
        
        # åŸºæœ¬çµ±è¨ˆ
        if len(df.select_dtypes(include=['number']).columns) > 0:
            st.markdown("### ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ")
            st.write(df.describe())
    
    st.info("ğŸ’¡ å®Œå…¨ãªLooker Studioæ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ã€looker_handler.pyã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„")

def show_semantic_search_ui():
    """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æã®UIã‚’è¡¨ç¤ºã™ã‚‹"""
    st.markdown("---")
    st.subheader("ğŸ§  é¡ä¼¼ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³æ¤œç´¢")
    
    # BigQueryã‹ã‚‰å…¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´»ç”¨ï¼‰
    @st.cache_data(ttl=3600)
    def get_all_campaign_names(_bq_client): # bq_client -> _bq_client ã«å¤‰æ›´
        if not _bq_client: # bq_client -> _bq_client ã«å¤‰æ›´
            return []
        try:
            query = "SELECT DISTINCT CampaignName FROM `vorn-digi-mktg-poc-635a.toki_air.LookerStudio_report_campaign` WHERE CampaignName IS NOT NULL"
            df = _bq_client.query(query).to_dataframe() # bq_client -> _bq_client ã«å¤‰æ›´
            return df["CampaignName"].tolist()
        except Exception as e:
            st.warning(f"ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åã®å–å¾—ã«å¤±æ•—: {e}")
            return []

    bq_client = st.session_state.get("bq_client")
    all_campaigns = get_all_campaign_names(bq_client)

    if not all_campaigns:
        st.warning("åˆ†æå¯¾è±¡ã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚BigQueryã«æ¥ç¶šã—ã¦ãã ã•ã„ã€‚")
        return

    # æ¤œç´¢UI
    target_campaign = st.selectbox("åŸºæº–ã¨ãªã‚‹ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„", options=all_campaigns)

    if st.button("é¡ä¼¼ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’æ¤œç´¢ã™ã‚‹", width='stretch'):
        if target_campaign:
            from semantic_analyzer import generate_embeddings, find_similar_texts
            
            # å…¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒåŠ¹ãï¼‰
            all_embeddings = generate_embeddings(all_campaigns)
            
            if all_embeddings:
                # é¡ä¼¼ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’æ¤œç´¢
                similar_campaigns_df = find_similar_texts(target_campaign, all_embeddings, top_n=5)
                
            if similar_campaigns_df is not None:
                st.success("é¡ä¼¼ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
                # st.dataframe ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«å¤‰æ›´
                st.dataframe(
                    similar_campaigns_df,
                    column_config={
                        "text": st.column_config.TextColumn("ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å", width="large"),
                        "similarity": st.column_config.ProgressColumn(
                            "é–¢é€£æ€§ã‚¹ã‚³ã‚¢",
                            help="åŸºæº–ãƒ†ã‚­ã‚¹ãƒˆã¨ã®æ„å‘³çš„ãªè¿‘ã•ï¼ˆ1ã«è¿‘ã„ã»ã©é–¢é€£æ€§ãŒé«˜ã„ï¼‰",
                            format="%.3f",
                            min_value=0,
                            max_value=1,
                        ),
                    },
                    use_container_width=True,
                    hide_index=True
                )
        else:
            st.error("åŸºæº–ã¨ãªã‚‹ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

def show_auto_grouping_ui():
    """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æã«ã‚ˆã‚‹è‡ªå‹•ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°UI (çµæœä¿æŒæ©Ÿèƒ½ä»˜ã)"""
    st.markdown("---")
    st.subheader("ğŸ§  åºƒå‘Šã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–è‡ªå‹•ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°")
    st.markdown("AIãŒãƒ‡ãƒ¼ã‚¿ã®å¯†åº¦ã«åŸºã¥ãã€æ„å‘³çš„ã«è‡ªç„¶ãªã‚°ãƒ«ãƒ¼ãƒ—ã‚’è‡ªå‹•ã§ç™ºè¦‹ã—ã¾ã™ã€‚")

    # --- 1. éå»ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå‚ç…§ï¼‰æ©Ÿèƒ½ ---
    with st.expander("ğŸ“‚ éå»ã®ã‚¿ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å‚ç…§ã™ã‚‹"):
        uploaded_file = st.file_uploader(
            "ä¿å­˜ã—ãŸã‚¿ã‚°æƒ…å ±CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            type="csv",
            key="grouping_csv_uploader", # keyã‚’è¿½åŠ ã—ã¦ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’åŒºåˆ¥
            help="ä»¥å‰ã«ã“ã®ã‚¢ãƒ—ãƒªã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸ `semantic_tags_...csv` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"
        )
        if uploaded_file is not None:
            try:
                past_tags_df = pd.read_csv(uploaded_file)
                if 'ad_text' in past_tags_df.columns:
                    past_tags_df.rename(columns={'ad_text': 'analyzed_text'}, inplace=True)
                required_columns = ['analyzed_text', 'cluster_id', 'tag']
                if not all(col in past_tags_df.columns for col in required_columns):
                     st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚{', '.join(required_columns)} ãŒå«ã¾ã‚Œã‚‹CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                else:
                    st.success(f"âœ… {len(past_tags_df)}ä»¶ã®éå»ã®ã‚¿ã‚°æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
                    st.dataframe(past_tags_df, use_container_width=True)
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    st.markdown("---")

    bq_client = st.session_state.get("bq_client")
    if not bq_client:
        st.warning("BigQueryã«æ¥ç¶šã—ã¦ãã ã•ã„ã€‚")
        return

    # --- åˆ†æå¯¾è±¡ã®å®šç¾© ---
    ANALYSIS_TARGETS = {
        "åºƒå‘Šæ–‡ (Headline)": ("LookerStudio_report_ad", "Headline"),
        "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ("LookerStudio_report_keyword", "Keyword"),
        "åºƒå‘Šã‚°ãƒ«ãƒ¼ãƒ—å": ("LookerStudio_report_ad_group", "AdGroupName_unified"),
        "ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å": ("LookerStudio_report_campaign", "CampaignName"),
    }

    selected_target_label = st.selectbox(
        "åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
        options=list(ANALYSIS_TARGETS.keys()),
        index=0
    )
    table_name, selected_column = ANALYSIS_TARGETS[selected_target_label]

    @st.cache_data(ttl=3600)
    def get_text_data(_bq_client, table_name, column_name):
        query = f"""
        SELECT DISTINCT {column_name} AS text_data
        FROM `vorn-digi-mktg-poc-635a.toki_air.{table_name}`
        WHERE {column_name} IS NOT NULL AND LENGTH({column_name}) > 5
        LIMIT 500
        """
        try:
            df = _bq_client.query(query).to_dataframe()
            return df["text_data"].tolist()
        except Exception as e:
            st.error(f"ã€Œ{column_name}ã€åˆ—ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—: {e}")
            return []

    ad_texts = get_text_data(bq_client, table_name, selected_column)
    if not ad_texts:
        st.info(f"åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ{selected_column}ï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    min_cluster_size = st.slider(
        "ã‚°ãƒ«ãƒ¼ãƒ—ã®æœ€å°ã‚µã‚¤ã‚º",
        min_value=2, max_value=10, value=3,
        help="ä½•å€‹ä»¥ä¸Šã®åºƒå‘Šæ–‡ãŒé›†ã¾ã£ãŸã‚‰ä¸€ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã¨è¦‹ãªã™ã‹ã‚’è¨­å®šã—ã¾ã™ã€‚"
    )

    # â–¼â–¼â–¼ã€ã“ã“ã‹ã‚‰ãŒä»Šå›ã®ä¿®æ­£ç®‡æ‰€ã§ã™ã€‘â–¼â–¼â–¼

    # --- å®Ÿè¡Œãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç† ---
    if st.button("ğŸš€ ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°å®Ÿè¡Œ", type="primary"):
        with st.spinner("AIã«ã‚ˆã‚‹ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œä¸­ã§ã™..."):
            from semantic_analyzer import group_texts_by_meaning, extract_tags_for_cluster, reduce_dimensions_for_visualization, generate_embeddings
            import pandas as pd

            grouped_df = group_texts_by_meaning(ad_texts, min_cluster_size=min_cluster_size)

            if grouped_df is not None:
                grouped_df_for_tags = grouped_df[grouped_df['cluster'] != -1].copy()
                gemini_model = st.session_state.get("gemini_model")
                cluster_tags = extract_tags_for_cluster(grouped_df_for_tags, gemini_model)
                cluster_themes = {cluster_id: ", ".join(tags) for cluster_id, tags in cluster_tags.items()}
                cluster_themes[-1] = "ãƒã‚¤ã‚º / åˆ†é¡å¤–"

                embeddings_dict = generate_embeddings(grouped_df['text'].tolist())
                vis_df = None
                if embeddings_dict:
                    vis_df_raw = reduce_dimensions_for_visualization(embeddings_dict)
                    if vis_df_raw is not None:
                        vis_df = pd.merge(vis_df_raw, grouped_df, on='text')
                        vis_df['theme'] = vis_df['cluster'].map(cluster_themes)

                # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                st.session_state.grouping_results = {
                    "grouped_df": grouped_df,
                    "cluster_themes": cluster_themes,
                    "vis_df": vis_df,
                    "cluster_tags": cluster_tags,
                    "selected_column": selected_column # åˆ†æå¯¾è±¡åˆ—ã‚‚ä¿å­˜
                }
            else:
                st.session_state.grouping_results = None
                st.error("ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ã•ã‚ŒãŸçµæœãŒã‚ã‚Œã°è¡¨ç¤ºã™ã‚‹ ---
    if "grouping_results" in st.session_state and st.session_state.grouping_results:
        import plotly.express as px
        import pandas as pd

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰çµæœã‚’èª­ã¿è¾¼ã‚€
        results = st.session_state.grouping_results
        grouped_df = results["grouped_df"]
        cluster_themes = results["cluster_themes"]
        vis_df = results["vis_df"]
        cluster_tags = results["cluster_tags"]
        selected_column = results["selected_column"]

        st.subheader("ğŸ“Š ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°çµæœ")

        # å¯è¦–åŒ–
        if vis_df is not None:
            fig = px.scatter(
                vis_df, x='x', y='y', color='theme', hover_name='text',
                title='åºƒå‘Šã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã®æ¦‚å¿µãƒãƒƒãƒ—', labels={'color': 'ã‚°ãƒ«ãƒ¼ãƒ—ãƒ†ãƒ¼ãƒ'},
                color_discrete_map={"ãƒã‚¤ã‚º / åˆ†é¡å¤–": "lightgrey"}
            )
            fig.update_layout(legend_title_text='<b>æ¦‚å¿µã‚°ãƒ«ãƒ¼ãƒ—</b>')
            st.plotly_chart(fig, use_container_width=True)

        # å„ã‚¯ãƒ©ã‚¹ã‚¿ã®è©³ç´°
        for cluster_id in sorted(grouped_df['cluster'].unique()):
            if cluster_id == -1: continue
            theme_name = cluster_themes.get(cluster_id, f"ã‚°ãƒ«ãƒ¼ãƒ— {cluster_id + 1}")
            with st.expander(f"**{theme_name}** ({len(grouped_df[grouped_df['cluster'] == cluster_id])}ä»¶)"):
                st.dataframe(grouped_df[grouped_df['cluster'] == cluster_id][['text']], use_container_width=True)

        noise_df = grouped_df[grouped_df['cluster'] == -1]
        if not noise_df.empty:
            with st.expander(f"**ãƒã‚¤ã‚º / åˆ†é¡å¤–** ({len(noise_df)}ä»¶)"):
                st.dataframe(noise_df[['text']], use_container_width=True)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
        st.markdown("---")
        st.subheader("ğŸ’¾ ä»Šå›ã®åˆ†æçµæœã‚’ä¿å­˜")
        
        tags_to_save = []
        for cluster_id, tags in cluster_tags.items():
            texts_in_cluster = grouped_df[grouped_df['cluster'] == cluster_id]['text']
            for text in texts_in_cluster:
                for tag in tags:
                    tags_to_save.append({
                        "analyzed_text": text,
                        "cluster_id": cluster_id,
                        "tag": tag,
                        "analysis_timestamp": pd.Timestamp.now(tz="Asia/Tokyo").isoformat()
                    })
        save_df = pd.DataFrame(tags_to_save)

        if not save_df.empty:
            save_df['analysis_target_column'] = selected_column
            new_column_order = ['analysis_target_column', 'analyzed_text', 'cluster_id', 'tag', 'analysis_timestamp']
            save_df = save_df[new_column_order]

        st.download_button(
            label="ğŸ“¥ ã“ã®ã‚¿ã‚°ä»˜ã‘çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=save_df.to_csv(index=False, encoding='utf-8-sig'),
            file_name=f"semantic_tags_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.csv",
            mime='text/csv',
        )

def show_ai_mode():
    """AIåˆ†æãƒ¢ãƒ¼ãƒ‰"""
    if IMPORT_STATUS["ui_main"]:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰å¿…è¦ãªæƒ…å ±ã‚’å–å¾—
        gemini_model = st.session_state.get("gemini_model")
        claude_client = st.session_state.get("claude_client")
        claude_model_name = st.session_state.get("claude_model_name")
        
        # SHEET_ANALYSIS_QUERIESã®å–å¾—
        sheet_analysis_queries = globals().get("SHEET_ANALYSIS_QUERIES", {})
        
        show_analysis_workbench(gemini_model, claude_client, claude_model_name, sheet_analysis_queries)

        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æãŒæœ‰åŠ¹ãªå ´åˆã®ã¿ã€æ¤œç´¢UIã‚’è¡¨ç¤º
        if st.session_state.get("use_semantic_analysis", False):
            show_semantic_search_ui() # æ—¢å­˜ã®é¡ä¼¼æ¤œç´¢UI
            show_auto_grouping_ui()   # æ–°ã—ãè¿½åŠ ã™ã‚‹ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°UI
    else:
        st.error("âŒ AIåˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

def show_manual_mode():
    """æ‰‹å‹•SQLå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰"""
    if IMPORT_STATUS["ui_main"]:
        show_manual_sql_interface()
    else:
        st.error("âŒ æ‰‹å‹•SQLæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

def show_monitoring_dashboard():
    """ä½¿ç”¨çŠ¶æ³ã‚„ã‚¨ãƒ©ãƒ¼å±¥æ­´ã‚’è¡¨ç¤ºã™ã‚‹ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    st.header("ğŸ“ˆ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

    if st.button("ğŸ”„ æœ€æ–°ã®æƒ…å ±ã«æ›´æ–°"):
        st.rerun()

    st.subheader("ğŸ“Š ä½¿ç”¨çŠ¶æ³ã‚µãƒãƒªãƒ¼")
    
    # st.session_stateã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
    stats = st.session_state.get("usage_stats", {})
    total_analyses = stats.get("total_analyses", 0)
    error_count = stats.get("error_count", 0)
    enhanced_usage = stats.get("enhanced_usage", 0)
    
    success_rate = ((total_analyses - error_count) / total_analyses * 100) if total_analyses > 0 else 0

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç·åˆ†æå›æ•°", f"{total_analyses} å›")
    with col2:
        st.metric("ã‚¨ãƒ©ãƒ¼å›æ•°", f"{error_count} å›")
    with col3:
        st.metric("æˆåŠŸç‡", f"{success_rate:.1f} %")
    with col4:
        st.metric("é«˜å“è³ªåˆ†æ", f"{enhanced_usage} å›")

    st.subheader("âš ï¸ ã‚¨ãƒ©ãƒ¼å±¥æ­´")
    
    error_history = st.session_state.get("error_history", [])
    if not error_history:
        st.success("âœ… ã“ã‚Œã¾ã§ã«è¨˜éŒ²ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        # ç›´è¿‘5ä»¶ã®ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤º
        with st.expander(f"ç›´è¿‘ã®ã‚¨ãƒ©ãƒ¼å±¥æ­´ ({len(error_history)}ä»¶)"):
            for i, error_info in enumerate(reversed(error_history[-5:])):
                st.error(f"**ã‚¨ãƒ©ãƒ¼ #{len(error_history)-i}:** {error_info.get('timestamp')}")
                st.code(error_info.get('error_message', 'è©³ç´°ä¸æ˜'), language='text')


def show_environment_debug_page():
    """
    ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œç’°å¢ƒã‚’å¾¹åº•çš„ã«è‡ªå·±è¨ºæ–­ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒãƒƒã‚°ãƒšãƒ¼ã‚¸
    """
    st.header("ğŸ”¬ ç’°å¢ƒè‡ªå·±è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ")

    st.subheader("1. Pythonå®Ÿè¡Œç’°å¢ƒ")
    st.markdown("ç¾åœ¨ã“ã®Streamlitã‚¢ãƒ—ãƒªã‚’å‹•ã‹ã—ã¦ã„ã‚‹Pythonã®å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚")
    st.code(sys.executable, language="text")

    st.subheader("2. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ¤œç´¢ãƒ‘ã‚¹")
    st.markdown("PythonãŒãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ¢ã—ã«è¡Œããƒ•ã‚©ãƒ«ãƒ€ã®ä¸€è¦§ã§ã™ã€‚ã“ã®ä¸­ã«`venv\\Lib\\site-packages`ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.json(sys.path)

    st.subheader("3. å®Ÿéš›ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª")
    st.markdown("ä¸Šè¨˜ã®Pythonç’°å¢ƒã«ã€ç¾åœ¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä¸€è¦§ã§ã™ã€‚")
    st.info("ã€Œ`pip freeze`ã®çµæœã‚’ã“ã“ã«å‡ºåŠ›ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

    if st.button("`pip freeze`ã®çµæœã‚’ã“ã“ã«å‡ºåŠ›"):
        import subprocess
        try:
            with st.spinner("ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸€è¦§ã‚’å–å¾—ä¸­..."):
                # sys.executable ã‚’ä½¿ã£ã¦ã€ç¾åœ¨å®Ÿè¡Œä¸­ã®Pythonã§pipã‚’å®Ÿè¡Œã™ã‚‹
                result = subprocess.run(
                    [sys.executable, "-m", "pip", "freeze"],
                    capture_output=True,
                    text=True,
                    check=True
                )
                st.code(result.stdout, language="text")
        except Exception as e:
            st.error(f"pip freezeã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.code(traceback.format_exc())

    st.subheader("4. `google-cloud-aiplatform` ã®ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ")
    st.markdown("ã“ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€ã“ã®ã‚¢ãƒ—ãƒªãŒ `google-cloud-aiplatform` ã‚’ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã‚‹ã‹è©¦ã—ã¾ã™ã€‚")
    if st.button("ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"):
        try:
            with st.spinner("ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦ã¿ã¦ã„ã¾ã™..."):
                from google.cloud import aiplatform
                st.success("âœ… `from google.cloud import aiplatform` ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«æˆåŠŸã—ã¾ã—ãŸï¼")
                st.write(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å ´æ‰€: `{aiplatform.__file__}`")
        except Exception as e:
            st.error("âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.code(traceback.format_exc())

def show_glossary_ui():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ç”¨èªé›†ã‚’è¡¨ç¤ºã™ã‚‹UI"""
    with st.sidebar.expander("ğŸ“– ãƒ“ã‚¸ãƒã‚¹ç”¨èªé›†"):
        try:
            # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã“ã“ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            import pandas as pd
            from pathlib import Path

            glossary_path = Path("glossary.csv")
            if glossary_path.exists():
                df = pd.read_csv(glossary_path)
                # hide_index=True ã§DataFrameã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0, 1, 2...ï¼‰ã‚’éè¡¨ç¤ºã«ã™ã‚‹
                st.dataframe(df, hide_index=True)
                st.caption("ã“ã®ç”¨èªé›†ã¯ `glossary.csv` ã‚’ç·¨é›†ã™ã‚‹ã“ã¨ã§æ›´æ–°ã§ãã¾ã™ã€‚")
            else:
                st.info("`glossary.csv` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        except Exception as e:
            st.error(f"ç”¨èªé›†ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")

# =========================================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =========================================================================

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•°ï¼ˆè¨­å®šå¯¾å¿œç‰ˆï¼‰"""
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
    st.title("ğŸš€ AIãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ")
    
    if SETTINGS_AVAILABLE:
        st.success("âœ… è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒä¸­")
    else:
        st.warning("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œä¸­ï¼ˆè¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ æœªä½¿ç”¨ï¼‰")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
    ensure_session_state()
    
    # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ãƒ»è¨­å®šãƒ‘ãƒãƒ«
    col1, col2 = st.columns([3, 1])
    with col2:
        show_system_status()
        show_settings_panel()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
    with st.sidebar:
        st.header("ğŸ›ï¸ ã‚·ã‚¹ãƒ†ãƒ åˆ¶å¾¡")
        
        # è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰é¸æŠ
        view_options = [
            "ğŸ“Š çµ±åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ", 
            "ğŸ“… é€±æ¬¡ãƒ»æœˆæ¬¡ã‚µãƒãƒªãƒ¼",
            "ğŸ’¡ æˆ¦ç•¥ææ¡ˆ & ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", 
            "ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ºæ–­", 
            "ğŸ”® äºˆæ¸¬åˆ†æ & ç•°å¸¸æ¤œçŸ¥", 
            "ğŸ§  è‡ªå‹•ã‚¤ãƒ³ã‚µã‚¤ãƒˆåˆ†æ", 
            "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º", 
            "ğŸ¤– AIåˆ†æ", 
            "âš™ï¸ æ‰‹å‹•SQLå®Ÿè¡Œ", 
            "ğŸ©º ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­", 
            "ğŸ“ˆ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", 
            "ğŸ”¬ ç’°å¢ƒãƒ‡ãƒãƒƒã‚°"]
        st.session_state.view_mode = st.selectbox(
            "è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰é¸æŠ",
            view_options,
            index=view_options.index(st.session_state.get("view_mode", "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º"))
        )
        
        st.markdown("---")
        
        # APIæ¥ç¶šè¨­å®š
        st.markdown("### ğŸ”Œ APIæ¥ç¶š")
        
        # BigQueryæ¥ç¶š
        if st.button("ğŸ”„ BigQueryæ¥ç¶š", width='stretch'):
            try: # â† try ã‚’è¿½åŠ 
                with st.spinner("BigQueryæ¥ç¶šä¸­..."):
                    bq_client = setup_bigquery_client()
                    if bq_client:
                        st.session_state.bq_client = bq_client
            except Exception as e: # â† except ã‚’è¿½åŠ 
                handle_error_with_ai(e, st.session_state.get("gemini_model"), {"operation": "BigQueryæ¥ç¶šãƒœã‚¿ãƒ³"})
        
        # Geminiæ¥ç¶š
        if st.button("ğŸ”„ Geminiæ¥ç¶š", width='stretch'):
            try: # â† try ã‚’è¿½åŠ 
                with st.spinner("Gemini APIæ¥ç¶šä¸­..."):
                    gemini_model = setup_gemini_client()
                    if gemini_model:
                        st.session_state.gemini_model = gemini_model
            except Exception as e: # â† except ã‚’è¿½åŠ 
                handle_error_with_ai(e, None, {"operation": "Geminiæ¥ç¶šãƒœã‚¿ãƒ³"})

        # Claudeæ¥ç¶š
        if st.button("ğŸ”„ Claudeæ¥ç¶š", width='stretch'):
            try: # â† try ã‚’è¿½åŠ 
                with st.spinner("Claude APIæ¥ç¶šä¸­..."):
                    claude_client, claude_model_name = setup_claude_client()
                    if claude_client and claude_model_name:
                        st.session_state.claude_client = claude_client
                        st.session_state.claude_model_name = claude_model_name
            except Exception as e: # â† except ã‚’è¿½åŠ 
                handle_error_with_ai(e, st.session_state.get("gemini_model"), {"operation": "Claudeæ¥ç¶šãƒœã‚¿ãƒ³"})

        st.markdown("---")

        if st.button("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š", width='stretch'):
            st.session_state.show_config_panel = True
            st.rerun()
        
        # ç”¨èªé›†è¡¨ç¤ºUIã‚’å‘¼ã³å‡ºã™
        show_glossary_ui()

        # --- â†“â†“â†“ ã“ã“ã‹ã‚‰ãŒè¿½åŠ ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã§ã™ â†“â†“â†“ ---
        st.markdown("---")
        st.markdown("### ğŸ§  AIæ‹¡å¼µæ©Ÿèƒ½")

        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æã®ã‚ªãƒ³/ã‚ªãƒ•ãƒˆã‚°ãƒ«
        st.session_state.use_semantic_analysis = st.toggle(
            "ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æã‚’æœ‰åŠ¹ã«ã™ã‚‹",
            value=st.session_state.get("use_semantic_analysis", False), # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚ªãƒ•
            help="ã‚ªãƒ³ã«ã™ã‚‹ã¨ã€ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åã‚„åºƒå‘Šæ–‡ã®æ„å‘³çš„ãªé¡ä¼¼æ€§åˆ†æãªã©ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ãŒã€å‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"
        )
        
        # ãƒ‡ãƒãƒƒã‚°è¨­å®š
        # Streamlitã®keyã‚’ä½¿ã£ã¦ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ç›´æ¥ç´ä»˜ã‘ã‚‹
        st.checkbox(
            "ğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰",
            key="debug_mode",
            help="ã‚ªãƒ³ã«ã™ã‚‹ã¨ã€ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«AIã®å†…éƒ¨çš„ãªå¿œç­”ã‚„ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ãªã©ã®è©³ç´°æƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
        )

        if st.session_state.debug_mode:
            st.markdown("**ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±**")
            
            # ç°¡æ˜“ã‚µãƒãƒªãƒ¼è¡¨ç¤º
            st.json({
                "ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚­ãƒ¼æ•°": len(st.session_state.keys()),
                "è¨­å®šã‚·ã‚¹ãƒ†ãƒ ": "âœ… åˆ©ç”¨å¯èƒ½" if SETTINGS_AVAILABLE else "âŒ åˆ©ç”¨ä¸å¯",
                "æœ€å¾Œã®åˆ†æ": st.session_state.get("last_user_input", "ãªã—")[:50] + "..."
            })
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®å…¨å†…å®¹è¡¨ç¤ºæ©Ÿèƒ½ã‚’è¿½åŠ 
            with st.expander("ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ï¼ˆst.session_stateï¼‰ã®å…¨å†…å®¹ã‚’è¡¨ç¤º"):
                st.json(st.session_state.to_dict(), expanded=False)


    # ğŸ”§ è¨­å®šãƒ‘ãƒãƒ«è¡¨ç¤ºå‡¦ç†ã‚’è¿½åŠ 
    if st.session_state.get("show_config_panel", False):
        if CONFIG_UI_AVAILABLE:
            show_config_panel()
        else:
            st.error("è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
        if st.button("âŒ è¨­å®šãƒ‘ãƒãƒ«ã‚’é–‰ã˜ã‚‹"):
            st.session_state.show_config_panel = False
            st.rerun()
        return

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¡¨ç¤º
    with col1:
        try:
            # â–¼â–¼â–¼ã€é‡è¦ã€‘ã“ã“ã‹ã‚‰ãŒä¿®æ­£ç®‡æ‰€ â–¼â–¼â–¼
            # ã©ã®ãƒ¢ãƒ¼ãƒ‰ã‚ˆã‚Šã‚‚å…ˆã«ã€ä¿®æ­£æ¡ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»é¢ã‚’è¡¨ç¤ºã™ã‚‹ã‹ã‚’æœ€å„ªå…ˆã§ãƒã‚§ãƒƒã‚¯
            if st.session_state.get("show_fix_review"):
                from ui_main import show_sql_fix_review_ui
                show_sql_fix_review_ui()
            
            # ä¿®æ­£æ¡ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»é¢ã‚’è¡¨ç¤ºã—ãªã„å ´åˆã«ã€é€šå¸¸ã®ãƒ¢ãƒ¼ãƒ‰åˆ¥ç”»é¢ã‚’è¡¨ç¤º
            if st.session_state.get("show_fix_review"):
                from ui_main import show_sql_fix_review_ui
                show_sql_fix_review_ui()
            elif st.session_state.view_mode == "ğŸ“Š çµ±åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ":
                if IMPORT_STATUS.get("master_analyzer"):
                    show_comprehensive_report_mode() # å¼•æ•°ãªã—ã§å‘¼ã³å‡ºã™
                else:
                    st.error("âŒ çµ±åˆåˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            elif st.session_state.view_mode == "ğŸ“… é€±æ¬¡ãƒ»æœˆæ¬¡ã‚µãƒãƒªãƒ¼":
                if IMPORT_STATUS.get("summary_system"):
                    show_summary_mode()  
                else:
                    st.error("âŒ ã‚µãƒãƒªãƒ¼æ©Ÿèƒ½ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            elif st.session_state.view_mode == "ğŸ’¡ æˆ¦ç•¥ææ¡ˆ & ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³":
                if IMPORT_STATUS.get("strategy_simulator"):
                    run_strategy_simulation()
                else:
                    st.error("âŒ æˆ¦ç•¥ææ¡ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            elif st.session_state.view_mode == "ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ºæ–­":
                if IMPORT_STATUS.get("performance_analyzer"):
                    run_performance_diagnosis()
                else:
                    st.error("âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ºæ–­ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            elif st.session_state.view_mode == "ğŸ”® äºˆæ¸¬åˆ†æ & ç•°å¸¸æ¤œçŸ¥": # ã“ã® elif ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä¸¸ã”ã¨è¿½åŠ 
                if IMPORT_STATUS.get("forecast_analyzer"):
                    run_forecast_analysis()
                else:
                    st.error("âŒ äºˆæ¸¬åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            elif st.session_state.view_mode == "ğŸ§  è‡ªå‹•ã‚¤ãƒ³ã‚µã‚¤ãƒˆåˆ†æ": # ã“ã® elif ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä¸¸ã”ã¨è¿½åŠ 
                if IMPORT_STATUS.get("insight_miner"):
                    run_insight_analysis()
                else:
                    st.error("âŒ è‡ªå‹•ã‚¤ãƒ³ã‚µã‚¤ãƒˆåˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            elif st.session_state.view_mode == "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º":
                show_dashboard_mode()
            elif st.session_state.view_mode in ["ğŸ¤– AIåˆ†æ", "âš™ï¸ æ‰‹å‹•SQLå®Ÿè¡Œ"]:
                show_ai_mode()
            elif st.session_state.view_mode == "ğŸ©º ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­":
                diagnostics.run_all_checks(
                    settings=settings,
                    bq_client=st.session_state.get("bq_client"),
                    gemini_model=st.session_state.get("gemini_model"),
                    claude_client=st.session_state.get("claude_client")
                )      
            elif st.session_state.view_mode == "ğŸ“ˆ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰":
                show_monitoring_dashboard()
            elif st.session_state.view_mode == "ğŸ”¬ ç’°å¢ƒãƒ‡ãƒãƒƒã‚°":
                show_environment_debug_page()
            # â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–²

        except Exception as e:
            st.error(f"âŒ è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}")
            if st.session_state.debug_mode:
                st.code(traceback.format_exc())
    
    # ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±
    st.markdown("---")
    footer_col1, footer_col2, footer_col3 = st.columns(3)
    with footer_col1:
        st.markdown("**ğŸš€ Version**: 2.0.0-config")
    with footer_col2:
        if SETTINGS_AVAILABLE:
            st.markdown(f"**ğŸ¤– Models**: {settings.ai.gemini_model}, {settings.ai.claude_model}")
        else:
            st.markdown("**ğŸ¤– Models**: Default")
    with footer_col3:
        st.markdown(f"**â° Last Update**: {dt.now().strftime('%Y-%m-%d %H:%M')}")

# =========================================================================
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
# =========================================================================

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"âŒ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
        st.markdown("### ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°")
        st.markdown("""
        1. **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª**: `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã¨ `config/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒæ­£ã—ãé…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹
        2. **API ã‚­ãƒ¼è¨­å®š**: ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯Streamlit Secretsã§ API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹  
        3. **ä¾å­˜é–¢ä¿‚**: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹
        4. **æ¨©é™ç¢ºèª**: BigQueryç­‰ã®ã‚µãƒ¼ãƒ“ã‚¹ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚‹ã‹
        """)
        
        if st.checkbox("ğŸ› è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º"):
            st.code(traceback.format_exc())

def show_glossary_ui():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ç”¨èªé›†ã‚’è¡¨ç¤ºã™ã‚‹UI"""
    with st.sidebar.expander("ğŸ“– ãƒ“ã‚¸ãƒã‚¹ç”¨èªé›†"):
        try:
            # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã“ã“ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            import pandas as pd
            from pathlib import Path

            glossary_path = Path("glossary.csv")
            if glossary_path.exists():
                df = pd.read_csv(glossary_path)
                # hide_index=True ã§DataFrameã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0, 1, 2...ï¼‰ã‚’éè¡¨ç¤ºã«ã™ã‚‹
                st.dataframe(df, hide_index=True)
                st.caption("ã“ã®ç”¨èªé›†ã¯ `glossary.csv` ã‚’ç·¨é›†ã™ã‚‹ã“ã¨ã§æ›´æ–°ã§ãã¾ã™ã€‚")
            else:
                st.info("`glossary.csv` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        except Exception as e:
            st.error(f"ç”¨èªé›†ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")

def display_comparative_analysis(analysis):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒåˆ†æã‚’è¡¨ç¤º"""
    if analysis.skipped:
        st.warning(f"âš ï¸ {analysis.skip_reason}")
        return
    
    # ã‚µãƒãƒªãƒ¼
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(
            "é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", 
            f"{len(analysis.high_performers)}ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³",
            f"å¹³å‡CPA: Â¥{analysis.analysis_summary['high_perf_avg_cpa']:,.0f}"
        )
    with col2:
        st.metric(
            "ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", 
            f"{len(analysis.low_performers)}ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³",
            f"å¹³å‡CPA: Â¥{analysis.analysis_summary['low_perf_avg_cpa']:,.0f}"
        )
    with col3:
        st.metric(
            "æœ‰æ„ãªå·®ç•°", 
            f"{len(analysis.significant_differences)}é …ç›®",
            "20%ä»¥ä¸Šã®å·®"
        )
    
    st.divider()
    
    # æœ‰æ„ãªå·®ç•°ã®è©³ç´°è¡¨ç¤º
    if analysis.significant_differences:
        st.subheader("ğŸ“ˆ æœ‰æ„ãªå·®ç•°ï¼ˆ20%ä»¥ä¸Šï¼‰")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å½¢å¼ã§è¡¨ç¤º
        diff_data = []
        for diff in analysis.significant_differences:
            diff_data.append({
                'æŒ‡æ¨™': diff.metric_name,
                'é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹': f"{diff.high_perf_avg:,.2f}",
                'ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹': f"{diff.low_perf_avg:,.2f}",
                'å·®ç•°': f"{diff.difference_pct:+.1f}%"
            })
        
        df = pd.DataFrame(diff_data)
        st.dataframe(df, use_container_width=True, hide_index=True)
        
        # å·®ç•°ã®å¯è¦–åŒ–
        st.subheader("ğŸ“Š å·®ç•°ã®å¯è¦–åŒ–")
        
        fig = go.Figure()
        
        metric_names = [diff.metric_name for diff in analysis.significant_differences]
        differences = [diff.difference_pct for diff in analysis.significant_differences]
        
        # è‰²åˆ†ã‘ï¼ˆæ­£ã®å·®ç•° vs è² ã®å·®ç•°ï¼‰
        colors = ['green' if d > 0 else 'red' for d in differences]
        
        fig.add_trace(go.Bar(
            x=differences,
            y=metric_names,
            orientation='h',
            marker=dict(color=colors),
            text=[f"{d:+.1f}%" for d in differences],
            textposition='outside'
        ))
        
        fig.update_layout(
            title="é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å·®ç•°",
            xaxis_title="å·®ç•°ï¼ˆ%ï¼‰",
            yaxis_title="æŒ‡æ¨™",
            height=400,
            showlegend=False
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    else:
        st.info("20%ä»¥ä¸Šã®æœ‰æ„ãªå·®ç•°ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
    
    # AIåˆ†æçµæœ
    if hasattr(analysis, 'ai_insights') and analysis.ai_insights:
        st.divider()
        st.subheader("ğŸ¤– AIåˆ†æ: å·®ç•°è¦å› ã®è§£èª¬")
        st.markdown(analysis.ai_insights)
    
    # è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¨ã‚¯ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼å†…ï¼‰
    with st.expander("ğŸ” é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³è©³ç´°"):
        high_perf_data = []
        for camp in analysis.high_performers[:10]:  # ä¸Šä½10ä»¶
            high_perf_data.append({
                'ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å': camp.campaign_name,
                'CPA': f"Â¥{camp.cpa:,.0f}",
                'ROAS': f"{camp.roas:.2f}",
                'CVR': f"{camp.conversion_rate:.2%}",
                'CTR': f"{camp.click_rate:.2%}",
                'ã‚³ã‚¹ãƒˆ': f"Â¥{camp.cost:,.0f}"
            })
        
        df_high = pd.DataFrame(high_perf_data)
        st.dataframe(df_high, use_container_width=True, hide_index=True)
    
    with st.expander("ğŸ” ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³è©³ç´°"):
        low_perf_data = []
        for camp in analysis.low_performers[:10]:  # ä¸‹ä½10ä»¶
            low_perf_data.append({
                'ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å': camp.campaign_name,
                'CPA': f"Â¥{camp.cpa:,.0f}",
                'ROAS': f"{camp.roas:.2f}",
                'CVR': f"{camp.conversion_rate:.2%}",
                'CTR': f"{camp.click_rate:.2%}",
                'ã‚³ã‚¹ãƒˆ': f"Â¥{camp.cost:,.0f}"
            })
        
        df_low = pd.DataFrame(low_perf_data)
        st.dataframe(df_low, use_container_width=True, hide_index=True)

def display_action_recommendations(recommendations):
    """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆã‚’è¡¨ç¤º"""
    if not recommendations.actions:
        st.warning("âš ï¸ " + recommendations.summary)
        return
    
    # ã‚µãƒãƒªãƒ¼
    st.markdown(recommendations.summary)
    
    st.divider()
    
    # å„ªå…ˆåº¦åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("é«˜å„ªå…ˆåº¦", recommendations.high_priority_count, "å³åº§ã«å®Ÿæ–½")
    with col2:
        st.metric("ä¸­å„ªå…ˆåº¦", recommendations.medium_priority_count, "2é€±é–“ä»¥å†…")
    with col3:
        st.metric("ä½å„ªå…ˆåº¦", recommendations.low_priority_count, "çŠ¶æ³ã«å¿œã˜ã¦")
    
    st.divider()
    
    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³é …ç›®ã®è¡¨ç¤º
    priority_icons = {
        Priority.HIGH: "ğŸ”´",
        Priority.MEDIUM: "ğŸŸ¡",
        Priority.LOW: "ğŸŸ¢"
    }
    
    for i, action in enumerate(recommendations.actions, 1):
        icon = priority_icons.get(action.priority, "âšª")
        
        with st.expander(
            f"{icon} {action.title} (å„ªå…ˆåº¦: {action.priority.value})",
            expanded=(i <= 3)  # ä¸Šä½3ä»¶ã¯å±•é–‹è¡¨ç¤º
        ):
            st.markdown(f"**ã‚«ãƒ†ã‚´ãƒª:** {action.category}")
            st.markdown(f"**å†…å®¹:**")
            st.write(action.description)
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**æœŸå¾…åŠ¹æœ:**")
                st.info(action.expected_impact)
            with col2:
                st.markdown("**æ¤œè¨¼æ–¹æ³•:**")
                st.success(action.validation_method)
    
    # AIåˆ†æçµæœ
    if hasattr(recommendations, 'ai_insights') and recommendations.ai_insights:
        st.divider()
        st.subheader("ğŸ¤– AIåˆ†æ: å®Ÿæ–½ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹")
        st.markdown(recommendations.ai_insights)
    
    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ï¼‰
    st.divider()
    st.subheader("ğŸ“‹ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ")
    
    checklist_md = "# ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ\n\n"
    checklist_md += f"ç”Ÿæˆæ—¥æ™‚: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\n\n"
    
    for priority in [Priority.HIGH, Priority.MEDIUM, Priority.LOW]:
        priority_actions = [a for a in recommendations.actions if a.priority == priority]
        if priority_actions:
            checklist_md += f"\n## {priority.value}å„ªå…ˆåº¦\n\n"
            for action in priority_actions:
                checklist_md += f"### â˜ {action.title}\n\n"
                checklist_md += f"- **å†…å®¹:** {action.description}\n"
                checklist_md += f"- **æœŸå¾…åŠ¹æœ:** {action.expected_impact}\n"
                checklist_md += f"- **æ¤œè¨¼æ–¹æ³•:** {action.validation_method}\n"
                checklist_md += f"- **ã‚«ãƒ†ã‚´ãƒª:** {action.category}\n"
                checklist_md += f"- **å®Ÿæ–½äºˆå®šæ—¥:** ____________\n"
                checklist_md += f"- **æ‹…å½“è€…:** ____________\n"
                checklist_md += f"- **å®Œäº†æ—¥:** ____________\n\n"
    
    st.download_button(
        label="ğŸ“¥ ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=checklist_md,
        file_name=f"action_checklist_{pd.Timestamp.now().strftime('%Y%m%d')}.md",
        mime="text/markdown"
    )

