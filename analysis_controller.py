# analysis_controller.py

import streamlit as st
import pandas as pd
import time
from datetime import datetime
from typing import Optional
import json

# --- å®‰å…¨ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
try:
    from bq_tool_config import settings
    SETTINGS_AVAILABLE = settings is not None
except ImportError:
    SETTINGS_AVAILABLE = False
    settings = None

try:
    from error_handler import handle_error_with_ai
except ImportError:
    def handle_error_with_ai(e, model, context):
        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")


def build_sql_from_plan(plan: dict) -> str:
    """AIãŒç”Ÿæˆã—ãŸè¨­è¨ˆæ›¸(plan)ã‹ã‚‰ã€å®‰å…¨ãªSQLæ–‡ã‚’çµ„ã¿ç«‹ã¦ã‚‹"""
    table_name = plan.get("table_to_use")
    if not table_name or not isinstance(table_name, str):
        st.warning("AIãŒä½¿ç”¨ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        table_name = "LookerStudio_report_campaign"

    full_table_path = f"`{settings.bigquery.project_id}.{settings.bigquery.dataset}.{table_name}`"
    from_clause = f"FROM\n  {full_table_path}"

    dimensions = plan.get("dimensions", [])
    metrics = plan.get("metrics", [])
    select_parts = []
    group_by_cols = []

    for col in dimensions:
        if isinstance(col, str) and col:
            select_parts.append(f"`{col}`")
            group_by_cols.append(f"`{col}`")

    for metric in metrics:
        if isinstance(metric, dict) and metric.get("expression") and metric.get("alias"):
            select_parts.append(f"{metric['expression']} AS `{metric['alias']}`")

    select_clause = "SELECT\n  " + (",\n  ".join(select_parts) if select_parts else "*")
    group_by_clause = "GROUP BY\n  " + ", ".join(group_by_cols) if group_by_cols else ""

    where_clause = ""
    if plan.get("filters"):
        conditions = []
        for f in plan.get("filters", []):
            if isinstance(f, dict) and all(k in f for k in ["column", "operator", "value"]):
                column, operator, value = f['column'], f['operator'], f['value']
                if isinstance(value, str):
                    escaped_value = value.replace("'", "''")
                    value_str = f"'{escaped_value}'"
                else:
                    value_str = str(value)
                conditions.append(f"`{column}` {operator} {value_str}")
        if conditions:
            where_clause = "WHERE\n  " + "\n  AND ".join(conditions)

    order_by_clause = ""
    if plan.get("order_by") and isinstance(plan.get("order_by"), dict) and plan["order_by"].get("column"):
        ob = plan["order_by"]
        direction = ob.get("direction", "DESC")
        order_by_clause = f"ORDER BY\n  `{ob['column']}` {direction}"

    limit_clause = f"LIMIT {int(plan['limit'])}" if plan.get("limit") else ""
    
    final_sql = "\n".join(filter(None, [select_clause, from_clause, where_clause, group_by_clause, order_by_clause, limit_clause]))
    return final_sql + ";"


def run_analysis_flow(gemini_model, user_input: str, prompt_system: str = "basic", bq_client=None) -> bool:
    """åˆ†æãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ç‰ˆï¼‰"""
    st.info("ğŸ”„ åˆ†æã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...")
    final_sql = "" # final_sqlã‚’tryãƒ–ãƒ­ãƒƒã‚¯ã®å¤–ã§åˆæœŸåŒ–

    try:
        if bq_client is None:
            bq_client = st.session_state.get("bq_client")

        if prompt_system == "enhanced":
            from enhanced_prompts import generate_sql_plan_prompt
            prompt = generate_sql_plan_prompt(user_input)
            st.info("ğŸš€ é«˜å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆè¨­è¨ˆæ›¸ãƒ¢ãƒ¼ãƒ‰ï¼‰ã‚’ä½¿ç”¨")
        else:
            from prompts import get_optimized_bigquery_template
            prompt = get_optimized_bigquery_template(user_input)
            st.info("âš¡ åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨")

        st.info("ğŸ¤– Gemini ãŒåˆ†æãƒ—ãƒ©ãƒ³ã‚’è¨­è¨ˆä¸­...")
        response = gemini_model.generate_content(prompt)

        if prompt_system == "enhanced":
            if "```json" in response.text:
                plan_json_str = response.text.strip().split("```json")[1].split("```")[0]
            else:
                plan_json_str = response.text.strip()
            plan = json.loads(plan_json_str)
            with st.expander("ğŸ“„ AIãŒç”Ÿæˆã—ãŸåˆ†æè¨­è¨ˆæ›¸ (JSON)"):
                st.json(plan)
            final_sql = build_sql_from_plan(plan)
        else:
            sql = response.text.strip()
            if "```sql" in sql:
                sql = sql.split("```sql")[1].split("```")[0].strip()
            final_sql = sql

        if not final_sql.strip():
            st.error("âŒ SQLãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return False

        with st.expander("ğŸ“„ å®Ÿè¡Œã•ã‚Œã‚‹SQL (æœ€çµ‚ç‰ˆ)", expanded=False):
            st.code(final_sql, language="sql")

        st.session_state.last_sql = final_sql
        st.session_state.last_user_input = user_input

        st.info("ğŸ“Š BigQuery ã§SQLå®Ÿè¡Œä¸­...")
        df = execute_sql_query(bq_client, final_sql)

        if df is not None:
            if not df.empty:
                st.session_state.last_analysis_result = df
                st.success(f"âœ… åˆ†æå®Œäº†ï¼ {len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
                update_usage_stats(user_input, True, prompt_system)
                st.session_state.pop("show_fix_review", None)
                return True
            else:
                st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æœŸé–“ã‚„æ¡ä»¶ã‚’å¤‰ãˆã¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                update_usage_stats(user_input, False, prompt_system)
                return False
        else:
            update_usage_stats(user_input, False, prompt_system)
            return False

    except Exception as e:
        st.error(f"åˆ†æãƒ•ãƒ­ãƒ¼ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}")
        context = { "user_input": user_input, "sql": final_sql, "generated_sql": final_sql, "operation": "AIåˆ†æå®Ÿè¡Œ" }
        handle_error_with_ai(e, st.session_state.get('gemini_model'), context)
        update_usage_stats(user_input, False, prompt_system)
        return False


def execute_sql_query(client, sql: str) -> Optional[pd.DataFrame]:
    """SQLå®Ÿè¡Œã€‚ã‚¨ãƒ©ãƒ¼ã¯å‘¼ã³å‡ºã—å…ƒã«raiseã—ã¦é›†ä¸­çš„ã«å‡¦ç†ã•ã›ã‚‹"""
    if not sql or not sql.strip():
        st.error("âŒ SQLãŒç©ºã§ã™")
        return None

    sql_upper = sql.upper().strip()
    dangerous_keywords = ['DROP', 'DELETE', 'TRUNCATE', 'ALTER', 'CREATE', 'INSERT', 'UPDATE']
    if any(keyword in sql_upper for keyword in dangerous_keywords):
        st.error(f"âŒ å±é™ºãªSQLæ“ä½œã¯å®Ÿè¡Œã§ãã¾ã›ã‚“")
        return None

    if not sql_upper.startswith('SELECT'):
        st.error("âŒ SELECTæ–‡ã®ã¿å®Ÿè¡Œå¯èƒ½ã§ã™")
        return None

    query_job = client.query(sql)
    df = query_job.to_dataframe()
    return df


def update_usage_stats(user_input: str, success: bool, system: str):
    """ä½¿ç”¨çµ±è¨ˆã®æ›´æ–°"""
    if "usage_stats" not in st.session_state:
        st.session_state.usage_stats = {"total_analyses": 0, "error_count": 0, "enhanced_usage": 0}
    
    st.session_state.usage_stats["total_analyses"] += 1
    if not success:
        st.session_state.usage_stats["error_count"] += 1
    if system == "enhanced":
        st.session_state.usage_stats["enhanced_usage"] += 1