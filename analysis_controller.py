# analysis_controller.py - å®Œå…¨ä¿®æ­£ç‰ˆ
"""
åˆ†æãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ - SQLç”Ÿæˆã‚¨ãƒ©ãƒ¼ä¿®æ­£ç‰ˆ
- åˆ†æå®Ÿè¡Œã®çµ±åˆç®¡ç†
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®é¸æŠãƒ»å®Ÿè¡Œ
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®çµ±åˆ
- å®Ÿè¡Œæ™‚é–“ã®ç®¡ç†
- å±¥æ­´ãƒ»ãƒ­ã‚°ã®è¨˜éŒ²
- SQLç”Ÿæˆãƒ»å®Ÿè¡Œã®å®Œå…¨ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
"""

import streamlit as st
import pandas as pd
import re
from datetime import datetime
from typing import Dict, List, Optional, Any

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from prompts import select_best_prompt, GENERAL_SQL_TEMPLATE
except ImportError:
    st.error("prompts.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    def select_best_prompt(user_input: str) -> dict:
        return {"description": "åŸºæœ¬åˆ†æ", "template": "åŸºæœ¬çš„ãªSQLåˆ†æ"}

try:
    from enhanced_prompts import generate_enhanced_sql_prompt, generate_enhanced_claude_prompt
except ImportError:
    st.warning("enhanced_prompts.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ä½¿ç”¨")
    generate_enhanced_sql_prompt = None
    generate_enhanced_claude_prompt = None

try:
    from error_handler import EnhancedErrorHandler, show_enhanced_error_message
except ImportError:
    st.warning("error_handler.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - åŸºæœ¬ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ã¿")
    EnhancedErrorHandler = None
    show_enhanced_error_message = None

try:
    from ui_features import log_analysis_usage, add_error_to_history
except ImportError:
    # ui_features.pyãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ä»£æ›¿é–¢æ•°
    def log_analysis_usage(user_input: str, system_type: str, execution_time: float = 0, error: bool = False):
        if "usage_stats" not in st.session_state:
            st.session_state.usage_stats = {"total_analyses": 0, "error_count": 0}
        st.session_state.usage_stats["total_analyses"] += 1
        if error:
            st.session_state.usage_stats["error_count"] += 1
    
    def add_error_to_history(error_message: str, error_category: str = "ä¸€èˆ¬ã‚¨ãƒ©ãƒ¼", solutions: List[str] = None):
        if "error_history" not in st.session_state:
            st.session_state.error_history = []
        st.session_state.error_history.append({
            "timestamp": datetime.now(),
            "message": error_message,
            "category": error_category,
            "solutions": solutions or []
        })

# =========================================================================
# SQLç”Ÿæˆã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ï¼ˆæ–°è¦è¿½åŠ ï¼‰
# =========================================================================

def clean_generated_sql(raw_sql: str) -> str:
    """
    Geminiã§ç”Ÿæˆã•ã‚ŒãŸSQLã‹ã‚‰ã‚¯ãƒªãƒ¼ãƒ³ãªSQLã‚’æŠ½å‡º
    """
    if not raw_sql or not raw_sql.strip():
        raise ValueError("ç”Ÿæˆã•ã‚ŒãŸSQLãŒç©ºã§ã™")
    
    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
    sql = re.sub(r'```sql\s*\n?', '', raw_sql, flags=re.IGNORECASE)
    sql = re.sub(r'```\s*$', '', sql)
    sql = re.sub(r'^```\s*', '', sql)
    
    # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã®é™¤å»ï¼ˆ#ã§å§‹ã¾ã‚‹è¡Œã€--ã§å§‹ã¾ã‚‹è¡Œï¼‰
    lines = sql.split('\n')
    sql_lines = []
    for line in lines:
        line = line.strip()
        if line and not line.startswith('#') and not line.startswith('--'):
            sql_lines.append(line)
    
    sql = ' '.join(sql_lines)
    
    # ä½™åˆ†ãªç©ºç™½ã‚’é™¤å»
    sql = re.sub(r'\s+', ' ', sql).strip()
    
    # SQLã®åŸºæœ¬çš„ãªæ§‹æ–‡ãƒã‚§ãƒƒã‚¯
    if not sql.upper().startswith('SELECT'):
        # SELECTã§å§‹ã¾ã‚‰ãªã„å ´åˆã€æœ€åˆã®SELECTæ–‡ã‚’æ¢ã™
        select_match = re.search(r'\bSELECT\b', sql, re.IGNORECASE)
        if select_match:
            sql = sql[select_match.start():]
        else:
            raise ValueError("æœ‰åŠ¹ãªSELECTæ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # æœ«å°¾ã®ã‚»ãƒŸã‚³ãƒ­ãƒ³ã‚’é™¤å»ï¼ˆBigQueryã§ã¯ä¸è¦ï¼‰
    sql = sql.rstrip(';')
    
    # ç©ºã®SQLãƒã‚§ãƒƒã‚¯
    if len(sql.strip()) < 10:  # SELECTç¨‹åº¦ã®æœ€å°é•·
        raise ValueError("ç”Ÿæˆã•ã‚ŒãŸSQLãŒçŸ­ã™ãã¾ã™")
    
    return sql

def validate_basic_sql_syntax(sql: str) -> bool:
    """
    åŸºæœ¬çš„ãªSQLæ§‹æ–‡ã®æ¤œè¨¼
    """
    if not sql or len(sql.strip()) < 6:
        return False
    
    sql_upper = sql.upper().strip()
    
    # SELECTæ–‡ã§å§‹ã¾ã‚‹ã“ã¨ã‚’ç¢ºèª
    if not sql_upper.startswith('SELECT'):
        return False
    
    # åŸºæœ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å­˜åœ¨ç¢ºèª
    if 'FROM' not in sql_upper:
        return False
    
    # å±é™ºãªSQLæ–‡ã®é™¤å¤–
    dangerous_keywords = ['DROP', 'DELETE', 'TRUNCATE', 'ALTER', 'CREATE', 'INSERT', 'UPDATE']
    for keyword in dangerous_keywords:
        if keyword in sql_upper:
            return False
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«åã®ç¢ºèª
    if 'vorn-digi-mktg-poc-635a' not in sql:
        return False
    
    return True

def execute_gemini_sql_generation(gemini_model, user_input: str, max_attempts: int = 3) -> Optional[str]:
    """
    Gemini ã§ã®SQLç”Ÿæˆï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰
    """
    for attempt in range(max_attempts):
        try:
            st.info(f"ğŸ§  Gemini ã§SQLç”Ÿæˆä¸­... (è©¦è¡Œ {attempt + 1}/{max_attempts})")
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
            sql_prompt = create_enhanced_sql_prompt(user_input)
            
            # Gemini APIå‘¼ã³å‡ºã—
            response = gemini_model.generate_content(sql_prompt)
            
            if not response or not response.text:
                st.warning("Geminiã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã—ãŸã€‚å†è©¦è¡Œã—ã¾ã™...")
                continue
            
            # ãƒ‡ãƒãƒƒã‚°: ç”Ÿæˆã•ã‚ŒãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¡¨ç¤º
            with st.expander(f"ğŸ” ãƒ‡ãƒãƒƒã‚°: Geminiãƒ¬ã‚¹ãƒãƒ³ã‚¹ (è©¦è¡Œ{attempt+1})", expanded=False):
                st.text(response.text[:500] + "..." if len(response.text) > 500 else response.text)
            
            # SQLã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            cleaned_sql = clean_generated_sql(response.text)
            
            # SQLæ§‹æ–‡ã®åŸºæœ¬çš„ãªæ¤œè¨¼
            if validate_basic_sql_syntax(cleaned_sql):
                st.success("âœ… æœ‰åŠ¹ãªSQLãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
                return cleaned_sql
            else:
                st.warning(f"âš ï¸ SQLæ§‹æ–‡ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚å†è©¦è¡Œã—ã¾ã™... (è©¦è¡Œ {attempt + 1})")
                continue
                
        except ValueError as e:
            st.warning(f"âš ï¸ SQLæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            if attempt == max_attempts - 1:
                st.error("âŒ SQLç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§SQLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                return None
            continue
            
        except Exception as e:
            st.error(f"âŒ Gemini API ã‚¨ãƒ©ãƒ¼: {e}")
            if attempt == max_attempts - 1:
                return None
            continue
    
    return None

def create_enhanced_sql_prompt(user_input: str) -> str:
    """
    å¼·åŒ–ã•ã‚ŒãŸSQLç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    """
    try:
        prompt_info = select_best_prompt(user_input)
        base_template = prompt_info["template"]
    except (ImportError, NameError):
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        base_template = """
# ã‚ãªãŸã¯åºƒå‘Šåˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
# ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡ç¤º: {user_input}
# åˆ†æå¯¾è±¡: `vorn-digi-mktg-poc-635a.toki_air.LookerStudio_report_campaign`
# å‡ºåŠ›: å®Ÿè¡Œå¯èƒ½ãªBigQuery SQLã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã‚„ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã¯ä¸è¦ã§ã™ã€‚
"""
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å¼·åŒ–
    enhanced_prompt = f"""
{base_template.format(user_input=user_input)}

## é‡è¦ãªå‡ºåŠ›è¦ä»¶:
1. SQLã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„
2. ```sql``` ãªã©ã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„
3. ã‚³ãƒ¡ãƒ³ãƒˆè¡Œ(#ã§å§‹ã¾ã‚‹è¡Œ)ã¯å«ã‚ãªã„ã§ãã ã•ã„
4. èª¬æ˜æ–‡ã¯ä¸è¦ã§ã™
5. SELECTã§å§‹ã¾ã‚‹å®Ÿè¡Œå¯èƒ½ãªã‚¯ã‚¨ãƒªã®ã¿è¿”ã—ã¦ãã ã•ã„

## SQLåˆ¶ç´„:
- SELECTæ–‡ã®ã¿è¨±å¯ï¼ˆINSERTã€UPDATEã€DELETEç­‰ã¯ç¦æ­¢ï¼‰
- ãƒ†ãƒ¼ãƒ–ãƒ«åã¯å¿…ãš `vorn-digi-mktg-poc-635a.toki_air.LookerStudio_report_campaign` ã‚’ä½¿ç”¨
- SAFE_DIVIDE()ã‚’ä½¿ç”¨ã—ã¦ã‚¼ãƒ­é™¤ç®—ã‚’å›é¿
- çµæœã¯é€šå¸¸20è¡Œä»¥ä¸‹ã«åˆ¶é™ï¼ˆLIMITå¥ä½¿ç”¨ï¼‰

## åˆ©ç”¨å¯èƒ½ãªä¸»è¦åˆ—:
- Date: æ—¥ä»˜
- CampaignName: ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å
- ServiceNameJA_Media: ãƒ¡ãƒ‡ã‚£ã‚¢å
- Impressions: ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°
- Clicks: ã‚¯ãƒªãƒƒã‚¯æ•°
- Conversions: ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°
- CostIncludingFees: ã‚³ã‚¹ãƒˆï¼ˆæ‰‹æ•°æ–™è¾¼ã¿ï¼‰

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åˆ†æè¦æ±‚: {user_input}
"""
    
    return enhanced_prompt

# =========================================================================
# SQLå®Ÿè¡Œæ©Ÿèƒ½ï¼ˆä¿®æ­£ç‰ˆï¼‰
# =========================================================================

def execute_sql_with_enhanced_handling(client, sql: str) -> Optional[pd.DataFrame]:
    """
    SQLã‚’å®Ÿè¡Œã—ã€è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¡Œã†ï¼ˆä¿®æ­£ç‰ˆï¼‰
    """
    try:
        # å…¥åŠ›æ¤œè¨¼
        if not sql or not sql.strip():
            st.error("âŒ å®Ÿè¡Œã™ã‚‹SQLãŒç©ºã§ã™")
            return None
            
        # SQLã®åŸºæœ¬çš„ãªå®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
        sql = sql.strip()
        
        # ãƒ‡ãƒãƒƒã‚°: å®Ÿéš›ã«å®Ÿè¡Œã•ã‚Œã‚‹SQLã‚’è¡¨ç¤º
        with st.expander("ğŸ” å®Ÿè¡Œäºˆå®šã®SQL", expanded=False):
            st.code(sql, language="sql")
        
        if not sql:
            st.error("âŒ SQLãŒç©ºã§ã™")
            return None
            
        # SQLã®åŸºæœ¬æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
        sql_upper = sql.upper()
        if not sql_upper.startswith('SELECT'):
            st.error("âŒ SELECTæ–‡ã®ã¿å®Ÿè¡Œå¯èƒ½ã§ã™")
            return None
            
        # å±é™ºãªSQLæ–‡ã®é™¤å¤–
        dangerous_keywords = ['DROP', 'DELETE', 'TRUNCATE', 'ALTER', 'CREATE', 'INSERT', 'UPDATE']
        for keyword in dangerous_keywords:
            if keyword in sql_upper:
                st.error(f"âŒ å±é™ºãªSQLæ“ä½œ '{keyword}' ã¯å®Ÿè¡Œã§ãã¾ã›ã‚“")
                return None
        
        # BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ç¢ºèª
        if not client:
            st.error("âŒ BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
            
        # SQLå®Ÿè¡Œ
        st.info("â³ BigQueryã§ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œä¸­...")
        query_job = client.query(sql)
        
        # çµæœã®å–å¾—
        df = query_job.to_dataframe()
        
        # çµæœã®æ¤œè¨¼
        if df is None:
            st.warning("âš ï¸ ã‚¯ã‚¨ãƒªçµæœãŒNullã§ã™")
            return pd.DataFrame()
            
        if df.empty:
            st.warning("âš ï¸ ã‚¯ã‚¨ãƒªã¯æ­£å¸¸ã«å®Ÿè¡Œã•ã‚Œã¾ã—ãŸãŒã€çµæœãŒç©ºã§ã—ãŸ")
            st.info("ğŸ’¡ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‚’ç·©ãã™ã‚‹ã‹ã€ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ã™ã‚‹æ—¥ä»˜ç¯„å›²ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            return df
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®è­¦å‘Š
        row_count = len(df)
        if row_count > 10000:
            st.warning(f"âš ï¸ å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ ({row_count:,}è¡Œ) ãŒå–å¾—ã•ã‚Œã¾ã—ãŸã€‚è¡¨ç¤ºã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™")
        elif row_count > 1000:
            st.info(f"â„¹ï¸ {row_count:,}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
        else:
            st.success(f"âœ… {row_count}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
            
        return df
        
    except Exception as e:
        # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã®è¡¨ç¤º
        error_str = str(e)
        st.error(f"âŒ SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {error_str}")
        
        # ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡åˆ¥å¯¾å¿œ
        if "Syntax error" in error_str:
            st.error("ğŸ” **SQLæ§‹æ–‡ã‚¨ãƒ©ãƒ¼**")
            st.info("ğŸ’¡ ç”Ÿæˆã•ã‚ŒãŸSQLã«æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
            st.markdown("""
            - SELECTæ–‡ã§å§‹ã¾ã£ã¦ã„ã‚‹ã‹
            - ã‚«ãƒ³ãƒã‚„ã‚¯ã‚©ãƒ¼ãƒˆãŒæ­£ã—ãè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã‹  
            - ãƒ†ãƒ¼ãƒ–ãƒ«åãŒæ­£ç¢ºã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã‹
            """)
            
        elif "Table" in error_str and "not found" in error_str:
            st.error("ğŸ” **ãƒ†ãƒ¼ãƒ–ãƒ«æœªç™ºè¦‹ã‚¨ãƒ©ãƒ¼**")
            st.info("ğŸ’¡ æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            
        elif "Column" in error_str and "not found" in error_str:
            st.error("ğŸ” **åˆ—æœªç™ºè¦‹ã‚¨ãƒ©ãƒ¼**") 
            st.info("ğŸ’¡ å­˜åœ¨ã—ãªã„åˆ—åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã™")
            
        elif "Access Denied" in error_str or "permission" in error_str.lower():
            st.error("ğŸ” **ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚¨ãƒ©ãƒ¼**")
            st.info("ğŸ’¡ BigQueryã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            
        else:
            st.error("ğŸ” **ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼**")
            st.info("ğŸ’¡ è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã€ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„")
        
        # ã‚¨ãƒ©ãƒ¼å±¥æ­´ã¸ã®è¿½åŠ ï¼ˆå¯èƒ½ã§ã‚ã‚Œã°ï¼‰
        try:
            if show_enhanced_error_message:
                show_enhanced_error_message(e, {"sql": sql, "operation": "SQLå®Ÿè¡Œ"})
        except:
            pass  # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            
        return None

# =========================================================================
# ãƒ¡ã‚¤ãƒ³åˆ†æãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ï¼ˆä¿®æ­£ç‰ˆï¼‰
# =========================================================================

def run_analysis_flow(gemini_model, claude_client, claude_model_name, user_input, sheet_analysis_queries):
    """
    ä¿®æ­£ã•ã‚ŒãŸåˆ†æãƒ•ãƒ­ãƒ¼å®Ÿè¡Œé–¢æ•°
    """
    if not user_input or not user_input.strip():
        st.error("âŒ åˆ†ææŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return
    
    start_time = datetime.now()
    
    try:
        # SQLç”Ÿæˆæ®µéš
        with st.spinner("ğŸ§  AIãŒSQLã‚’ç”Ÿæˆä¸­..."):
            generated_sql = execute_gemini_sql_generation(gemini_model, user_input)
            
            if not generated_sql:
                st.error("âŒ SQLç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                show_manual_sql_input()
                return
        
        # ç”Ÿæˆã•ã‚ŒãŸSQLã®è¡¨ç¤º
        with st.expander("ğŸ“ ç”Ÿæˆã•ã‚ŒãŸSQL", expanded=False):
            st.code(generated_sql, language="sql")
        
        # SQLå®Ÿè¡Œæ®µéš
        with st.spinner("ğŸ” ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
            df = execute_sql_with_enhanced_handling(st.session_state.bq_client, generated_sql)
            
            if df is None or df.empty:
                st.error("âŒ ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                show_error_recovery_options(user_input)
                return
        
        # çµæœã®ä¿å­˜
        st.session_state.sql = generated_sql
        st.session_state.df = df
        st.session_state.user_input = user_input
        
        st.success(f"âœ… åˆ†æå®Œäº†ï¼ {len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
        
        # Claudeåˆ†æã®å®Ÿè¡Œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if st.session_state.get("auto_claude_analysis", True):
            run_claude_analysis(claude_client, claude_model_name, df)
        
        # å®Ÿè¡Œæ™‚é–“ã®è¨˜éŒ²
        execution_time = (datetime.now() - start_time).total_seconds()
        log_analysis_usage(user_input, "enhanced", execution_time, False)
        
        # åˆ†æå¾Œå‡¦ç†
        post_process_analysis_results()
        
        return True
        
    except Exception as e:
        execution_time = (datetime.now() - start_time).total_seconds()
        log_analysis_usage(user_input, "enhanced", execution_time, True)
        
        st.error(f"âŒ åˆ†æå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        show_error_recovery_options(user_input)
        return False

def show_manual_sql_input():
    """
    æ‰‹å‹•SQLå…¥åŠ›ã®UI
    """
    st.warning("âš ï¸ è‡ªå‹•SQLç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§SQLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    with st.expander("âœï¸ æ‰‹å‹•SQLå…¥åŠ›", expanded=True):
        manual_sql = st.text_area(
            "SQLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            value="SELECT CampaignName, SUM(CostIncludingFees) as Cost, SUM(Clicks) as Clicks FROM `vorn-digi-mktg-poc-635a.toki_air.LookerStudio_report_campaign` GROUP BY CampaignName ORDER BY Cost DESC LIMIT 10",
            height=200
        )
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸš€ æ‰‹å‹•SQLã‚’å®Ÿè¡Œ"):
                df = execute_sql_with_enhanced_handling(st.session_state.bq_client, manual_sql)
                if df is not None:
                    st.session_state.sql = manual_sql
                    st.session_state.df = df
        
        with col2:
            if st.button("ğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«SQLã‚’ä½¿ç”¨"):
                sample_sqls = {
                    "ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åˆ¥ã‚³ã‚¹ãƒˆä¸Šä½10": "SELECT CampaignName, SUM(CostIncludingFees) as Cost FROM `vorn-digi-mktg-poc-635a.toki_air.LookerStudio_report_campaign` GROUP BY CampaignName ORDER BY Cost DESC LIMIT 10",
                    "æ—¥åˆ¥ã‚¯ãƒªãƒƒã‚¯æ•°": "SELECT Date, SUM(Clicks) as Clicks FROM `vorn-digi-mktg-poc-635a.toki_air.LookerStudio_report_campaign` GROUP BY Date ORDER BY Date DESC LIMIT 30",
                    "ãƒ¡ãƒ‡ã‚£ã‚¢åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹": "SELECT ServiceNameJA_Media, SUM(CostIncludingFees) as Cost, SUM(Clicks) as Clicks, SUM(Conversions) as Conversions FROM `vorn-digi-mktg-poc-635a.toki_air.LookerStudio_report_campaign` GROUP BY ServiceNameJA_Media ORDER BY Cost DESC"
                }
                
                selected_sample = st.selectbox("ã‚µãƒ³ãƒ—ãƒ«SQLã‚’é¸æŠ", list(sample_sqls.keys()))
                st.code(sample_sqls[selected_sample], language="sql")

def show_error_recovery_options(user_input: str):
    """
    ã‚¨ãƒ©ãƒ¼å›å¾©ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è¡¨ç¤º
    """
    st.markdown("### ğŸ”§ è§£æ±ºæ–¹æ³•")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ”„ å†è©¦è¡Œ", type="primary"):
            st.rerun()
    
    with col2:
        if st.button("âœï¸ æ‰‹å‹•å…¥åŠ›"):
            show_manual_sql_input()
    
    with col3:
        if st.button("ğŸ’¡ æŒ‡ç¤ºã‚’å¤‰æ›´"):
            st.info("ã‚ˆã‚Šå…·ä½“çš„ãªæŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ã¿ã¦ãã ã•ã„")
    
    # ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–
    with st.expander("ğŸ’¡ ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–"):
        st.markdown("""
        **ä¸€èˆ¬çš„ãªåŸå› :**
        - AIãŒç†è§£ã§ããªã„æ›–æ˜§ãªæŒ‡ç¤º
        - å­˜åœ¨ã—ãªã„åˆ—åã‚„æ©Ÿèƒ½ã®æŒ‡å®š
        - è¤‡é›‘ã™ãã‚‹åˆ†æè¦æ±‚
        
        **æ”¹å–„æ–¹æ³•:**
        - ã‚ˆã‚Šå…·ä½“çš„ã§æ˜ç¢ºãªæŒ‡ç¤ºã«å¤‰æ›´
        - ã€Œã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åˆ¥ã®ã€ã€Œæ—¥åˆ¥ã®ã€ãªã©å…·ä½“çš„ãªè»¸ã‚’æŒ‡å®š
        - ä¸€åº¦ã«è¤‡æ•°ã®åˆ†æã‚’æ±‚ã‚ãšã€æ®µéšçš„ã«å®Ÿè¡Œ
        
        **æŒ‡ç¤ºã®ä¾‹:**
        - âœ… "ã‚³ã‚¹ãƒˆä¸Šä½10ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’è¡¨ç¤º"
        - âœ… "éå»30æ—¥é–“ã®æ—¥åˆ¥ã‚¯ãƒªãƒƒã‚¯æ•°"
        - âŒ "å…¨ä½“çš„ãªå‚¾å‘ã‚’åˆ†æã—ã¦"
        - âŒ "ã„ã‚ã‚“ãªè§’åº¦ã‹ã‚‰è©³ã—ã"
        """)

def run_claude_analysis(claude_client, claude_model_name: str, df):
    """
    Claudeåˆ†æã®å®Ÿè¡Œ
    """
    try:
        if df is None or df.empty:
            return
        
        with st.spinner("ğŸ¯ ClaudeãŒåˆ†æä¸­..."):
            # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã®ä½œæˆ
            data_sample = df.head(10).to_string()
            
            # Claudeãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            claude_prompt = f"""
ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ã€é‡è¦ãªæ´å¯Ÿã¨æ”¹å–„ææ¡ˆã‚’3ã¤ä»¥å†…ã§ç°¡æ½”ã«è¿°ã¹ã¦ãã ã•ã„ã€‚

ãƒ‡ãƒ¼ã‚¿:
{data_sample}

åˆ†æçµæœã‚’ç®‡æ¡æ›¸ãã§è¿°ã¹ã¦ãã ã•ã„:
"""
            
            response = claude_client.messages.create(
                model=claude_model_name,
                max_tokens=1000,
                messages=[{"role": "user", "content": claude_prompt}]
            )
            
            if response and response.content:
                st.session_state.comment = response.content[0].text
                st.success("âœ… Claudeåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
    except Exception as e:
        st.warning(f"âš ï¸ Claudeåˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.info("ğŸ’¡ SQLå®Ÿè¡Œçµæœã¯æ­£å¸¸ã«å–å¾—ã•ã‚Œã¦ã„ã¾ã™ã€‚")

# =========================================================================
# æ—¢å­˜ã®é–¢æ•°ç¾¤ï¼ˆäº’æ›æ€§ã®ãŸã‚ç¶­æŒï¼‰
# =========================================================================

def execute_gemini_sql_analysis(gemini_model, user_input: str, system_type: str) -> bool:
    """Geminiç”¨SQLåˆ†æã®å®Ÿè¡Œï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰"""
    try:
        generated_sql = execute_gemini_sql_generation(gemini_model, user_input)
        if generated_sql:
            df = execute_sql_with_enhanced_handling(st.session_state.bq_client, generated_sql)
            if df is not None and not df.empty:
                st.session_state.sql = generated_sql
                st.session_state.df = df
                st.session_state.user_input = user_input
                return True
        return False
    except Exception as e:
        st.error(f"âŒ Gemini SQLç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        add_error_to_history(str(e), "Gemini SQLç”Ÿæˆã‚¨ãƒ©ãƒ¼", ["ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¦‹ç›´ã—ã¦ãã ã•ã„", "APIæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„"])
        return False

def execute_claude_analysis(claude_client, claude_model_name: str, user_input: str, system_type: str) -> bool:
    """Claudeåˆ†æã®å®Ÿè¡Œï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰"""
    try:
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿Claudeåˆ†æã‚’å®Ÿè¡Œ
        if st.session_state.get("df") is not None and not st.session_state.df.empty:
            st.info("ğŸ¯ Claudeã§è©³ç´°åˆ†æã‚’å®Ÿè¡Œä¸­...")
            
            data_sample = st.session_state.df.head(20).to_string()
            claude_prompt = generate_claude_prompt(data_sample, system_type)
            
            # Claudeåˆ†æã®å®Ÿè¡Œ
            response = claude_client.messages.create(
                model=claude_model_name,
                max_tokens=3000,
                messages=[{"role": "user", "content": claude_prompt}]
            )
            
            st.session_state.comment = response.content[0].text
            st.success("âœ… Claudeåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            return True
            
        else:
            st.warning("åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšGeminiã§SQLã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
            return False
            
    except Exception as e:
        st.error(f"âŒ Claudeåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        add_error_to_history(str(e), "Claudeåˆ†æã‚¨ãƒ©ãƒ¼", ["APIæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„", "ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„"])
        return False

# =========================================================================
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆï¼ˆæ—¢å­˜é–¢æ•°ã®äº’æ›æ€§ç¶­æŒï¼‰
# =========================================================================

def generate_sql_prompt(user_input: str, system_type: str) -> str:
    """SQLãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆ"""
    if system_type == "enhanced" and generate_enhanced_sql_prompt:
        try:
            return generate_enhanced_sql_prompt(user_input)
        except Exception as e:
            st.warning(f"å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}ã€‚åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return create_basic_sql_prompt(user_input)
    else:
        return create_basic_sql_prompt(user_input)

def generate_claude_prompt(data_sample: str, system_type: str) -> str:
    """Claudeãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆ"""
    if system_type == "enhanced" and generate_enhanced_claude_prompt:
        try:
            return generate_enhanced_claude_prompt(
                data_sample, 
                str(st.session_state.get("graph_cfg", {}))
            )
        except Exception as e:
            st.warning(f"å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}ã€‚åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return f"ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’è©³ç´°ã«åˆ†æã—ã¦ãã ã•ã„:\n\n{data_sample}"
    else:
        return f"ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ãã ã•ã„:\n\n{data_sample}"

def create_basic_sql_prompt(user_input: str) -> str:
    """åŸºæœ¬SQLãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ"""
    return create_enhanced_sql_prompt(user_input)  # æ–°ã—ã„é–¢æ•°ã‚’ä½¿ç”¨

# =========================================================================
# ãã®ä»–ã®æ—¢å­˜é–¢æ•°ç¾¤ï¼ˆãã®ã¾ã¾ç¶­æŒï¼‰
# =========================================================================

def execute_sql_and_store_results(sql: str, user_input: str) -> bool:
    """SQLã®å®Ÿè¡Œã¨çµæœã®ä¿å­˜"""
    try:
        df = execute_sql_with_enhanced_handling(st.session_state.bq_client, sql)
        
        if df is not None and not df.empty:
            # çµæœã®ä¿å­˜
            st.session_state.sql = sql
            st.session_state.df = df
            st.session_state.user_input = user_input
            
            # åŸºæœ¬çš„ãªçµæœæƒ…å ±ã®è¡¨ç¤º
            st.success(f"âœ… SQLå®Ÿè¡Œå®Œäº†ï¼{len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
            
            # ãƒ‡ãƒ¼ã‚¿å“è³ªã®ç°¡æ˜“ãƒã‚§ãƒƒã‚¯
            perform_basic_data_validation(df)
            
            return True
        else:
            st.error("âŒ SQLã®å®Ÿè¡Œã«å¤±æ•—ã—ãŸã‹ã€çµæœãŒç©ºã§ã—ãŸã€‚")
            return False
            
    except Exception as e:
        handle_sql_execution_error(e, sql)
        return False

def perform_basic_data_validation(df: pd.DataFrame):
    """åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ¤œè¨¼"""
    issues = []
    
    # NULLå€¤ã®å¤šã„åˆ—ã‚’ãƒã‚§ãƒƒã‚¯
    null_rates = (df.isnull().sum() / len(df)) * 100
    high_null_cols = null_rates[null_rates > 30].index.tolist()
    if high_null_cols:
        issues.append(f"NULLå€¤ã®å¤šã„åˆ—: {', '.join(high_null_cols)}")
    
    # é‡è¤‡è¡Œã®ãƒã‚§ãƒƒã‚¯
    duplicate_count = df.duplicated().sum()
    if duplicate_count > 0:
        issues.append(f"é‡è¤‡è¡Œ: {duplicate_count}è¡Œ")
    
    # è­¦å‘Šã®è¡¨ç¤º
    if issues:
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿å“è³ªã«é–¢ã™ã‚‹æ³¨æ„ç‚¹:")
        for issue in issues:
            st.caption(f"â€¢ {issue}")

def post_process_analysis_results():
    """åˆ†æçµæœã®å¾Œå‡¦ç†"""
    if st.session_state.get("df") is not None and not st.session_state.df.empty:
        df = st.session_state.df
        
        # åŸºæœ¬çµ±è¨ˆã®è¨ˆç®—ã¨ä¿å­˜
        basic_stats = calculate_basic_statistics(df)
        st.session_state.analysis_stats = basic_stats
        
        # ã‚°ãƒ©ãƒ•è¨­å®šã®æ¨å¥¨
        recommend_visualization_settings(df)

def calculate_basic_statistics(df: pd.DataFrame) -> Dict[str, Any]:
    """åŸºæœ¬çµ±è¨ˆã®è¨ˆç®—"""
    stats = {
        "row_count": len(df),
        "column_count": len(df.columns),
        "numeric_columns": len(df.select_dtypes(include=['number']).columns),
        "categorical_columns": len(df.select_dtypes(include=['object', 'category']).columns),
        "null_percentage": (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100,
        "memory_usage_mb": df.memory_usage(deep=True).sum() / 1024 / 1024
    }
    
    return stats

def recommend_visualization_settings(df: pd.DataFrame):
    """å¯è¦–åŒ–è¨­å®šã®æ¨å¥¨"""
    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    
    recommendations = []
    
    # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æ¤œå‡º
    date_cols = [col for col in df.columns if 'date' in col.lower() or 'æ—¥ä»˜' in col]
    if date_cols and numeric_cols:
        recommendations.append({
            "type": "æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•",
            "x_axis": date_cols[0],
            "y_axis": numeric_cols[0],
            "description": "æ™‚é–“ã®å¤‰åŒ–ã«ä¼´ã†ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ç¢ºèª"
        })
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥æ¯”è¼ƒã®æ¨å¥¨
    if categorical_cols and numeric_cols:
        recommendations.append({
            "type": "æ£’ã‚°ãƒ©ãƒ•",
            "x_axis": categorical_cols[0],
            "y_axis": numeric_cols[0],
            "description": "ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ"
        })
    
    # ç›¸é–¢åˆ†æã®æ¨å¥¨
    if len(numeric_cols) >= 2:
        recommendations.append({
            "type": "æ•£å¸ƒå›³",
            "x_axis": numeric_cols[0],
            "y_axis": numeric_cols[1],
            "description": "2ã¤ã®æŒ‡æ¨™ã®ç›¸é–¢é–¢ä¿‚ã‚’ç¢ºèª"
        })
    
    # æ¨å¥¨è¨­å®šã®ä¿å­˜
    st.session_state.visualization_recommendations = recommendations

# =========================================================================
# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
# =========================================================================

def handle_analysis_error(error: Exception, user_input: str, system_type: str):
    """åˆ†æã‚¨ãƒ©ãƒ¼ã®çµ±åˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
    error_context = {
        "user_input": user_input,
        "system_type": system_type,
        "sql": st.session_state.get("sql", "")
    }
    
    if show_enhanced_error_message:
        # å¼·åŒ–ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨
        show_enhanced_error_message(error, error_context)
    else:
        # åŸºæœ¬ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
        st.error(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {str(error)}")
        add_error_to_history(str(error), "åˆ†æå®Ÿè¡Œã‚¨ãƒ©ãƒ¼", ["å…¥åŠ›å†…å®¹ã‚’ç¢ºèªã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„"])

def handle_sql_execution_error(error: Exception, sql: str):
    """SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã®å‡¦ç†"""
    error_context = {
        "sql": sql,
        "error_type": "SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼"
    }
    
    if show_enhanced_error_message:
        show_enhanced_error_message(error, error_context)
    else:
        st.error(f"âŒ SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(error)}")
        add_error_to_history(str(error), "SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼", ["SQLã®æ§‹æ–‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„", "ãƒ†ãƒ¼ãƒ–ãƒ«åãƒ»åˆ—åã‚’ç¢ºèªã—ã¦ãã ã•ã„"])

# =========================================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
# =========================================================================

def initialize_analysis_session():
    """åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–"""
    if "analysis_session" not in st.session_state:
        st.session_state.analysis_session = {
            "session_id": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "start_time": datetime.now(),
            "analyses_count": 0,
            "total_execution_time": 0,
            "errors_count": 0,
            "last_analysis": None
        }

def update_analysis_session(execution_time: float, error: bool = False):
    """åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æ›´æ–°"""
    if "analysis_session" not in st.session_state:
        initialize_analysis_session()
    
    session = st.session_state.analysis_session
    session["analyses_count"] += 1
    session["total_execution_time"] += execution_time
    session["last_analysis"] = datetime.now()
    
    if error:
        session["errors_count"] += 1

def get_session_summary() -> Dict[str, Any]:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚µãƒãƒªãƒ¼ã®å–å¾—"""
    if "analysis_session" not in st.session_state:
        initialize_analysis_session()
    
    session = st.session_state.analysis_session
    
    return {
        "session_duration": (datetime.now() - session["start_time"]).total_seconds() / 60,  # åˆ†
        "analyses_count": session["analyses_count"],
        "avg_execution_time": session["total_execution_time"] / max(session["analyses_count"], 1),
        "error_rate": session["errors_count"] / max(session["analyses_count"], 1) * 100,
        "success_rate": (session["analyses_count"] - session["errors_count"]) / max(session["analyses_count"], 1) * 100
    }

# =========================================================================
# åˆ†æå±¥æ­´ç®¡ç†
# =========================================================================

def save_analysis_to_history(user_input: str, sql: str, df: pd.DataFrame, system_type: str):
    """åˆ†æã‚’å±¥æ­´ã«ä¿å­˜"""
    if "analysis_history" not in st.session_state:
        st.session_state.analysis_history = []
    
    history_entry = {
        "timestamp": datetime.now(),
        "user_input": user_input,
        "sql": sql,
        "row_count": len(df) if df is not None else 0,
        "system_type": system_type,
        "columns": list(df.columns) if df is not None else [],
        "success": True
    }
    
    st.session_state.analysis_history.append(history_entry)
    
    # å±¥æ­´ã®ä¸Šé™ç®¡ç†
    if len(st.session_state.analysis_history) > 50:
        st.session_state.analysis_history = st.session_state.analysis_history[-50:]

def load_analysis_from_history(history_index: int):
    """å±¥æ­´ã‹ã‚‰åˆ†æã‚’å¾©å…ƒ"""
    if "analysis_history" not in st.session_state or history_index >= len(st.session_state.analysis_history):
        st.error("æŒ‡å®šã•ã‚ŒãŸå±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return False
    
    history_entry = st.session_state.analysis_history[history_index]
    
    try:
        # å±¥æ­´ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å¾©å…ƒ
        st.session_state.user_input = history_entry["user_input"]
        st.session_state.sql = history_entry["sql"]
        st.session_state.use_enhanced_prompts = (history_entry["system_type"] == "enhanced")
        
        # SQLã‚’å†å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        if history_entry["sql"]:
            execute_sql_and_store_results(history_entry["sql"], history_entry["user_input"])
        
        st.success(f"âœ… å±¥æ­´ã‹ã‚‰åˆ†æã‚’å¾©å…ƒã—ã¾ã—ãŸ: {history_entry['user_input'][:50]}...")
        return True
        
    except Exception as e:
        st.error(f"å±¥æ­´ã®å¾©å…ƒã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False

# =========================================================================
# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
# =========================================================================

def analyze_performance_metrics():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã®åˆ†æ"""
    session_summary = get_session_summary()
    
    performance_insights = []
    
    # å®Ÿè¡Œæ™‚é–“ã®è©•ä¾¡
    avg_time = session_summary["avg_execution_time"]
    if avg_time > 30:
        performance_insights.append({
            "type": "warning",
            "message": f"å¹³å‡å®Ÿè¡Œæ™‚é–“ãŒé•·ã‚ã§ã™ï¼ˆ{avg_time:.1f}ç§’ï¼‰",
            "suggestion": "ãƒ‡ãƒ¼ã‚¿é‡ã‚’æ¸›ã‚‰ã™ã‹LIMITå¥ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„"
        })
    elif avg_time < 5:
        performance_insights.append({
            "type": "success",
            "message": f"é«˜é€Ÿãªå®Ÿè¡Œæ™‚é–“ã§ã™ï¼ˆ{avg_time:.1f}ç§’ï¼‰",
            "suggestion": "ç¾åœ¨ã®ã‚¯ã‚¨ãƒªè¨­è¨ˆãŒåŠ¹ç‡çš„ã§ã™"
        })
    
    # ã‚¨ãƒ©ãƒ¼ç‡ã®è©•ä¾¡
    error_rate = session_summary["error_rate"]
    if error_rate > 30:
        performance_insights.append({
            "type": "critical",
            "message": f"ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã„ã§ã™ï¼ˆ{error_rate:.1f}%ï¼‰",
            "suggestion": "å…¥åŠ›å†…å®¹ã‚„SQLæ§‹æ–‡ã®ç¢ºèªã‚’ãŠå‹§ã‚ã—ã¾ã™"
        })
    elif error_rate == 0:
        performance_insights.append({
            "type": "success",
            "message": "ã‚¨ãƒ©ãƒ¼ãªãå®Ÿè¡Œã§ãã¦ã„ã¾ã™",
            "suggestion": "å®‰å®šã—ãŸåˆ†æãƒ•ãƒ­ãƒ¼ã§ã™"
        })
    
    return performance_insights

def show_performance_insights():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ´å¯Ÿã®è¡¨ç¤º"""
    insights = analyze_performance_metrics()
    
    if insights:
        with st.expander("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ", expanded=False):
            for insight in insights:
                if insight["type"] == "critical":
                    st.error(f"ğŸ”´ {insight['message']}")
                    st.info(f"ğŸ’¡ {insight['suggestion']}")
                elif insight["type"] == "warning":
                    st.warning(f"ğŸŸ¡ {insight['message']}")
                    st.info(f"ğŸ’¡ {insight['suggestion']}")
                elif insight["type"] == "success":
                    st.success(f"ğŸŸ¢ {insight['message']}")
                    st.info(f"ğŸ’¡ {insight['suggestion']}")

# =========================================================================
# è‡ªå‹•æœ€é©åŒ–æ©Ÿèƒ½
# =========================================================================

def suggest_query_optimizations(sql: str) -> List[Dict[str, str]]:
    """ã‚¯ã‚¨ãƒªæœ€é©åŒ–ã®ææ¡ˆ"""
    suggestions = []
    sql_upper = sql.upper()
    
    # SELECT *ã®ä½¿ç”¨ãƒã‚§ãƒƒã‚¯
    if "SELECT *" in sql_upper:
        suggestions.append({
            "type": "performance",
            "description": "SELECT * ã®ä½¿ç”¨ã‚’é¿ã‘ã€å¿…è¦ãªåˆ—ã®ã¿ã‚’é¸æŠ",
            "example": "SELECT column1, column2 FROM table",
            "priority": "medium"
        })
    
    # LIMITå¥ã®ä½¿ç”¨ãƒã‚§ãƒƒã‚¯
    if "LIMIT" not in sql_upper and "COUNT" not in sql_upper:
        suggestions.append({
            "type": "performance",
            "description": "å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯LIMITå¥ã®ä½¿ç”¨ã‚’æ¨å¥¨",
            "example": "SELECT ... FROM table LIMIT 1000",
            "priority": "low"
        })
    
    # WHEREå¥ã®æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒã‚§ãƒƒã‚¯
    if "WHERE" not in sql_upper and ("Date" in sql or "date" in sql):
        suggestions.append({
            "type": "performance",
            "description": "æ—¥ä»˜ç¯„å›²ã§ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’æ¨å¥¨",
            "example": "WHERE Date >= '2024-01-01'",
            "priority": "medium"
        })
    
    # SAFEé–¢æ•°ã®ä½¿ç”¨ãƒã‚§ãƒƒã‚¯
    if "/" in sql and "SAFE_DIVIDE" not in sql_upper:
        suggestions.append({
            "type": "safety",
            "description": "é™¤ç®—ã«ã¯SAFE_DIVIDE()ã®ä½¿ç”¨ã‚’æ¨å¥¨",
            "example": "SAFE_DIVIDE(numerator, denominator)",
            "priority": "high"
        })
    
    return suggestions

# =========================================================================
# åˆ†æå“è³ªè©•ä¾¡
# =========================================================================

def evaluate_analysis_quality(user_input: str, sql: str, df: pd.DataFrame) -> Dict[str, Any]:
    """åˆ†æå“è³ªã®è©•ä¾¡"""
    quality_score = 0
    quality_factors = []
    
    # å…¥åŠ›ã®å…·ä½“æ€§è©•ä¾¡
    if len(user_input.split()) >= 10:
        quality_score += 20
        quality_factors.append("è©³ç´°ãªåˆ†ææŒ‡ç¤º")
    else:
        quality_factors.append("ç°¡æ½”ãªåˆ†ææŒ‡ç¤º")
    
    # SQLã®è¤‡é›‘åº¦è©•ä¾¡
    sql_upper = sql.upper()
    complexity_score = 0
    
    if "JOIN" in sql_upper:
        complexity_score += 10
        quality_factors.append("è¤‡æ•°ãƒ†ãƒ¼ãƒ–ãƒ«çµåˆ")
    
    if "GROUP BY" in sql_upper:
        complexity_score += 10
        quality_factors.append("ãƒ‡ãƒ¼ã‚¿é›†ç´„")
    
    if "ORDER BY" in sql_upper:
        complexity_score += 5
        quality_factors.append("é©åˆ‡ãªã‚½ãƒ¼ãƒˆ")
    
    if "LIMIT" in sql_upper:
        complexity_score += 5
        quality_factors.append("çµæœåˆ¶é™")
    
    quality_score += min(complexity_score, 30)
    
    # ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡
    if df is not None and not df.empty:
        data_score = 0
        
        # ãƒ‡ãƒ¼ã‚¿é‡ã®è©•ä¾¡
        if 10 <= len(df) <= 10000:
            data_score += 20
            quality_factors.append("é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿é‡")
        elif len(df) > 10000:
            data_score += 10
            quality_factors.append("å¤§é‡ãƒ‡ãƒ¼ã‚¿")
        else:
            data_score += 5
            quality_factors.append("å°‘é‡ãƒ‡ãƒ¼ã‚¿")
        
        # NULLå€¤ã®è©•ä¾¡
        null_rate = (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
        if null_rate < 10:
            data_score += 15
            quality_factors.append("ä½NULLå€¤ç‡")
        elif null_rate < 30:
            data_score += 10
            quality_factors.append("ä¸­ç¨‹åº¦NULLå€¤ç‡")
        else:
            data_score += 0
            quality_factors.append("é«˜NULLå€¤ç‡")
        
        quality_score += min(data_score, 35)
    
    # ç·åˆè©•ä¾¡
    quality_level = "ä½"
    if quality_score >= 70:
        quality_level = "é«˜"
    elif quality_score >= 50:
        quality_level = "ä¸­"
    
    return {
        "score": quality_score,
        "level": quality_level,
        "factors": quality_factors,
        "recommendations": generate_quality_recommendations(quality_score, quality_factors)
    }

def generate_quality_recommendations(score: int, factors: List[str]) -> List[str]:
    """å“è³ªæ”¹å–„ã®æ¨å¥¨äº‹é …"""
    recommendations = []
    
    if score < 50:
        recommendations.append("ã‚ˆã‚Šå…·ä½“çš„ã§è©³ç´°ãªåˆ†ææŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        recommendations.append("è¤‡æ•°ã®æŒ‡æ¨™ã‚’çµ„ã¿åˆã‚ã›ãŸåˆ†æã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
    
    if "é«˜NULLå€¤ç‡" in factors:
        recommendations.append("NULLå€¤ã®å¤šã„ãƒ‡ãƒ¼ã‚¿ã¯å“è³ªãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    
    if "å°‘é‡ãƒ‡ãƒ¼ã‚¿" in factors:
        recommendations.append("åˆ†ææœŸé–“ã‚’å»¶é•·ã—ã¦ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ãã ã•ã„")
    
    if "å¤§é‡ãƒ‡ãƒ¼ã‚¿" in factors:
        recommendations.append("å¿…è¦ã«å¿œã˜ã¦LIMITå¥ã§ãƒ‡ãƒ¼ã‚¿é‡ã‚’åˆ¶é™ã—ã¦ãã ã•ã„")
    
    if score >= 70:
        recommendations.append("é«˜å“è³ªãªåˆ†æãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã™ï¼")
    
    return recommendations

# =========================================================================
# å¤–éƒ¨å‘¼ã³å‡ºã—ç”¨ã®çµ±åˆé–¢æ•°
# =========================================================================

def run_comprehensive_analysis(gemini_model, claude_client, claude_model_name, user_input, sheet_analysis_queries):
    """åŒ…æ‹¬çš„ãªåˆ†æå®Ÿè¡Œï¼ˆã™ã¹ã¦ã®æ©Ÿèƒ½ã‚’çµ±åˆï¼‰"""
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
    initialize_analysis_session()
    
    # ãƒ¡ã‚¤ãƒ³åˆ†æãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
    success = run_analysis_flow(gemini_model, claude_client, claude_model_name, user_input, sheet_analysis_queries)
    
    if success:
        # å¾Œå‡¦ç†
        post_process_analysis_results()
        
        # å±¥æ­´ä¿å­˜
        if st.session_state.get("df") is not None:
            save_analysis_to_history(
                user_input, 
                st.session_state.get("sql", ""), 
                st.session_state.df,
                "enhanced" if st.session_state.get("use_enhanced_prompts", True) else "basic"
            )
        
        # å“è³ªè©•ä¾¡
        if st.session_state.get("df") is not None:
            quality_report = evaluate_analysis_quality(
                user_input, 
                st.session_state.get("sql", ""), 
                st.session_state.df
            )
            st.session_state.analysis_quality = quality_report
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ´å¯Ÿè¡¨ç¤º
        show_performance_insights()
    
    return success

# =========================================================================
# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»å¾©å…ƒæ©Ÿèƒ½
# =========================================================================

def export_analysis_session():
    """åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    import json
    
    export_data = {
        "session_info": st.session_state.get("analysis_session", {}),
        "current_analysis": {
            "user_input": st.session_state.get("user_input", ""),
            "sql": st.session_state.get("sql", ""),
            "system_type": "enhanced" if st.session_state.get("use_enhanced_prompts", True) else "basic"
        },
        "history": st.session_state.get("analysis_history", []),
        "stats": st.session_state.get("usage_stats", {}),
        "export_timestamp": datetime.now().isoformat()
    }
    
    return json.dumps(export_data, ensure_ascii=False, indent=2, default=str)

def import_analysis_session(import_data: str):
    """åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    try:
        import json
        data = json.loads(import_data)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã®å¾©å…ƒ
        if "session_info" in data:
            st.session_state.analysis_session = data["session_info"]
        
        # ç¾åœ¨ã®åˆ†æã®å¾©å…ƒ
        if "current_analysis" in data:
            current = data["current_analysis"]
            st.session_state.user_input = current.get("user_input", "")
            st.session_state.sql = current.get("sql", "")
            st.session_state.use_enhanced_prompts = (current.get("system_type") == "enhanced")
        
        # å±¥æ­´ã®å¾©å…ƒ
        if "history" in data:
            st.session_state.analysis_history = data["history"]
        
        # çµ±è¨ˆã®å¾©å…ƒ
        if "stats" in data:
            st.session_state.usage_stats = data["stats"]
        
        st.success("âœ… åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸã€‚")
        return True
        
    except Exception as e:
        st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False