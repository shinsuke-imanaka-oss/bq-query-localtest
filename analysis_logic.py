# analysis_logic.py - å‹ãƒ’ãƒ³ãƒˆä¿®æ­£ç‰ˆ
"""
åˆ†æãƒ­ã‚¸ãƒƒã‚¯ - å‹ãƒ’ãƒ³ãƒˆä¿®æ­£ç‰ˆ
- BigQuery SQLå®Ÿè¡Œæ©Ÿèƒ½
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
"""

import streamlit as st
import pandas as pd
import json
import traceback
import time
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple  # âœ… Tuple ã‚’è¿½åŠ 

# æ—¢å­˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã®äº’æ›æ€§ç¶­æŒã®ãŸã‚ã€åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚‚ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from prompts import select_best_prompt, MODIFY_SQL_TEMPLATE, CLAUDE_COMMENT_PROMPT_TEMPLATE
except ImportError:
    st.warning("prompts.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# å¼·åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ  
try:
    from enhanced_prompts import (
        generate_enhanced_sql_prompt, 
        generate_enhanced_claude_prompt,
        ENHANCED_MODIFY_SQL_TEMPLATE,
        PromptContextEnhancer
    )
except ImportError:
    st.warning("enhanced_prompts.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ä½¿ç”¨")

# å¼·åŒ–ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
try:
    from error_handler import handle_analysis_error, show_enhanced_error_message
except ImportError:
    st.warning("error_handler.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - åŸºæœ¬ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä½¿ç”¨")
    def handle_analysis_error(error, sql="", operation=""):
        st.error(f"ã‚¨ãƒ©ãƒ¼: {str(error)}")
        return False
    def show_enhanced_error_message(error, context):
        st.error(f"ã‚¨ãƒ©ãƒ¼: {str(error)}")

MAX_ATTEMPTS = 3

def json_converter(o):
    """JSONå¤‰æ›ç”¨ã®ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼"""
    import datetime, decimal
    if isinstance(o, (datetime.date, datetime.datetime)): 
        return o.isoformat()
    if isinstance(o, decimal.Decimal): 
        return float(o)
    return str(o)

def add_modification_to_current_session(modification_type: str, instruction: str, new_sql: Optional[str] = None):
    """ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿®æ­£å±¥æ­´ã‚’è¿½åŠ ï¼ˆæˆåŠŸæ™‚ã®ã¿ï¼‰"""
    if not st.session_state.get('current_session_id'):
        return
    
    for session in st.session_state.get('analysis_sessions', []):
        if session["session_id"] == st.session_state.current_session_id:
            modification = {
                "timestamp": datetime.now(),
                "type": modification_type,  # "ai_modify", "manual_edit", "initial"
                "instruction": instruction,
                "sql": new_sql
            }
            session["modifications"].append(modification)
            if new_sql:
                session["current_sql"] = new_sql
            break

def execute_sql_with_error_handling(client, sql: str) -> Optional[pd.DataFrame]:
    """
    SQLã‚’å®Ÿè¡Œã—ã€è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¡Œã†ï¼ˆä¿®æ­£ç‰ˆï¼‰
    """
    try:
        # å…¥åŠ›æ¤œè¨¼
        if not sql or not sql.strip():
            st.error("âŒ å®Ÿè¡Œã™ã‚‹SQLãŒç©ºã§ã™")
            return None
            
        # SQLã®åŸºæœ¬çš„ãªå®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
        sql = sql.strip()
        
        # ãƒ‡ãƒãƒƒã‚°: å®Ÿéš›ã«å®Ÿè¡Œã•ã‚Œã‚‹SQLã‚’è¡¨ç¤º
        st.write(f"ğŸ” **ãƒ‡ãƒãƒƒã‚°**: å®Ÿè¡ŒSQL: `{sql[:100]}...`")
        
        if not sql:
            st.error("âŒ SQLãŒç©ºã§ã™")
            return None
            
        # SQLã®åŸºæœ¬æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
        sql_upper = sql.upper()
        if not sql_upper.startswith('SELECT'):
            st.error("âŒ SELECTæ–‡ã®ã¿å®Ÿè¡Œå¯èƒ½ã§ã™")
            return None
            
        # å±é™ºãªSQLæ–‡ã®é™¤å¤–
        dangerous_keywords = ['DROP', 'DELETE', 'TRUNCATE', 'ALTER', 'CREATE', 'INSERT', 'UPDATE']
        for keyword in dangerous_keywords:
            if keyword in sql_upper:
                st.error(f"âŒ å±é™ºãªSQLæ“ä½œ '{keyword}' ã¯å®Ÿè¡Œã§ãã¾ã›ã‚“")
                return None
        
        # BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ç¢ºèª
        if not client:
            st.error("âŒ BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
            
        # SQLå®Ÿè¡Œ
        st.info("â³ BigQueryã§ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œä¸­...")
        query_job = client.query(sql)
        
        # çµæœã®å–å¾—
        df = query_job.to_dataframe()
        
        # çµæœã®æ¤œè¨¼
        if df is None:
            st.warning("âš ï¸ ã‚¯ã‚¨ãƒªçµæœãŒNullã§ã™")
            return pd.DataFrame()
            
        if df.empty:
            st.warning("âš ï¸ ã‚¯ã‚¨ãƒªã¯æ­£å¸¸ã«å®Ÿè¡Œã•ã‚Œã¾ã—ãŸãŒã€çµæœãŒç©ºã§ã—ãŸ")
            st.info("ğŸ’¡ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‚’ç·©ãã™ã‚‹ã‹ã€ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ã™ã‚‹æ—¥ä»˜ç¯„å›²ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            return df
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®è­¦å‘Š
        row_count = len(df)
        if row_count > 10000:
            st.warning(f"âš ï¸ å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ ({row_count:,}è¡Œ) ãŒå–å¾—ã•ã‚Œã¾ã—ãŸã€‚è¡¨ç¤ºã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™")
        elif row_count > 1000:
            st.info(f"â„¹ï¸ {row_count:,}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
        else:
            st.success(f"âœ… {row_count}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
            
        return df
        
    except Exception as e:
        # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã®è¡¨ç¤º
        error_str = str(e)
        st.error(f"âŒ SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {error_str}")
        
        # ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡åˆ¥å¯¾å¿œ
        if "Syntax error" in error_str:
            st.error("ğŸ” **SQLæ§‹æ–‡ã‚¨ãƒ©ãƒ¼**")
            st.info("ğŸ’¡ ç”Ÿæˆã•ã‚ŒãŸSQLã«æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
            st.markdown("""
            - SELECTæ–‡ã§å§‹ã¾ã£ã¦ã„ã‚‹ã‹
            - ã‚«ãƒ³ãƒã‚„ã‚¯ã‚©ãƒ¼ãƒˆãŒæ­£ã—ãè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã‹  
            - ãƒ†ãƒ¼ãƒ–ãƒ«åãŒæ­£ç¢ºã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã‹
            """)
            
        elif "Table" in error_str and "not found" in error_str:
            st.error("ğŸ” **ãƒ†ãƒ¼ãƒ–ãƒ«æœªç™ºè¦‹ã‚¨ãƒ©ãƒ¼**")
            st.info("ğŸ’¡ æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            
        elif "Column" in error_str and "not found" in error_str:
            st.error("ğŸ” **åˆ—æœªç™ºè¦‹ã‚¨ãƒ©ãƒ¼**") 
            st.info("ğŸ’¡ å­˜åœ¨ã—ãªã„åˆ—åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã™")
            
        elif "Access Denied" in error_str or "permission" in error_str.lower():
            st.error("ğŸ” **ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚¨ãƒ©ãƒ¼**")
            st.info("ğŸ’¡ BigQueryã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            
        else:
            st.error("ğŸ” **ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼**")
            st.info("ğŸ’¡ è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã€ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„")
        
        # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®SQLè¡¨ç¤º
        with st.expander("ğŸ”§ å®Ÿè¡Œã—ã‚ˆã†ã¨ã—ãŸSQL"):
            st.code(sql, language="sql")
            
        # ã‚¨ãƒ©ãƒ¼å±¥æ­´ã¸ã®è¿½åŠ ï¼ˆå¯èƒ½ã§ã‚ã‚Œã°ï¼‰
        try:
            show_enhanced_error_message(e, {"sql": sql, "operation": "SQLå®Ÿè¡Œ"})
        except:
            pass  # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            
        return None

def validate_sql_before_execution(sql: str) -> tuple[bool, str]:
    """
    SQLå®Ÿè¡Œå‰ã®æ¤œè¨¼
    Returns: (is_valid, error_message)
    """
    if not sql or not sql.strip():
        return False, "SQLãŒç©ºã§ã™"
    
    sql = sql.strip()
    sql_upper = sql.upper()
    
    # SELECTæ–‡ãƒã‚§ãƒƒã‚¯
    if not sql_upper.startswith('SELECT'):
        return False, "SELECTæ–‡ã§å§‹ã¾ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
    
    # FROMå¥ãƒã‚§ãƒƒã‚¯
    if 'FROM' not in sql_upper:
        return False, "FROMå¥ãŒå¿…è¦ã§ã™"
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«åãƒã‚§ãƒƒã‚¯
    if 'vorn-digi-mktg-poc-635a' not in sql:
        return False, "æ­£ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’å«ã‚€ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
    
    # å±é™ºãªSQLæ–‡ãƒã‚§ãƒƒã‚¯
    dangerous_keywords = ['DROP', 'DELETE', 'TRUNCATE', 'ALTER', 'CREATE', 'INSERT', 'UPDATE']
    for keyword in dangerous_keywords:
        if keyword in sql_upper:
            return False, f"å±é™ºãªSQLæ“ä½œ '{keyword}' ã¯å®Ÿè¡Œã§ãã¾ã›ã‚“"
    
    # åŸºæœ¬çš„ãªæ§‹æ–‡ãƒã‚§ãƒƒã‚¯
    if sql.count('(') != sql.count(')'):
        return False, "æ‹¬å¼§ã®æ•°ãŒä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“"
    
    return True, ""

def validate_sql_safety(sql: str) -> Tuple[bool, List[str]]:
    """SQLã®å®‰å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    warnings = []
    
    # åŸºæœ¬çš„ãªå®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
    sql_upper = sql.upper()
    
    # å±é™ºãªæ“ä½œã®ãƒã‚§ãƒƒã‚¯
    dangerous_operations = ['DROP', 'DELETE', 'UPDATE', 'INSERT', 'ALTER', 'TRUNCATE']
    for op in dangerous_operations:
        if op in sql_upper:
            warnings.append(f"å±é™ºãªæ“ä½œ '{op}' ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
    
    # å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™å¯èƒ½æ€§ã®ãƒã‚§ãƒƒã‚¯
    if 'LIMIT' not in sql_upper and 'COUNT' not in sql_upper:
        warnings.append("LIMITå¥ãŒãªã„ãŸã‚ã€å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    
    # WHEREå¥ãªã—ã®ãƒã‚§ãƒƒã‚¯
    if 'WHERE' not in sql_upper and 'LIMIT' not in sql_upper:
        warnings.append("WHEREå¥ã¾ãŸã¯LIMITå¥ã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™")
    
    return len(warnings) == 0, warnings

def generate_ai_comment(gemini_model, claude_client, claude_model_name: str, selected_ai: str, df: pd.DataFrame, graph_cfg: Dict) -> str:
    """AIã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã™ã‚‹ï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
    try:
        sample = df.head(10).to_dict(orient="records")
        chart_type = graph_cfg.get('main_chart_type', 'æœªé¸æŠ')
        analysis_focus = f"ã€Œ{chart_type}ã€ã§å¯è¦–åŒ–ã—ã¦ã„ã¾ã™ã€‚"
        
        if legend_col := graph_cfg.get('legend_col'):
            if legend_col != "ãªã—":
                analysis_focus += f" ã€Œ{legend_col}ã€ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ã„ã¾ã™ã€‚"
        
        if selected_ai == "Gemini (SQLç”Ÿæˆ)":
            # Geminiã¯ç°¡æ½”ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§åŠ¹æœçš„
            prompt = f"""
            ã‚ãªãŸã¯ãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
            ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã¨å¯è¦–åŒ–è¨­å®šã‚’åŸºã«ã€ç°¡æ½”ã§å®Ÿç”¨çš„ãªåˆ†æã‚³ãƒ¡ãƒ³ãƒˆã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚

            ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«: {json.dumps(sample, ensure_ascii=False, default=json_converter)[:2000]}
            å¯è¦–åŒ–è¨­å®š: {analysis_focus}
            
            ä»¥ä¸‹ã®è¦³ç‚¹ã§åˆ†æã—ã¦ãã ã•ã„ï¼š
            1. ä¸»è¦ãªæ•°å€¤ã‚„ãƒˆãƒ¬ãƒ³ãƒ‰
            2. æ³¨ç›®ã™ã¹ããƒã‚¤ãƒ³ãƒˆ
            3. æ”¹å–„ã®ãŸã‚ã®å…·ä½“çš„ææ¡ˆ
            
            200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
            """
            
            response = gemini_model.generate_content(prompt)
            return response.text if response.text else "Geminiã‹ã‚‰ã®å¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
            
        else:  # Claude
            # å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            try:
                prompt = generate_enhanced_claude_prompt(
                    json.dumps(sample, ensure_ascii=False, default=json_converter)[:2000],
                    analysis_focus
                )
            except (NameError, TypeError):
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                prompt = f"""
                ä»¥ä¸‹ã®ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€æˆ¦ç•¥çš„ãªæ´å¯Ÿã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š
                
                ãƒ‡ãƒ¼ã‚¿: {json.dumps(sample, ensure_ascii=False, default=json_converter)[:2000]}
                å¯è¦–åŒ–: {analysis_focus}
                
                åˆ†æã®è¦³ç‚¹ï¼š
                1. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®è©•ä¾¡
                2. å•é¡Œç‚¹ã¨æ©Ÿä¼šã®ç‰¹å®š
                3. å…·ä½“çš„ãªæ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
                
                300æ–‡å­—ç¨‹åº¦ã§å®Ÿç”¨çš„ãªææ¡ˆã‚’ã—ã¦ãã ã•ã„ã€‚
                """
            
            response = claude_client.messages.create(
                model=claude_model_name,
                max_tokens=1000,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text if response.content else "Claudeã‹ã‚‰ã®å¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
            
    except Exception as e:
        error_msg = f"AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        handle_analysis_error(e, "", "AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ")
        return error_msg

def run_analysis_flow(gemini_model, claude_client, claude_model_name: str, selected_ai: str, 
                     user_input: str, sheet_analysis_queries: Dict):
    """åˆ†æãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã®çµ±åˆé–¢æ•°"""
    try:
        start_time = time.time()
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®é¸æŠ
        use_enhanced = st.session_state.get("use_enhanced_prompts", False)
        
        if selected_ai == "Gemini (SQLç”Ÿæˆ)":
            st.info("ğŸ§  Geminiã§åˆ†æç”¨SQLã‚’ç”Ÿæˆä¸­...")
            
            # SQLç”Ÿæˆ
            if use_enhanced:
                try:
                    sql_prompt = generate_enhanced_sql_prompt(user_input)
                except (NameError, TypeError):
                    st.warning("å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                    sql_prompt = create_basic_sql_prompt(user_input)
            else:
                sql_prompt = create_basic_sql_prompt(user_input)
            
            # SQLç”Ÿæˆã®å®Ÿè¡Œ
            sql_response = gemini_model.generate_content(sql_prompt)
            generated_sql = sql_response.text.strip()
            
            # SQLå®Ÿè¡Œ
            df = execute_sql_with_error_handling(st.session_state.bq_client, generated_sql)
            
            if df is not None and not df.empty:
                st.session_state.sql = generated_sql
                st.session_state.df = df
                st.session_state.user_input = user_input
                
                execution_time = time.time() - start_time
                st.success(f"âœ… åˆ†æå®Œäº†ï¼{len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚ï¼ˆå®Ÿè¡Œæ™‚é–“: {execution_time:.1f}ç§’ï¼‰")
                
                # åˆ†æå±¥æ­´ã«è¿½åŠ 
                add_to_history(user_input, generated_sql, df)
                
            else:
                st.error("âŒ SQLã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                
        else:  # Claudeåˆ†æ
            if st.session_state.get("df") is not None and not st.session_state.df.empty:
                st.info("ğŸ¯ Claudeã§è©³ç´°åˆ†æã‚’å®Ÿè¡Œä¸­...")
                
                # Claudeåˆ†æã®å®Ÿè¡Œ
                df = st.session_state.df
                graph_cfg = st.session_state.get("graph_cfg", {})
                
                comment = generate_ai_comment(
                    gemini_model, claude_client, claude_model_name, 
                    selected_ai, df, graph_cfg
                )
                
                st.session_state.comment = comment
                execution_time = time.time() - start_time
                st.success(f"âœ… Claudeåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼ï¼ˆå®Ÿè¡Œæ™‚é–“: {execution_time:.1f}ç§’ï¼‰")
                
            else:
                st.warning("åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšGeminiã§SQLã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
                
    except Exception as e:
        handle_analysis_error(e, st.session_state.get("sql", ""), "åˆ†æãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ")

def create_basic_sql_prompt(user_input: str) -> str:
    """åŸºæœ¬SQLãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ"""
    try:
        prompt_info = select_best_prompt(user_input)
        return f"""
# ã‚ãªãŸã¯åºƒå‘Šåˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
# ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡ç¤º: {user_input}
# åˆ†æå¯¾è±¡: `vorn-digi-mktg-poc-635a.toki_air.LookerStudio_report_campaign`

{prompt_info.get("template", "")}

# å‡ºåŠ›: å®Ÿè¡Œå¯èƒ½ãª BigQuery SQL ã ã‘è¿”ã™ï¼ˆèª¬æ˜ãªã—ï¼‰
"""
    except (NameError, TypeError):
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé–¢æ•°ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ç·Šæ€¥ç”¨
        return f"""
# BigQuery SQLç”Ÿæˆä¾é ¼

ä»¥ä¸‹ã®åˆ†æè¦æ±‚ã«åŸºã¥ã„ã¦SQLã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
{user_input}

ãƒ†ãƒ¼ãƒ–ãƒ«: `vorn-digi-mktg-poc-635a.toki_air.LookerStudio_report_campaign`

åˆ©ç”¨å¯èƒ½ãªä¸»è¦åˆ—:
- Date, Impressions, Clicks, CostIncludingFees, Conversions
- ServiceNameJA_Media, CampaignName, AccountName
- ConversionValue, VideoViews

å®Ÿè¡Œå¯èƒ½ãªBigQuery SQLã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
"""

def add_to_history(user_input: str, sql: str, df: pd.DataFrame):
    """åˆ†æå±¥æ­´ã¸ã®è¿½åŠ """
    if "history" not in st.session_state:
        st.session_state.history = []
    
    history_entry = {
        "timestamp": datetime.now(),
        "user_input": user_input,
        "sql": sql,
        "df": df.copy(),  # DataFrameã®ã‚³ãƒ”ãƒ¼ã‚’ä¿å­˜
        "row_count": len(df),
        "columns": list(df.columns)
    }
    
    st.session_state.history.append(history_entry)
    
    # å±¥æ­´ã®ä¸Šé™ç®¡ç†ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
    if len(st.session_state.history) > 20:
        st.session_state.history = st.session_state.history[-20:]

def rerun_sql_flow(client, sql: str):
    """SQLå†å®Ÿè¡Œãƒ•ãƒ­ãƒ¼"""
    try:
        st.info("ğŸ”„ SQLã‚’å†å®Ÿè¡Œä¸­...")
        df = execute_sql_with_error_handling(client, sql)
        
        if df is not None:
            st.session_state.df = df
            st.success(f"âœ… å†å®Ÿè¡Œå®Œäº†ï¼{len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
        else:
            st.error("âŒ SQLå†å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            
    except Exception as e:
        handle_analysis_error(e, sql, "SQLå†å®Ÿè¡Œ")

def modify_and_rerun_sql_flow(gemini_model, client, original_sql: str, modification_instruction: str):
    """SQLä¿®æ­£ãƒ»å†å®Ÿè¡Œãƒ•ãƒ­ãƒ¼"""
    try:
        st.info("ğŸ”§ SQLã‚’ä¿®æ­£ä¸­...")
        
        # ä¿®æ­£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
        modify_prompt = f"""
ä»¥ä¸‹ã®SQLã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ï¼š

å…ƒã®SQL:
```sql
{original_sql}
```

ä¿®æ­£æŒ‡ç¤º: {modification_instruction}

ä¿®æ­£ã•ã‚ŒãŸBigQuery SQLã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚
"""
        
        # SQLä¿®æ­£ã®å®Ÿè¡Œ
        response = gemini_model.generate_content(modify_prompt)
        modified_sql = response.text.strip()
        
        # ä¿®æ­£ã•ã‚ŒãŸSQLã®å®Ÿè¡Œ
        df = execute_sql_with_error_handling(client, modified_sql)
        
        if df is not None and not df.empty:
            st.session_state.sql = modified_sql
            st.session_state.df = df
            st.success(f"âœ… SQLä¿®æ­£ãƒ»å®Ÿè¡Œå®Œäº†ï¼{len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
            
            # ä¿®æ­£å±¥æ­´ã«è¿½åŠ 
            add_modification_to_current_session("ai_modify", modification_instruction, modified_sql)
        else:
            st.error("âŒ ä¿®æ­£ã•ã‚ŒãŸSQLã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            
    except Exception as e:
        handle_analysis_error(e, original_sql, "SQLä¿®æ­£")

def analyze_query_performance(sql: str, execution_time: float, row_count: int) -> Dict[str, Any]:
    """ã‚¯ã‚¨ãƒªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®åˆ†æ"""
    performance = {
        "execution_time": execution_time,
        "row_count": row_count,
        "complexity_score": 0,
        "recommendations": []
    }
    
    sql_upper = sql.upper()
    
    # è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
    complexity_factors = {
        "JOIN": sql_upper.count("JOIN") * 2,
        "SUBQUERY": (sql_upper.count("SELECT") - 1) * 3,
        "GROUP BY": sql_upper.count("GROUP BY") * 1,
        "ORDER BY": sql_upper.count("ORDER BY") * 1,
        "WINDOW": sql_upper.count("OVER(") * 2
    }
    
    performance["complexity_score"] = sum(complexity_factors.values())
    
    # æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
    if execution_time > 10:
        performance["recommendations"].append("å®Ÿè¡Œæ™‚é–“ãŒé•·ã„ãŸã‚ã€LIMITã‚„WHEREå¥ã§ã®çµã‚Šè¾¼ã¿ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
    
    if row_count > 5000:
        performance["recommendations"].append("å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã¦ã„ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦é›†ç´„ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
    
    if "SELECT *" in sql_upper:
        performance["recommendations"].append("SELECT * ã®ä»£ã‚ã‚Šã«å¿…è¦ãªåˆ—ã®ã¿ã‚’é¸æŠã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™")
    
    return performance

def optimize_sql_query(sql: str) -> str:
    """SQLã‚¯ã‚¨ãƒªã®æœ€é©åŒ–ææ¡ˆ"""
    optimizations = []
    
    sql_upper = sql.upper()
    
    # SELECT * ã®æœ€é©åŒ–
    if "SELECT *" in sql_upper:
        optimizations.append("SELECT * ã‚’å…·ä½“çš„ãªåˆ—åã«å¤‰æ›´")
    
    # LIMITå¥ã®è¿½åŠ ææ¡ˆ
    if "LIMIT" not in sql_upper and "COUNT" not in sql_upper:
        optimizations.append("çµæœã‚’åˆ¶é™ã™ã‚‹ãŸã‚ã®LIMITå¥ã®è¿½åŠ ")
    
    # WHEREå¥ã®è¿½åŠ ææ¡ˆ
    if "WHERE" not in sql_upper:
        optimizations.append("ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã‚€ãŸã‚ã®WHEREå¥ã®è¿½åŠ ")
    
    # SAFE_DIVIDE ã®ä½¿ç”¨ææ¡ˆ
    if "/" in sql and "SAFE_DIVIDE" not in sql_upper:
        optimizations.append("ã‚¼ãƒ­é™¤ç®—ã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚ã®SAFE_DIVIDE()ã®ä½¿ç”¨")
    
    return "; ".join(optimizations) if optimizations else "æœ€é©åŒ–ã®ææ¡ˆã¯ã‚ã‚Šã¾ã›ã‚“"

def get_query_statistics(df: pd.DataFrame) -> Dict[str, Any]:
    """ã‚¯ã‚¨ãƒªçµæœã®çµ±è¨ˆæƒ…å ±"""
    if df is None or df.empty:
        return {"error": "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"}
    
    stats = {
        "row_count": len(df),
        "column_count": len(df.columns),
        "numeric_columns": len(df.select_dtypes(include=['number']).columns),
        "text_columns": len(df.select_dtypes(include=['object']).columns),
        "null_values": df.isnull().sum().sum(),
        "memory_usage_mb": df.memory_usage(deep=True).sum() / 1024 / 1024
    }
    
    # ãƒ‡ãƒ¼ã‚¿å‹ã®åˆ†å¸ƒ
    dtype_counts = df.dtypes.value_counts().to_dict()
    stats["dtype_distribution"] = {str(k): v for k, v in dtype_counts.items()}
    
    return stats

# =========================================================================
# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =========================================================================

def export_analysis_results(df: pd.DataFrame, sql: str, comment: str) -> Dict[str, Any]:
    """åˆ†æçµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    export_data = {
        "export_timestamp": datetime.now().isoformat(),
        "sql_query": sql,
        "row_count": len(df) if df is not None else 0,
        "columns": list(df.columns) if df is not None else [],
        "ai_comment": comment,
        "data_sample": df.head(5).to_dict(orient="records") if df is not None else [],
        "statistics": get_query_statistics(df)
    }
    
    return export_data

def import_analysis_session(session_data: Dict[str, Any]) -> bool:
    """åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    try:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
        required_keys = ["sql_query", "user_input"]
        if not all(key in session_data for key in required_keys):
            st.error("âŒ ä¸æ­£ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã§ã™")
            return False
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã¸ã®å¾©å…ƒ
        st.session_state.sql = session_data["sql_query"]
        st.session_state.user_input = session_data["user_input"]
        
        if "ai_comment" in session_data:
            st.session_state.comment = session_data["ai_comment"]
        
        st.success("âœ… åˆ†æã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ")
        return True
        
    except Exception as e:
        st.error(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False
    
def build_where_clause(filters: dict, apply_date: bool = True, apply_media: bool = True, 
                      apply_campaign: bool = True, prefix: str = "WHERE") -> str:
    """
    ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‹ã‚‰WHEREå¥ã‚’æ§‹ç¯‰ã™ã‚‹é–¢æ•°
    
    Args:
        filters: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã®è¾æ›¸
        apply_date: æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨ã™ã‚‹ã‹
        apply_media: ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨ã™ã‚‹ã‹
        apply_campaign: ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨ã™ã‚‹ã‹
        prefix: WHEREå¥ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ ("WHERE" or "AND")
    
    Returns:
        æ§‹ç¯‰ã•ã‚ŒãŸWHEREå¥ã®æ–‡å­—åˆ—
    """
    where_conditions = []
    
    # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if apply_date and filters.get("start_date") and filters.get("end_date"):
        start_date = filters["start_date"]
        end_date = filters["end_date"]
        
        # æ—¥ä»˜ãŒæ–‡å­—åˆ—ã®å ´åˆã®å‡¦ç†
        if isinstance(start_date, str):
            start_date_str = start_date
        else:
            start_date_str = start_date.strftime('%Y-%m-%d')
            
        if isinstance(end_date, str):
            end_date_str = end_date
        else:
            end_date_str = end_date.strftime('%Y-%m-%d')
        
        where_conditions.append(f"Date >= '{start_date_str}'")
        where_conditions.append(f"Date <= '{end_date_str}'")
    
    # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç† - ä¿®æ­£ç‰ˆ
    if apply_media and filters.get("media") and len(filters["media"]) > 0:
        media_list = filters["media"]
        if media_list:
            # SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ã®ãŸã‚ã€ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            escaped_media = []
            for media in media_list:
                escaped_value = media.replace("'", "''")  # SQLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                escaped_media.append(f"'{escaped_value}'")
            
            media_condition = f"ServiceNameJA_Media IN ({', '.join(escaped_media)})"
            where_conditions.append(media_condition)
    
    # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç† - ä¿®æ­£ç‰ˆ
    if apply_campaign and filters.get("campaigns") and len(filters["campaigns"]) > 0:
        campaign_list = filters["campaigns"]
        if campaign_list:
            # SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ã®ãŸã‚ã€ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            escaped_campaigns = []
            for campaign in campaign_list:
                escaped_value = campaign.replace("'", "''")  # SQLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                escaped_campaigns.append(f"'{escaped_value}'")
            
            campaign_condition = f"CampaignName IN ({', '.join(escaped_campaigns)})"
            where_conditions.append(campaign_condition)
    
    # WHEREå¥ã®æ§‹ç¯‰
    if where_conditions:
        if prefix == "WHERE":
            return f"WHERE {' AND '.join(where_conditions)}"
        elif prefix == "AND":
            return f"AND {' AND '.join(where_conditions)}"
        else:
            return ' AND '.join(where_conditions)
    else:
        return ""

def build_safe_where_clause(filters: dict, table_schema: dict = None) -> str:
    """
    ã‚ˆã‚Šå®‰å…¨ãªWHEREå¥æ§‹ç¯‰ï¼ˆæ¨å¥¨ç‰ˆï¼‰
    
    Args:
        filters: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶
        table_schema: ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Returns:
        æ§‹ç¯‰ã•ã‚ŒãŸWHEREå¥
    """
    conditions = []
    
    # æ—¥ä»˜ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if filters.get("start_date") and filters.get("end_date"):
        start_date = filters["start_date"]
        end_date = filters["end_date"]
        
        # æ—¥ä»˜ã®æ­£è¦åŒ–
        if hasattr(start_date, 'strftime'):
            start_str = start_date.strftime('%Y-%m-%d')
        else:
            start_str = str(start_date)
            
        if hasattr(end_date, 'strftime'):
            end_str = end_date.strftime('%Y-%m-%d')
        else:
            end_str = str(end_date)
        
        conditions.append(f"Date BETWEEN '{start_str}' AND '{end_str}'")
    
    # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆé…åˆ—ãŒç©ºã§ãªã„å ´åˆã®ã¿ï¼‰- ä¿®æ­£ç‰ˆ
    if filters.get("media") and len(filters["media"]) > 0:
        media_values = []
        for media in filters["media"]:
            # åŸºæœ¬çš„ãªæ–‡å­—åˆ—æ¤œè¨¼ã¨ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            if isinstance(media, str) and media.strip():
                escaped = media.replace("'", "''")  # SQLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ï¼ˆä¿®æ­£ç‰ˆï¼‰
                media_values.append(f"'{escaped}'")
        
        if media_values:
            conditions.append(f"ServiceNameJA_Media IN ({', '.join(media_values)})")
    
    # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆé…åˆ—ãŒç©ºã§ãªã„å ´åˆã®ã¿ï¼‰- ä¿®æ­£ç‰ˆ
    if filters.get("campaigns") and len(filters["campaigns"]) > 0:
        campaign_values = []
        for campaign in filters["campaigns"]:
            # åŸºæœ¬çš„ãªæ–‡å­—åˆ—æ¤œè¨¼ã¨ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            if isinstance(campaign, str) and campaign.strip():
                escaped = campaign.replace("'", "''")  # SQLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ï¼ˆä¿®æ­£ç‰ˆï¼‰
                campaign_values.append(f"'{escaped}'")
        
        if campaign_values:
            conditions.append(f"CampaignName IN ({', '.join(campaign_values)})")
    
    # æ¡ä»¶ã®çµåˆ
    if conditions:
        return f"WHERE {' AND '.join(conditions)}"
    else:
        return ""

# ã‚ˆã‚Šé«˜åº¦ãªæ¤œç´¢æ¡ä»¶æ§‹ç¯‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ï¼‰
def build_advanced_where_clause(filters: dict, advanced_options: dict = None) -> str:
    """
    é«˜åº¦ãªWHEREå¥æ§‹ç¯‰ï¼ˆå°†æ¥çš„ãªæ©Ÿèƒ½æ‹¡å¼µç”¨ï¼‰
    """
    base_where = build_safe_where_clause(filters)
    
    if not advanced_options:
        return base_where
    
    additional_conditions = []
    
    # ã‚³ã‚¹ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if advanced_options.get("min_cost"):
        additional_conditions.append(f"CostIncludingFees >= {advanced_options['min_cost']}")
    
    if advanced_options.get("max_cost"):
        additional_conditions.append(f"CostIncludingFees <= {advanced_options['max_cost']}")
    
    # ã‚¯ãƒªãƒƒã‚¯æ•°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if advanced_options.get("min_clicks"):
        additional_conditions.append(f"Clicks >= {advanced_options['min_clicks']}")
    
    # è¿½åŠ æ¡ä»¶ãŒã‚ã‚‹å ´åˆã®çµ±åˆ
    if additional_conditions:
        if base_where:
            return f"{base_where} AND {' AND '.join(additional_conditions)}"
        else:
            return f"WHERE {' AND '.join(additional_conditions)}"
    
    return base_where